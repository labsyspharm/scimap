{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Scimap is a scalable toolkit for analyzing spatial molecular data. The underlying framework is generalizable to spatial datasets mapped to XY coordinates. The package uses the anndata framework making it easy to integrate with other popular single-cell analysis toolkits. It includes preprocessing, phenotyping, visualization, clustering, spatial analysis and differential spatial testing. The Python-based implementation efficiently deals with large datasets of millions of cells.</p> <p>Scimap operates on segmented single-cell data derived from imaging data using tools such as cellpose or MCMICRO. The essential inputs for SCIMAP are: (a) a single-cell expression matrix and (b) the X and Y coordinates for each cell. Additionally, multi-stack OME-TIFF or TIFF images can be optionally provided to enable visualization of the data analysis on the original raw images. </p> <p>Scimap development was led by Ajit Johnson Nirmal, Harvard Medical School. Check out other tools from the Nirmal Lab. </p>"},{"location":"#citing-scimap","title":"Citing scimap","text":"<p>Nirmal et al., (2024). SCIMAP: A Python Toolkit for Integrated Spatial Analysis of Multiplexed Imaging Data. Journal of Open Source Software, 9(97), 6604, https://doi.org/10.21105/joss.06604</p>"},{"location":"#funding","title":"Funding","text":"<p>This work was supported by the following NIH grant K99-CA256497</p>"},{"location":"Getting%20Started/","title":"Welcome to Scimap! \ud83d\ude80","text":"<p>Begin your journey into the fascinating world of spatial single-cell analysis with Scimap, a comprehensive toolkit designed to empower your single-cell data exploration.</p>"},{"location":"Getting%20Started/#installation","title":"Installation \ud83d\udce6","text":"<p>Kick off by installing Scimap through these simple commands: We highly advise creating a separate environment for installing Scimap to ensure a smooth and conflict-free setup. For comprehensive guidance on this process, please refer to our tutorials.</p> <pre><code># If you have conda installed\nconda create --name scimap python=3.10\nconda activate scimap\n</code></pre> <p>Install <code>scimap</code> directly into an activated virtual environment:</p> <p>Firstly, we suggest installing <code>scimap</code> and <code>napari</code> together to enable visualization out of the box. Keep in mind, <code>napari</code> needs a GUI toolkit, such as PyQt. If you run into any issues because of your computer's operating system, install <code>scimap</code> and <code>napari</code> separately by following the guidance in <code>napari's</code> documentation.</p> <p>Here's how you can install both using pip:</p> <pre><code>pip install \"scimap[napari]\"\n</code></pre> <p>If you encounter a problem with PyQt6 during the installation, you can install <code>scimap</code> alone first. Later on, if you find you need <code>napari</code>, you can go ahead and install it by itself.</p> <p>To install just <code>scimap</code>:</p> <pre><code>pip install scimap\n</code></pre> <p>Open python and import scimap</p> <pre><code>&gt;&gt;&gt; import scimap as sm\n</code></pre> <p>This setup provides you with the foundational tools needed for your single-cell analysis endeavors.</p>"},{"location":"Getting%20Started/#data-loading-and-integration","title":"Data Loading and Integration \ud83d\udd04","text":"<p>SCIMAP operates on segmented single-cell data derived from imaging data using tools such as cellpose or MCMICRO. The essential inputs for SCIMAP are: (a) a single-cell expression matrix and (b) the X and Y coordinates for each cell. Additionally, multi-stack OME-TIFF or TIFF images can be optionally provided to enable visualization of the data analysis on the original raw images.</p> <p>Scimap champions the interoperability of single-cell analysis tools by embracing the <code>AnnData</code> data structure. This strategic choice allows seamless use of numerous single-cell analysis utilities alongside <code>AnnData</code>.</p>"},{"location":"Getting%20Started/#the-anndata-framework","title":"The AnnData Framework \ud83e\uddec","text":"<p>An <code>AnnData</code> object, <code>adata</code>, encapsulates a data matrix <code>adata.X</code>, with annotations of observations <code>adata.obs</code> and variables <code>adata.var</code> as <code>pd.DataFrame</code>, and unstructured annotation <code>adata.uns</code> as a dictionary. Observation and variable names are accessible via <code>adata.obs_names</code> and <code>adata.var_names</code>, respectively. AnnData objects support slicing, similar to dataframes: <code>adata_subset = adata[:, list_of_gene_names]</code>. Explore <code>AnnData</code> further in the official documentation.</p>"},{"location":"Getting%20Started/#initializing-anndata-objects","title":"Initializing AnnData Objects \ud83d\udd04","text":"<p>To begin with an AnnData object, proceed as follows:</p> <pre><code>import anndata as ad\nimport pandas as pd\n\n# Load your data\ndata = pd.read_csv('counts_matrix.csv')  # Your single-cell counts matrix\nmeta = pd.read_csv('meta_data.csv')      # Associated MetaData\n\n# Craft the AnnData object\nadata = ad.AnnData(data)\nadata.obs = meta\n</code></pre> <p>!!! Note \ud83d\udcdd     Leveraging the mcmicro pipeline? Scimap simplifies converting <code>mcmicro</code> outputs into an <code>AnnData</code> object:</p> <pre><code>filepath = ['/path/to/file.csv']\nadata = sm.pp.mcmicro_to_scimap(filepath)\n</code></pre>"},{"location":"Getting%20Started/#navigating-non-mcmicro-data","title":"Navigating Non-mcmicro Data \ud83e\uddd0","text":"<p>What to do if your dataset wasn't processed with mcmicro? Ensuring your data aligns with Scimap's expectations is vital for smooth analysis:</p> <ul> <li>Spatial Assumptions: Spatial functions expect XY coordinates in 'X_centroid' and 'Y_centroid' columns. If your data differs, specify your columns when using these functions.</li> <li>Manual Data Integration: Here's how to manually prepare your data for Scimap analysis:</li> </ul> <pre><code># Import necessary packages\nimport anndata as ad\nimport pandas as pd\n\n# Load data\ndata = pd.read_csv('path/to/counts_table.csv')  # Counts matrix\nmeta = pd.read_csv('path/to/meta_data.csv')     # Meta data with coordinates\n\n# Merge data and metadata for the AnnData object\nadata = ad.AnnData(data)\nadata.obs = meta\n\n# preserve raw data\nadata.raw = adata\n\n# log transform data\nadata = sm.pp.log1p(adata)\n\n# Add marker annotation for visualization with Napari\nadata.uns['all_markers'] = ['list', 'of', 'all', 'markers', 'in', 'image']\n</code></pre>"},{"location":"Getting%20Started/#key-steps-for-data-preparation","title":"Key Steps for Data Preparation \ud83d\udddd\ufe0f","text":"<ol> <li>Unique Image Identification: Include a <code>imageid</code> column in your metadata for easy data retrieval.</li> <li>Preserving Raw Data: Store unprocessed data in <code>adata.raw</code> for reference.</li> <li>Log Transformation Layer: Create a <code>log</code> layer for log-transformed data normalization.</li> <li>Marker Annotation: Keep a record of image markers in <code>adata.uns['all_markers']</code> for clarity during analysis.</li> </ol>"},{"location":"Getting%20Started/#saving-your-anndata-object","title":"Saving Your AnnData Object \ud83d\udcbe","text":"<p>An AnnData object centralizes your data and analysis, making it simple to share and collaborate. To save your work:</p> <pre><code># Save your AnnData object\nadata.write('/path/to/scimapExampleData.h5ad')\n</code></pre> <p>This streamlined approach facilitates comprehensive analyses, enabling you to leverage Scimap's full suite of tools and integrate with other analysis frameworks seamlessly.</p>"},{"location":"Getting%20Started/#your-workflow-journey","title":"Your Workflow Journey \ud83d\udee4\ufe0f","text":"<p>With Scimap, navigate through a suite of tools designed to enrich your analysis:</p> <ul> <li>Pre-Processing Tools: <code>sm.pp.&lt;tool&gt;</code> for data preparation.</li> <li>Analysis Tools: <code>sm.tp.&lt;tool&gt;</code> for in-depth insights.</li> <li>Plotting Tools: <code>sm.pl.&lt;tool&gt;</code> for impactful visualizations.</li> <li>Helper Tools: <code>sm.hl.&lt;tool&gt;</code> for additional functionalities.</li> </ul> <p>Embark on your spatial single-cell analysis journey with Scimap today and unlock the potential within your data. \ud83c\udf1f</p>"},{"location":"Tools%20Shortcut/","title":"Tools Shortcut","text":"<pre><code>import scimap as sm\n</code></pre>"},{"location":"Tools%20Shortcut/#preprocessing-pp","title":"Preprocessing (<code>pp</code>)","text":"<p><code>Scimap</code> offers an array of preprocessing functions, meticulously designed to optimize high-dimensional datasets for advanced analysis.</p> Function Detailed Description <code>sm.pp.mcmicro_to_scimap</code> Facilitates the transformation of <code>mcmicro</code> outputs into <code>scimap</code>-compatible formats, enabling the integration of microscopy data for comprehensive analysis. <code>sm.pp.log1p</code> Applies a log1p transformation to the raw data within an AnnData object. <code>sm.pp.rescale</code> Employs both manual and automated gating-based strategies for data rescaling, enhancing measurement scale sensitivity and dynamic range for optimal data representation. <code>sm.pp.combat</code> Implements an advanced batch correction algorithm to effectively neutralize batch-related variabilities, ensuring data consistency across different experimental batches."},{"location":"Tools%20Shortcut/#tools-tl","title":"Tools (<code>tl</code>)","text":"<p><code>Scimap</code> presents a broad spectrum of analytical tools, each engineered to extract nuanced insights from single-cell datasets through sophisticated algorithms.</p> Function Description <code>sm.tl.phenotype_cells</code> Leverages probability distribution models for precise cell phenotyping, enabling detailed characterization of cellular identities based on marker expressions. <code>sm.tl.cluster</code> Provides a flexible clustering framework to delineate cellular subpopulations using a range of algorithms, facilitating the discovery of previously unrecognized cell types. <code>sm.tl.umap</code> Applies the UMAP algorithm for dimensionality reduction, affording a more interpretable visualization of complex single-cell data landscapes. <code>sm.tl.foldchange</code> Calculates fold changes in phenotype expressions between samples or Regions of Interest (ROIs), enabling quantitative comparisons of cellular characteristics. <code>sm.tl.spatial_distance</code> Computes the nearest distances between all phenotypes for each cell, offering insights into spatial arrangements and distributions within tissue contexts. <code>sm.tl.spatial_interaction</code> Analyzes cell-cell interactions to uncover patterns of spatial organization and intercellular communication within microenvironments. <code>sm.tl.spatial_count</code> Evaluates the distribution of cell types within local neighborhoods, providing a quantitative measure of cellular diversity and density. <code>sm.tl.spatial_lda</code> Utilizes Latent Dirichlet Allocation (LDA) modeling to identify spatial motifs, facilitating the understanding of complex spatial patterns and their biological implications. <code>sm.tl.spatial_expression</code> Investigates the distribution of spatial expression patterns within local neighborhoods, offering insights into the spatial heterogeneity of gene expression. <code>sm.tl.spatial_cluster</code> Identifies clusters based on spatial expression patterns, enabling the elucidation of spatially defined cellular networks and communities. <code>sm.tl.spatial_pscore</code> Scores the proximity between predefined cell types, quantifying the spatial relationships and potential functional interactions between distinct cellular populations. <code>sm.tl.spatial_aggregate</code> Summarizes aggregates of cell types within local neighborhoods, providing a macroscopic view of cellular organization and tissue architecture. <code>sm.tl.spatial_similarity_search</code> Searches for regions within and across images that exhibit similar spatial patterns, aiding in the identification of recurring spatial motifs and their biological relevance."},{"location":"Tools%20Shortcut/#plotting-pl","title":"Plotting (<code>pl</code>)","text":"<p><code>Scimap</code> incorporates a comprehensive suite of plotting functions designed for the intuitive visualization and interpretation of spatial and phenotypic data.</p> Function Description <code>sm.pl.image_viewer</code> Integrates with <code>napari</code> to offer an interactive platform for enhanced image viewing and annotation with data overlays. <code>sm.pl.addROI_image</code> Facilitates the addition of Regions of Interest (ROIs) through <code>napari</code>, enriching spatial analyses with precise locational data. <code>sm.pl.gate_finder</code> Aids in the manual gating process by overlaying marker positivity on images, simplifying the identification and analysis of cellular subsets. <code>sm.pl.napariGater</code> Modified version of gate_finder and soon to replace it. <code>sm.pl.heatmap</code> Creates heatmaps to visually explore marker expression or feature distributions across different groups. <code>sm.pl.markerCorrelation</code> Computes and visualizes the correlation among selected markers. <code>sm.pl.groupCorrelation</code> Calculates and displays the correlation between the abundances of groups across user defined conditions. <code>sm.pl.distPlot</code> Generates distribution plots for specific markers, allowing for the visual comparison of marker expression across different conditions or cell types. <code>sm.pl.densityPlot2D</code> Creates two-dimensional density plots of marker expressions, facilitating the visualization of expression patterns and densities in a spatial context. <code>sm.pl.cluster_plots</code> Provides a meta-function that outputs a combination of UMAP, heatmap, and ranked markers for each group, offering a comprehensive view of clustering results. <code>sm.pl.umap</code> Overlays markers on UMAP projections, enhancing the interpretation of dimensional reduction analyses with annotated data points. <code>sm.pl.foldchange</code> Visualizes fold changes in phenotypes between samples or ROIs, enabling the graphical comparison of cellular expression profiles. <code>sm.pl.spatial_scatterPlot</code> Produces scatter plots of spatially resolved data, illustrating the distribution and organization of cells within tissue sections. <code>sm.pl.spatial_distance</code> Visualizes the spatial distances between phenotypes, providing insights into the physical separation and clustering of cell types. <code>sm.pl.spatial_interaction</code> Displays heatmaps of cell-cell interaction analyses, highlighting the complex interplay between different cellular populations. <code>sm.pl.spatialInteractionNetwork</code> Displays  cell-cell interaction analyses as a Network plot. <code>sm.pl.spatial_pscore</code> Generates bar plots of Spatial Proximity Scores, quantifying and visualizing the proximity between selected cell types within a spatial context. <code>sm.pl.stacked_barplot</code> Creates stacked barplots from any two columns of categorical data, offering a clear visualization of proportions and relationships between categories. <code>sm.pl.pie</code> Produces pie charts to represent the proportions of cell types or any categorical data, facilitating the quick assessment of composition within datasets. <code>sm.pl.voronoi</code> Generates Voronoi diagrams colored by categorical data, providing a unique visual representation of spatial distributions and territories."},{"location":"Tools%20Shortcut/#helper-functions-hl","title":"Helper Functions (<code>hl</code>)","text":"<p><code>Scimap</code> also features a collection of helper functions designed to facilitate efficient data manipulation and enhance the analytical workflow.</p> Function Description <code>sm.hl.classify</code> Streamlines the classification of cells based on the positivity or negativity of specified markers, simplifying the assignment of cellular identities. <code>sm.hl.rename</code> Enables quick and efficient renaming within data columns through the application of dictionary-based mappings, enhancing data clarity and consistency. <code>sm.hl.addROI_omero</code> Allows for the seamless integration of Regions of Interest (ROIs) extracted from Omero into <code>scimap</code> objects, bridging imaging and analytical platforms. <code>sm.hl.dropFeatures</code> Provides a convenient function for subsetting the <code>adata</code> object by removing specified features, aiding in the focus on relevant data. <code>sm.hl.animate</code> Creates animated scatter plots transitioning from embedding to physical location, offering dynamic visual insights into spatial data relationships. <code>sm.hl.merge_adata_obs</code> Facilitates the merging of multiple AnnData objects, ensuring cohesive analysis across disparate datasets. <code>sm.hl.scimap_to_csv</code> Enables the export of <code>scimap</code> objects to CSV format, providing flexibility in data sharing and further analysis with external tools."},{"location":"contribute/","title":"Contributing guide","text":"<p>We are thrilled you're interested in contributing to our tool! To ensure a smooth integration of your contributions, we have outlined a simple process. Contributions can be in the form of new functionalities, bug fixes, or enhancements to existing features. Please see the provided steps below and never hesitate to contact us. Follow these steps to get started:</p> <p>If you are a new user, we recommend checking out the detailed Docs.  </p>"},{"location":"contribute/#setting-up-a-development-installation","title":"Setting up a development installation","text":"<p>In order to make changes to scimap, you will need to fork the repository. If you are not familiar with git, we recommend reading up on this guide.</p> <p>Before we set up <code>SCIMAP</code>, we highly recommend using a environment manager like Conda. Using an environment manager like Conda allows you to create and manage isolated environments with specific package versions and dependencies.</p> <pre><code># use the terminal (mac/linux) and anaconda promt (windows) to run the following\nconda create --name scimap -y python=3.10\nconda activate scimap\n</code></pre> <p>We use poetry to manage scimap dependencies. Intall poetry and scimap into the environment. Follow poetry documentation to install it depending on the OS of your system.</p> <pre><code># install pipx by following the documentation here: https://pipx.pypa.io/stable/installation/\n\n# install poetry within the environment\npipx install poetry\n\n# install scimap within the environment\npoetry install\n</code></pre>"},{"location":"contribute/#set-up-the-contributions","title":"Set up the contributions","text":"<p>We invite contributions aimed at enhancing the performance, functionality, and reliability of the existing codebase within <code>scimap</code>. Additionally, we are open to the integration of innovative tools into scimap to facilitate the seamless analysis of multiplexed imaging data.</p> <p>If you are interested in contributing a new tool to <code>scimap</code>, please encapsulate all requisite functions within a single Python script. This script should be comprehensively designed to ensure full functionality of the proposed tool. Once prepared, place this script in the designated directory path: <code>scimap/scimap/external</code>.</p> <p>Your function must adhere to the structure outlined below.</p> <pre><code># Required libraries\nimport [library name] as [alias]\n...\n...\n\n# Your function\ndef functionName (adata,\n                    ...\n                    ...\n                    ... # other necessary parameters\n                    ...\n                    verbose=True,\n                    outputDir=None):\n\n    # CODE BLOCK: Function implementation\n\n\n    # OUTPUT\n    # not needed if the output is a plot\n\n    if outputDir:\n        adata.write(outputDir / name the file)\n    else:    \n        return adata\n</code></pre> <p>If your function requires dependencies not present in <code>scimap</code>, ascertain this by examining the <code>pyproject.toml</code> file. In such cases, it is advisable to package your tool independently. Consequently, <code>scimap</code> could function merely as an API interface to your package, enabling it to be easily installed via pip when a user wishes to utilize your tool. This strategy is primarily aimed at reducing the maintenance effort associated with managing numerous dependencies.</p>"},{"location":"contribute/#add-documentation","title":"Add Documentation","text":"<p>All contributions must be documented directly within the code to maintain clarity and usability. This includes a short description at the top of your script, followed by a detailed comment block that explains the functionality of your code, parameters, return values, and provides an example usage.</p> <p>Your code contributions should start with a script header followed by an abstract in a docstring, giving a brief overview of its functionality. Below is a template based on the provided script:</p> <pre><code>#!/usr/bin/env python3\n# Created on [Date] by [Your Name]\n\"\"\"\n\n\n!!! abstract \"Short Description\"\n    [Briefly describe the function's purpose and its utility in the tool. Explain how it contributes to the tool's functionality and any specific features it offers.]\n\n    Results are stored in the [specify location, e.g., `.uns` section of the Anndata object] for easy access and further analysis.\n\n\n\n## Function\n\"\"\"\n\n# Required libraries\nimport [library name] as [alias]\n\n# Your function\ndef functionName (parameters):\n\n    \"\"\"\nParameters:\n    parameter1 (type): \n        Description of parameter1.\n    parameter2 (type, optional): \n        Description of parameter2. \n\nReturns:\n    return_type (type): \n        Description of what is returned.\n\nExample:\n\n    ```python\n\n    # Example usage of your function\n    adata = sm.ex.yourFunction(parameter1, parameter2, ...)\n\n    ```\n    \"\"\"\n\n    # Function implementation\n</code></pre>"},{"location":"contribute/#add-unit-tests","title":"Add Unit Tests","text":"<p>Contributing unit tests is as vital as contributing code! Well-crafted unit tests help maintain the tool's integrity and facilitate future enhancements. Here's how you can add unit tests following our specified format:</p> <ol> <li> <p>Unit Test Structure: Unit tests for our tool must be added to the test_external.py file, adhering to a specific template for consistency and effectiveness. Ensure your tests are comprehensive, covering various scenarios and edge cases.</p> </li> <li> <p>Test Template and Example: Below is a template for creating a unit test, including the setup for test data and an example test case. This template uses pytest, a powerful testing framework for Python. Ensure you have pytest installed before proceeding.</p> </li> </ol> <pre><code>import pytest\nimport sys, os\nimport anndata as ad\n\n@pytest.fixture\ndef adata():\n    # Adjust the path to where the example data is located in your environment\n    image_path = os.getcwd() + '/scimap/tests/data/example_data.h5ad'\n    adata = ad.read(image_path)\n    return adata\n\n# Example unit test for your function\ndef test_yourFunction(adata):\n\n    from scimap.external.yourFunction import yourFunction\n\n    # Add your testing logic here\n    # Example: Assert the expected outcome from running your function on `adata`\n</code></pre> <p>Please ensure your test cases are well-documented, explaining the purpose of the test and the expected outcomes. This will help other contributors understand and maintain the test cases over time.</p>"},{"location":"contribute/#add-tutorial-optional","title":"Add tutorial (optional)","text":"<p>Develop a Jupyter notebook to demonstrate the capabilities of your tool, utilizing the example dataset available in /scimap/tests/data/ whenever feasible, even if the data does not precisely reflect biological accuracy. Please store the completed notebook in the <code>scimap/docs/tutorials/nb</code> directory.</p>"},{"location":"Functions/hl/addROI_omero/","title":"addROI_omero","text":"<p>Short Description</p> <p><code>sm.hl.add_roi_omero</code>: This function integrates Regions of Interest (ROIs) extracted from Omero into AnnData objects, enriching spatial datasets with precise, user-defined annotations. An optional buffering parameter allows the creation of a ring-like border region for specified ROIs to aid in spatial analyses.</p> <p>The function allows users to add annotations extracted from Omero via: https://gist.github.com/Yu-AnChen/58754f960ccd540e307ed991bc6901b0.</p>"},{"location":"Functions/hl/addROI_omero/#scimap.helpers.addROI_omero--function","title":"Function","text":""},{"location":"Functions/hl/addROI_omero/#scimap.helpers.addROI_omero.addROI_omero","title":"<code>addROI_omero(adata, roi, x_coordinate='X_centroid', y_coordinate='Y_centroid', imageid='imageid', naming_column='Name', subset=None, overwrite=True, label='ROI', buffer_roi=0, buffer_regions=None, n_jobs=-1, verbose=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix or path to an AnnData object, containing spatial gene expression data.</p> required <code>roi</code> <code>DataFrame</code> <p>DataFrame containing ROI coordinates and identifiers, obtained from Omero.</p> required <code>x_coordinate</code> <code>(str, required)</code> <p>Column name in <code>adata</code> for the x-coordinates.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <code>(str, required)</code> <p>Column name in <code>adata</code> for the y-coordinates.</p> <code>'Y_centroid'</code> <code>imageid</code> <code>str</code> <p>Column name in <code>adata.obs</code> identifying distinct images in the dataset.</p> <code>'imageid'</code> <code>naming_column</code> <code>str</code> <p>The column name in the <code>roi</code> file that contains the ROI names\u2014typically, this is <code>Name</code> or <code>Text</code>.</p> <code>'Name'</code> <code>subset</code> <code>list</code> <p>Specific image identifier(s) for targeted ROI addition.</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>If True, replaces existing ROI data; if False, appends new ROI data without overwriting.</p> <code>True</code> <code>label</code> <code>str</code> <p>Label under which ROI data will be stored in <code>adata.obs</code>.</p> <code>'ROI'</code> <code>buffer_roi</code> <code>int or float</code> <p>A numeric value (in pixels) specifying the total buffering distance. When positive, a border ROI is computed by contracting the ROI inward by half the buffer and expanding it outward by the remaining half. The new annotation will be named \"[ROI_name]_border\". The function ensures that the buffered borders do not overlap other ROIs by enforcing a minimum 1-pixel gap.</p> <code>0</code> <code>buffer_regions</code> <code>None, str, or list</code> <p>If set to None (default), the buffering is applied to all ROIs. Otherwise, it may be provided as a string or list of strings specifying the ROI name(s) (as found in the <code>naming_column</code>) to which the buffering should be applied.</p> <code>None</code> <code>n_jobs</code> <code>int</code> <p>Number of jobs for parallel processing. Defaults to -1, using all cores.</p> <code>-1</code> <code>verbose</code> <code>bool</code> <p>If set to True, the function will print detailed progress messages and statistics.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>The updated AnnData object with ROI annotations added to adata.obs[label].</p> Example <pre><code># Load the ROI CSV file\nroi_df = pd.read_csv('path/to/roi.csv')\n\n# Apply composite labeling for overlapping ROIs and buffered borders to all ROIs with a total buffer of 40 pixels\nadata = sm.hl.addROI_omero(adata, roi=roi_df, label='Sample_ROI', buffer_roi=40, verbose=True)\n\n# Apply buffering only to ROI named 'Tumor 1' with a 40-pixel buffer\nadata = sm.hl.addROI_omero(adata, roi=roi_df, label='Sample_ROI', buffer_roi=40, buffer_regions='Tumor 1', verbose=True)\n\n# Apply buffering only to a list of ROIs\nadata = sm.hl.addROI_omero(adata, roi=roi_df, label='Sample_ROI', buffer_roi=40, buffer_regions=['Tumor 1', 'TLS'], verbose=True)\n</code></pre> Source code in <code>scimap/helpers/addROI_omero.py</code> <pre><code>def addROI_omero(adata, \n                 roi, \n                 x_coordinate='X_centroid',\n                 y_coordinate='Y_centroid',\n                 imageid='imageid', \n                 naming_column='Name',\n                 subset=None, \n                 overwrite=True,\n                 label='ROI',\n                 buffer_roi=0,  # Buffer distance in pixels for border creation (e.g., 40)\n                 buffer_regions=None,  # If None, apply to all; else a str or list specifying ROI names for buffering\n                 n_jobs=-1, \n                 verbose=False):\n    \"\"\"\nParameters:\n        adata (anndata.AnnData):  \n            Annotated data matrix or path to an AnnData object, containing spatial gene expression data.\n\n        roi (DataFrame):  \n            DataFrame containing ROI coordinates and identifiers, obtained from Omero.\n\n        x_coordinate (str, required):  \n            Column name in `adata` for the x-coordinates.\n\n        y_coordinate (str, required):  \n            Column name in `adata` for the y-coordinates.\n\n        imageid (str):  \n            Column name in `adata.obs` identifying distinct images in the dataset.\n\n        naming_column (str):  \n            The column name in the `roi` file that contains the ROI names\u2014typically, this is `Name` or `Text`.\n\n        subset (list, optional):  \n            Specific image identifier(s) for targeted ROI addition.\n\n        overwrite (bool):  \n            If True, replaces existing ROI data; if False, appends new ROI data without overwriting.\n\n        label (str):  \n            Label under which ROI data will be stored in `adata.obs`.\n\n        buffer_roi (int or float, optional):  \n            A numeric value (in pixels) specifying the total buffering distance. When positive,\n            a border ROI is computed by contracting the ROI inward by half the buffer and expanding it\n            outward by the remaining half. The new annotation will be named \"[ROI_name]_border\". The function\n            ensures that the buffered borders do not overlap other ROIs by enforcing a minimum 1-pixel gap.\n\n        buffer_regions (None, str, or list, optional):  \n            If set to None (default), the buffering is applied to all ROIs. Otherwise, it may be provided as a string or list of strings\n            specifying the ROI name(s) (as found in the `naming_column`) to which the buffering should be applied.\n\n        n_jobs (int):  \n            Number of jobs for parallel processing. Defaults to -1, using all cores.\n\n        verbose (bool):  \n            If set to True, the function will print detailed progress messages and statistics.\n\nReturns:\n        adata (anndata.AnnData):  \n            The updated AnnData object with ROI annotations added to adata.obs[label].\n\nExample:\n        ```python\n        # Load the ROI CSV file\n        roi_df = pd.read_csv('path/to/roi.csv')\n\n        # Apply composite labeling for overlapping ROIs and buffered borders to all ROIs with a total buffer of 40 pixels\n        adata = sm.hl.addROI_omero(adata, roi=roi_df, label='Sample_ROI', buffer_roi=40, verbose=True)\n\n        # Apply buffering only to ROI named 'Tumor 1' with a 40-pixel buffer\n        adata = sm.hl.addROI_omero(adata, roi=roi_df, label='Sample_ROI', buffer_roi=40, buffer_regions='Tumor 1', verbose=True)\n\n        # Apply buffering only to a list of ROIs\n        adata = sm.hl.addROI_omero(adata, roi=roi_df, label='Sample_ROI', buffer_roi=40, buffer_regions=['Tumor 1', 'TLS'], verbose=True)\n        ```\n    \"\"\"\n    # Create a DataFrame with spatial coordinates and image identifiers.\n    data = pd.DataFrame(adata.obs)[[x_coordinate, y_coordinate, imageid]]\n    if verbose:\n        print(f\"[INFO] Total number of cells in dataset: {data.shape[0]}\")\n\n    # Subset data if a specific image subset is provided.\n    if subset is not None:\n        if isinstance(subset, str): \n            subset = [subset]\n        sub_data = data[data['imageid'].isin(subset)]\n        if verbose:\n            print(f\"[INFO] Using subset {subset}: {sub_data.shape[0]} cells selected.\")\n    else:\n        sub_data = data\n\n    # Helper function to parse coordinate strings from the ROI CSV.\n    def parse_roi_points(all_points):\n        return np.array(\n            re.findall(r'\\d+\\.?\\d+', all_points), dtype=float\n        ).reshape(-1, 2)\n\n    # Function to create an ellipse patch from four vertex points.\n    def ellipse_points_to_patch(vertex_1, vertex_2, co_vertex_1, co_vertex_2):\n        v_and_co_v = np.array([vertex_1, vertex_2, co_vertex_1, co_vertex_2])\n        centers = v_and_co_v.mean(axis=0)\n        d = sdistance.cdist(v_and_co_v, v_and_co_v, metric='euclidean')\n        width = d[0, 1]\n        height = d[2, 3]\n        vector_2 = v_and_co_v[1] - v_and_co_v[0]\n        vector_2 /= np.linalg.norm(vector_2)\n        angle = np.degrees(np.arccos([1, 0] @ vector_2))\n        ellipse_patch = mpatches.Ellipse(centers, width=width, height=height, angle=angle)\n        return ellipse_patch\n\n    # Function to retrieve a matplotlib patch corresponding to the ROI type.\n    def get_mpatch(roi_row):\n        points = parse_roi_points(roi_row['all_points'])\n        roi_type = roi_row['type']\n        if roi_type in ['Point', 'Line']:\n            roi_mpatch = mpatches.Polygon(points, closed=False)\n        elif roi_type in ['Rectangle', 'Polygon', 'Polyline']:\n            roi_mpatch = mpatches.Polygon(points, closed=True)\n        elif roi_type == 'Ellipse':\n            roi_mpatch = ellipse_points_to_patch(*points)\n        else:\n            raise ValueError(\"Unrecognized ROI type: {}\".format(roi_type))\n        return roi_mpatch\n\n    # Build a dictionary mapping each ROI Id to its corresponding shapely Polygon.\n    main_polys = {}\n    unique_ids = roi['Id'].unique()\n    if verbose:\n        print(f\"[INFO] Found {len(unique_ids)} unique ROIs to process.\")\n    for roi_id in unique_ids:\n        roi_row = roi[roi['Id'] == roi_id].iloc[0]\n        points = parse_roi_points(roi_row['all_points'])\n        try:\n            poly = Polygon(points)\n        except Exception as e:\n            raise ValueError(\"Error creating polygon for ROI {}: {}\".format(roi_row[naming_column], e))\n        main_polys[roi_id] = poly\n\n    # Main ROI assignment: assign each spatial coordinate to its corresponding ROI.\n    def add_roi_internal(roi_id):\n        roi_subset = roi[roi['Id'] == roi_id].iloc[0]\n        roi_mpatch = get_mpatch(roi_subset)\n        inside = sub_data[roi_mpatch.contains_points(sub_data[[x_coordinate, y_coordinate]])].copy()\n        inside['ROI_internal'] = roi_subset[naming_column]\n        return inside\n\n    if verbose:\n        print(\"[INFO] Assigning cells to main ROIs...\")\n    main_roi_list = Parallel(n_jobs=n_jobs, verbose=verbose)(\n        delayed(add_roi_internal)(roi_id=i) for i in unique_ids\n    )\n    final_roi = pd.concat(main_roi_list)[['ROI_internal']]\n    # Aggregate overlapping main ROI assignments into a composite label.\n    final_roi = final_roi.groupby(final_roi.index).agg(\n        {'ROI_internal': lambda x: '_'.join(sorted(set(x)))}\n    )\n    if verbose:\n        print(f\"[INFO] Main ROI assignment complete: {final_roi.shape[0]} cells assigned.\")\n\n    # If buffering is requested, compute border ROIs for eligible regions.\n    if buffer_roi &gt; 0:\n        if verbose:\n            print(\"[INFO] Buffering enabled. Computing border ROIs...\")\n        half_buffer = buffer_roi / 2.0\n\n        def add_border_roi(roi_row):\n            # Determine whether this ROI should be buffered.\n            if buffer_regions is not None:\n                allowed = buffer_regions if isinstance(buffer_regions, list) else [buffer_regions]\n                if roi_row[naming_column] not in allowed:\n                    return pd.DataFrame(columns=['ROI_internal'])\n            roi_id = roi_row['Id']\n            poly = main_polys[roi_id]\n            try:\n                inner = poly.buffer(-half_buffer)\n            except Exception:\n                inner = poly  # If inward buffering fails, revert to original polygon.\n            outer = poly.buffer(half_buffer)\n            border_poly = outer.difference(inner)\n            # Enforce a minimum 1-pixel gap from other ROIs.\n            other_polys = [main_polys[other_id].buffer(1) for other_id in main_polys if other_id != roi_id]\n            if other_polys:\n                union_other = unary_union(other_polys)\n                border_poly = border_poly.difference(union_other)\n            border_indices = []\n            for idx, row in sub_data.iterrows():\n                pt = Point(row[x_coordinate], row[y_coordinate])\n                if border_poly.contains(pt):\n                    border_indices.append(idx)\n            df_border = pd.DataFrame(index=border_indices)\n            df_border['ROI_internal'] = str(roi_row[naming_column]) + '_border'\n            return df_border\n\n        border_roi_list = Parallel(n_jobs=n_jobs, verbose=verbose)(\n            delayed(add_border_roi)(roi_row) for idx, roi_row in roi.drop_duplicates('Id').iterrows()\n        )\n        border_df = pd.concat(border_roi_list)\n        if verbose:\n            print(f\"[INFO] Border ROI assignment complete: {border_df.shape[0]} cells assigned to border regions.\")\n        # Exclude cells already assigned a main ROI.\n        border_df = border_df[~border_df.index.isin(final_roi.index)]\n        # Aggregate overlapping border ROI assignments.\n        border_df = border_df.groupby(border_df.index).agg(\n            {'ROI_internal': lambda x: '_'.join(sorted(set(x)))}\n        )\n\n\n    # -------------------------------\n    # Handle label assignment\n    # -------------------------------\n\n    # 1) Normalize subset\n    if subset is not None:\n        subset_ids = [subset] if isinstance(subset, str) else list(subset)\n    else:\n        subset_ids = adata.obs[imageid].unique().tolist()\n    subset_idx = adata.obs.index[adata.obs[imageid].isin(subset_ids)]\n\n    # 2) Ensure label column exists\n    if label not in adata.obs.columns:\n        adata.obs[label] = pd.NA\n\n    # 3) Build a combined mapping: main ROIs + border ROIs (border overrides)\n    mapping_main = final_roi['ROI_internal']\n    if buffer_roi &gt; 0:\n        mapping_border = border_df['ROI_internal']\n        # concat then keep last (border) where overlapping\n        mapping = pd.concat([mapping_main, mapping_border])\n        mapping = mapping[~mapping.index.duplicated(keep='last')]\n    else:\n        mapping = mapping_main\n\n    # 4) Restrict to this subset and drop NAs\n    mapping = mapping.reindex(subset_idx).dropna()\n\n    if overwrite:\n        # -- your existing overwrite=True code --\n        adata.obs[label] = pd.NA\n        new_labels = pd.Series(\"Other\", index=subset_idx)\n        new_labels.update(mapping)\n        adata.obs.loc[subset_idx, label] = new_labels\n    else:\n        # *** now correctly append both ROI and ROI_border labels ***\n        adata.obs.loc[mapping.index, label] = mapping.values\n\n    if verbose:\n        total = len(subset_idx)\n        n_roi = mapping.size\n        action = \"Overwrote\" if overwrite else \"Appended\"\n        print(f\"[INFO] {action} ROI labels in {n_roi}/{total} cells of {subset_ids}.\")\n\n\n\n\n    # Generate summary statistics on ROI assignments.\n    roi_counts = adata.obs[label].value_counts()\n    if verbose:\n        print(\"[INFO] ROI assignment summary:\")\n        print(roi_counts.to_string())\n        print(f\"[INFO] Total cells annotated: {adata.obs[label].notnull().sum()}\")\n\n    return adata\n</code></pre>"},{"location":"Functions/hl/animate/","title":"animate","text":"<p>Short Description</p> <p><code>sm.hl.animate</code>: This function creates dynamic animations transitioning between  UMAP embeddings and physical X and Y coordinates, offering a visual bridge between  abstract and physical data representations. Given varying computer configurations and  execution environments (such as Jupyter notebooks), real-time animation playback may  experience performance issues or may not display properly. Therefore, it is strongly advised  to save animations to disk. Note that saving requires <code>imagemagick</code> installed on your system.  Installation instructions for <code>imagemagick</code> can be found  at: https://imagemagick.org/script/download.php</p>"},{"location":"Functions/hl/animate/#scimap.helpers.animate--function","title":"Function","text":""},{"location":"Functions/hl/animate/#scimap.helpers.animate.animate","title":"<code>animate(adata, color=None, palette=None, embedding='umap', x_coordinate='X_centroid', y_coordinate='Y_centroid', flip_y=True, imageid='imageid', subset=None, layer=None, use_raw=False, log=False, subsample=None, random_state=0, n_frames=50, interval=50, reverse=True, final_frame=5, s=None, alpha=1, cmap='vlag', tight_layout=True, plot_legend=False, title=None, fontsize=20, watermark=True, figsize=(5, 5), pltStyle=None, verbose=True, save_animation=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The annotated data object to be visualized.</p> required <code>color</code> <code>list</code> <p>Identifiers for annotations or genes to color the animation. Accepts a single annotation name. </p> <code>None</code> <code>palette</code> <code>dict</code> <p>Custom color mapping for categorical annotations. Unspecified categories are automatically colored. </p> <code>None</code> <code>embedding</code> <code>str</code> <p>Specifies the UMAP embedding label in <code>adata.obsm</code>. </p> <code>'umap'</code> <code>x_coordinate,</code> <code>y_coordinate (str</code> <p>Columns in <code>adata.obs</code> for spatial coordinates. Defaults are 'X_centroid' and 'Y_centroid', respectively.</p> required <code>flip_y</code> <code>bool</code> <p>Whether to invert the Y-axis, useful if the Y-coordinates appear flipped. </p> <code>True</code> <code>imageid</code> <code>str</code> <p>Column name in <code>adata.obs</code> that identifies unique images, for datasets containing multiple images. </p> <code>'imageid'</code> <code>subset</code> <code>list</code> <p>Identifiers for specific images to visualize, used in conjunction with <code>imageid</code>.</p> <code>None</code> <code>layer</code> <code>str</code> <p>Specifies a layer in <code>adata.layers</code> to use for the animation. Default is None, using <code>adata.X</code>.</p> <code>None</code> <code>use_raw</code> <code>bool</code> <p>Whether to use data from <code>adata.raw.X</code> for coloring. </p> <code>False</code> <code>log</code> <code>bool</code> <p>Applies natural log transformation to the data if True. </p> <code>False</code> <code>subsample</code> <code>float</code> <p>Fraction of data to randomly subsample for large datasets, between 0-1. </p> <code>None</code> <code>random_state</code> <code>int</code> <p>Seed for the random number generator, ensuring reproducibility. </p> <code>0</code> <code>n_frames</code> <code>int</code> <p>Number of frames between UMAP and spatial coordinates, affecting animation smoothness. </p> <code>50</code> <code>interval</code> <code>int</code> <p>Time interval between frames in milliseconds. </p> <code>50</code> <code>reverse</code> <code>bool</code> <p>If True, includes a reverse transition from UMAP to spatial coordinates. </p> <code>True</code> <code>final_frame</code> <code>int</code> <p>Number of frames to display the final frame, enhancing visualization. </p> <code>5</code> <code>s</code> <code>int</code> <p>Marker size in points. </p> <code>None</code> <code>alpha</code> <code>float</code> <p>Opacity of markers, between 0 (transparent) and 1 (opaque). </p> <code>1</code> <code>cmap</code> <code>str</code> <p>Colormap for continuous variables. </p> <code>'vlag'</code> <code>tight_layout</code> <code>bool</code> <p>Adjusts subplot padding, ensuring visibility of legends. </p> <code>True</code> <code>plot_legend</code> <code>bool</code> <p>Whether to display the legend. </p> <code>False</code> <code>title</code> <code>bool or str</code> <p>Adds a title to the plot. Custom titles can be specified. </p> <code>None</code> <code>fontsize</code> <code>int</code> <p>Font size for the title. </p> <code>20</code> <code>watermark</code> <code>bool</code> <p>Displays a 'made with scimap' watermark. </p> <code>True</code> <code>figsize</code> <code>tuple</code> <p>Figure dimensions in inches. </p> <code>(5, 5)</code> <code>pltStyle</code> <code>str</code> <p>Matplotlib plot style to use. </p> <code>None</code> <code>save_animation</code> <code>str</code> <p>File path to save the animation. Saving is recommended for optimal viewing. </p> <code>None</code> <code>**kwargs</code> <p>Additional matplotlib parameters.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Animation</code> <p>An interactive animation or saved file illustrating the dynamic transition.</p> Example <pre><code># Run UMAP\nadata = sm.tl.umap(adata)\n\n# Basic animation with default UMAP and spatial coordinates\nsm.hl.animate(adata)\n\n# Customized animation with specific cell-type coloring and reverse transition\nsm.hl.animate(adata, color='cell_type', reverse=False, save_animation='umap_to_spatial.gif')\n\n# Animation with a subset of images, using custom palette and increased frame interval\nsm.hl.animate(adata, color='condition', palette={'Control': '#1f77b4', 'Treated': '#ff7f0e'}, \n        subset='image_01', interval=100, save_animation='custom_animation.gif')\n</code></pre> Source code in <code>scimap/helpers/animate.py</code> <pre><code>def animate (adata, color=None,\n             palette=None,\n             embedding='umap', \n             x_coordinate='X_centroid', \n             y_coordinate='Y_centroid',\n             flip_y=True,\n             imageid='imageid', \n             subset=None,\n             layer=None, \n             use_raw=False, \n             log=False,\n             subsample=None,\n             random_state=0,\n             n_frames=50, \n             interval=50,\n             reverse=True,\n             final_frame=5, \n             s=None, \n             alpha=1,  \n             cmap='vlag',\n             tight_layout=True,\n             plot_legend=False,\n             title=None, \n             fontsize=20,\n             watermark=True,\n             figsize=(5,5), \n             pltStyle=None,\n             verbose=True,\n             save_animation=None,**kwargs):\n    \"\"\"\nParameters:\n    adata (anndata.AnnData):   \n        The annotated data object to be visualized.\n\n    color (list, optional):  \n        Identifiers for annotations or genes to color the animation. Accepts a single annotation name. \n\n    palette (dict, optional):  \n        Custom color mapping for categorical annotations. Unspecified categories are automatically colored. \n\n    embedding (str, optional):  \n        Specifies the UMAP embedding label in `adata.obsm`. \n\n    x_coordinate, y_coordinate (str, optional):  \n        Columns in `adata.obs` for spatial coordinates. Defaults are 'X_centroid' and 'Y_centroid', respectively.\n\n    flip_y (bool, optional):  \n        Whether to invert the Y-axis, useful if the Y-coordinates appear flipped. \n\n    imageid (str, optional):  \n        Column name in `adata.obs` that identifies unique images, for datasets containing multiple images. \n\n    subset (list, optional):  \n        Identifiers for specific images to visualize, used in conjunction with `imageid`.\n\n    layer (str, optional):  \n        Specifies a layer in `adata.layers` to use for the animation. Default is None, using `adata.X`.\n\n    use_raw (bool, optional):  \n        Whether to use data from `adata.raw.X` for coloring. \n\n    log (bool, optional):  \n        Applies natural log transformation to the data if True. \n\n    subsample (float, optional):  \n        Fraction of data to randomly subsample for large datasets, between 0-1. \n\n    random_state (int, optional):  \n        Seed for the random number generator, ensuring reproducibility. \n\n    n_frames (int, optional):  \n        Number of frames between UMAP and spatial coordinates, affecting animation smoothness. \n\n    interval (int, optional):  \n        Time interval between frames in milliseconds. \n\n    reverse (bool, optional):  \n        If True, includes a reverse transition from UMAP to spatial coordinates. \n\n    final_frame (int, optional):  \n        Number of frames to display the final frame, enhancing visualization. \n\n    s (int, optional):  \n        Marker size in points. \n\n    alpha (float, optional):  \n        Opacity of markers, between 0 (transparent) and 1 (opaque). \n\n    cmap (str, optional):  \n        Colormap for continuous variables. \n\n    tight_layout (bool, optional):  \n        Adjusts subplot padding, ensuring visibility of legends. \n\n    plot_legend (bool, optional):  \n        Whether to display the legend. \n\n    title (bool or str, optional):  \n        Adds a title to the plot. Custom titles can be specified. \n\n    fontsize (int, optional):  \n        Font size for the title. \n\n    watermark (bool, optional):  \n        Displays a 'made with scimap' watermark. \n\n    figsize (tuple, optional):  \n        Figure dimensions in inches. \n\n    pltStyle (str, optional):  \n        Matplotlib plot style to use. \n\n    save_animation (str, optional):  \n        File path to save the animation. Saving is recommended for optimal viewing. \n\n    **kwargs : Additional matplotlib parameters.\n\n\nReturns:\n        Animation:  \n            An interactive animation or saved file illustrating the dynamic transition.\n\nExample:\n    ```python\n\n    # Run UMAP\n    adata = sm.tl.umap(adata)\n\n    # Basic animation with default UMAP and spatial coordinates\n    sm.hl.animate(adata)\n\n    # Customized animation with specific cell-type coloring and reverse transition\n    sm.hl.animate(adata, color='cell_type', reverse=False, save_animation='umap_to_spatial.gif')\n\n    # Animation with a subset of images, using custom palette and increased frame interval\n    sm.hl.animate(adata, color='condition', palette={'Control': '#1f77b4', 'Treated': '#ff7f0e'}, \n            subset='image_01', interval=100, save_animation='custom_animation.gif')\n\n    ```\n\n    \"\"\"\n\n\n\n    # intrapolation function between co-ordinate sytems\n    def tween(e1, e2, n_frames, final_frame):\n\n        # number of frame to pop\n        #n_frames = int(n_frames + (n_frames*0.3))\n        for i in range(5):\n            yield e1\n        for i in range(n_frames):\n            alpha = i / float(n_frames - 1)\n            yield (1 - alpha) * e1 + alpha * e2\n        for i in range(final_frame):\n            yield e2\n\n        return\n\n\n    # check if umap tool has been run\n    try:\n        adata.obsm[embedding]\n    except KeyError:\n        raise KeyError(\"Please run `sm.tl.umap(adata)` first\")\n\n    # identify the coordinates\n    umap_coordinates = pd.DataFrame(adata.obsm[embedding],index=adata.obs.index, columns=['umap-1','umap-2'])\n    real_coordinates = adata.obs[[x_coordinate,y_coordinate]]\n\n    # other data that the user requests\n    if color is not None:\n        if isinstance(color, str):\n            color = [color]\n\n        # identify if all elemets of color are available        \n        if len(color) &gt; 1:\n            raise ValueError(\"Only a single value in `color` is supported\")\n\n        # identify if all elemets of color are available        \n        if set(color).issubset(list(adata.var.index) + list(adata.obs.columns)) is False:\n            raise ValueError(\"Element passed to `color` is not found in adata, please check!\")\n\n        # organise the data\n        if any(item in color for item in list(adata.obs.columns)):\n            adataobs = adata.obs.loc[:, adata.obs.columns.isin(color)]\n        else:\n            adataobs = None\n\n        if any(item in color for item in list(adata.var.index)):\n            # find the index of the marker\n            marker_index = np.where(np.isin(list(adata.var.index), color))[0]\n            if layer is not None:\n                adatavar = adata.layers[layer][:, np.r_[marker_index]]\n            elif use_raw is True:\n                adatavar = adata.raw.X[:, np.r_[marker_index]]\n            else:\n                adatavar = adata.X[:, np.r_[marker_index]]\n            adatavar = pd.DataFrame(adatavar, index=adata.obs.index, columns = list(adata.var.index[marker_index]))\n        else:\n            adatavar = None\n\n        # combine all color data\n        if adataobs is not None and adatavar is not None:\n            color_data = pd.concat ([adataobs, adatavar], axis=1)\n        elif adataobs is not None and adatavar is None:\n            color_data = adataobs\n            # convert to string\n            color_data[color] = color_data[color].astype('category')\n        elif adataobs is None and adatavar is not None:\n            color_data = adatavar    \n\n    else:\n        color_data = None\n\n    # combine color data with umap coordinates\n    if color_data is not None:\n        final_data = pd.concat([umap_coordinates, real_coordinates, color_data], axis=1)\n    else:\n        final_data = umap_coordinates\n\n    # subset the final data if nedded\n    if subset is not None:\n        if isinstance(subset, str):\n            subset = [subset]\n        cell_to_keep = adata[adata.obs[imageid].isin(subset)].obs.index\n        final_data = final_data.loc[cell_to_keep]\n\n    # subsample the data if user requests\n    if subsample is not None:\n        final_data = final_data.sample(frac=subsample, replace=False, random_state=random_state)\n\n    # extract the spaces\n    e1 = final_data[['umap-1', 'umap-2']].values.astype(float)\n    e2 = final_data[[x_coordinate,y_coordinate]].values.astype(float)\n\n\n    # rescale to same co-ordinates system\n    e1[:, 0] -= (max(e1[:, 0]) + min(e1[:, 0])) / 2\n    e1[:, 1] -= (max(e1[:, 1]) + min(e1[:, 1])) / 2\n    # scale\n    scale = max(max(e1[:, 0]) - min(e1[:, 0]), max(e1[:, 1]) - min(e1[:, 1]))\n    e1[:, 0] /= scale\n    e1[:, 1] /= scale\n    # Translate\n    e1[:, 0] += 0.5\n    e1[:, 1] += 0.5\n\n    # rescale co-ordinates\n    e2[:, 0] -= (max(e2[:, 0]) + min(e2[:, 0])) / 2\n    e2[:, 1] -= (max(e2[:, 1]) + min(e2[:, 1])) / 2\n    # scale\n    scale = max(max(e2[:, 0]) - min(e2[:, 0]), max(e2[:, 1]) - min(e2[:, 1]))\n    e2[:, 0] /= scale\n    e2[:, 1] /= scale\n    # Translate\n    e2[:, 0] += 0.5\n    e2[:, 1] += 0.5\n\n    # remove the identified indeces\n    def delete_multiple_element(list_object, indices):\n        indices = sorted(indices, reverse=True)\n        for idx in indices:\n            if idx &lt; len(list_object):\n                list_object.pop(idx)\n\n    # run the interpolation\n    interpolation = list(tween(e1, e2, n_frames=n_frames, final_frame=final_frame))\n    # drop x number of frames\n    top_frames = int(n_frames + 5)\n\n    l = np.percentile(range(5,top_frames),30); h = np.percentile(range(5,top_frames),80)\n    index_between = list(range(int(l), int(h)))\n    numElems = int(len(index_between) * 0.5)\n    drop = np.round(np.linspace(0, len(index_between) - 1, numElems)).astype(int)\n    drop_index = [index_between[i] for i in drop] \n\n    # delete frames\n    delete_multiple_element(interpolation, drop_index)\n\n    top20 = np.percentile(range(5,top_frames),20); top30 = np.percentile(range(5,top_frames),30)\n    bottom80 = np.percentile(range(5,top_frames),80); bottom90 = np.percentile(range(5,top_frames),90)\n\n    ib_top = list(range(int(top20), int(top30)))\n    ib_bottom = list(range(int(bottom80), int(bottom90)))\n    ib = ib_top + ib_bottom\n    numElems2 = int(len(ib) * 0.20)\n    drop2 = np.round(np.linspace(0, len(ib) - 1, numElems2)).astype(int)\n    di = [ib[i] for i in drop2] \n    # delete frames\n    delete_multiple_element(interpolation, di)\n\n    top10 = np.percentile(range(5,top_frames),10); top19 = np.percentile(range(5,top_frames),19)\n    bottom91 = np.percentile(range(5,top_frames),91); bottom95 = np.percentile(range(5,top_frames),95)\n\n    ib_top = list(range(int(top10), int(top19)))\n    ib_bottom = list(range(int(bottom91), int(bottom95)))\n    ib = ib_top + ib_bottom\n    numElems2 = int(len(ib) * 0.10)\n    drop2 = np.round(np.linspace(0, len(ib) - 1, numElems2)).astype(int)\n    di = [ib[i] for i in drop2] \n    # delete frames\n    delete_multiple_element(interpolation, di)\n\n\n\n\n    if reverse is True:\n        interpolation = interpolation + interpolation[::-1]\n\n    # generate colors\n    if s is None:\n        s = 130000 / final_data.shape[0]\n\n    # if there are categorical data then assign colors to them\n    if final_data.select_dtypes(exclude=[\"number\",\"bool_\",\"object_\"]).shape[1] &gt; 0:\n        # find all categories in the dataframe\n        cat_data = final_data.select_dtypes(exclude=[\"number\",\"bool_\",\"object_\"])\n        # find all categories\n        all_cat = []\n        for i in cat_data.columns:\n            all_cat.append(list(cat_data[i].cat.categories))\n\n        # generate colormapping for all categories\n        less_9 = [colors.rgb2hex(x) for x in sns.color_palette('Set1')]\n        nineto20 = [colors.rgb2hex(x) for x in sns.color_palette('tab20')]\n        greater20 = [colors.rgb2hex(x) for x in sns.color_palette('gist_ncar', max([len(i) for i in all_cat]))]\n\n        all_cat_colormap = dict()\n        for i in range(len(all_cat)):\n            if len(all_cat[i]) &lt;= 9:\n                dict1 = dict(zip(all_cat[i] , less_9[ : len(all_cat[i]) ]   ))\n            elif len(all_cat[i]) &gt; 9 and len(all_cat[i]) &lt;= 20:\n                dict1 = dict(zip(all_cat[i] , nineto20[ : len(all_cat[i]) ]   ))\n            else:\n                dict1 = dict(zip(all_cat[i] , greater20[ : len(all_cat[i]) ]   ))\n            all_cat_colormap.update(dict1)\n\n        # if user has passed in custom colours update the colors\n        if palette is not None:\n            all_cat_colormap.update(palette)\n    else:\n        all_cat_colormap = None\n\n    # number of plots\n    nplots = len(final_data.columns) - 4 # total number of plots\n    if nplots &gt; 0:\n        column_to_plot = [e for e in list(final_data.columns) if e not in ('umap-1', 'umap-2',x_coordinate,y_coordinate)][0]\n        if all_cat_colormap is not None:\n            custom_color = list(final_data[column_to_plot].map(all_cat_colormap).values)\n\n\n    # plot\n    plt.rcdefaults()\n    if pltStyle is not None:\n        plt.style.use(pltStyle)\n    fig, ax = plt.subplots(figsize=figsize)\n\n\n    ax.set(xlim=(-0.1, 1.1), ylim=(-0.1, 1.1))\n    if flip_y is True:\n        ax.invert_yaxis()\n\n\n\n    if nplots == 0:\n        scat = ax.scatter(x = interpolation[0][:, 0], y = interpolation[0][:, 1], s=s, cmap=cmap, alpha=alpha, **kwargs)\n        plt.tick_params(right= False,top= False,left= False, bottom= False)\n        ax.get_xaxis().set_ticks([]); ax.get_yaxis().set_ticks([])\n        if watermark is True:\n            ax.text(1.08, 1.08, \"made with scimap.xyz\",horizontalalignment=\"right\",\n            verticalalignment=\"bottom\", alpha=0.5,fontsize=fontsize * 0.4)\n        if title is True: \n            plt.title(column_to_plot, fontsize=fontsize)\n        elif isinstance(title, str):\n            plt.title(title, fontsize=fontsize)  \n        if tight_layout is True:\n            plt.tight_layout()\n\n    if nplots &gt; 0:\n        if all_cat_colormap is None:\n            scat = ax.scatter(x = interpolation[0][:, 0], y = interpolation[0][:, 1], s=s, \n                           c=final_data[column_to_plot],\n                           cmap=cmap, alpha=alpha, **kwargs)\n            if plot_legend is True:\n                plt.colorbar(scat, ax=ax)\n        else:\n            scat = ax.scatter(x = interpolation[0][:, 0], y = interpolation[0][:, 1], s=s, \n                           c=custom_color,\n                           cmap=cmap, alpha=alpha, **kwargs)\n            # create legend\n            if plot_legend is True:\n                patchList = []\n                for key in list(final_data[column_to_plot].unique()):\n                    data_key = mpatches.Patch(color=all_cat_colormap[key], label=key)\n                    patchList.append(data_key)    \n                    ax.legend(handles=patchList,bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n\n        if title is True: \n            plt.title(column_to_plot, fontsize=fontsize)\n        elif isinstance(title, str):\n            plt.title(title, fontsize=fontsize) \n        if watermark is True:\n            ax.text(1.08, 1.08, \"made with scimap.xyz\",horizontalalignment=\"right\",\n            verticalalignment=\"bottom\", alpha=0.5,fontsize=fontsize * 0.4)\n        plt.tick_params(right= False,top= False,left= False, bottom= False)\n        ax.set(xticklabels = ([])); ax.set(yticklabels = ([]))\n        if tight_layout is True:\n            plt.tight_layout()\n\n\n\n    def animate(i):\n        scat.set_offsets(interpolation[i])\n\n    anim = FuncAnimation(fig, animate, interval=interval, frames=len(interpolation)-1)\n\n\n\n    if save_animation is not None:\n        if verbose:\n            print ('Saving file- This can take several minutes to hours for large files')\n        anim.save( save_animation + '_scimap.gif', writer='imagemagick', fps=24)\n\n    # save animation\n    #anim.save('/Users/aj/Downloads/filename.mp4')\n\n    return plt.show(anim, block=False)\n</code></pre>"},{"location":"Functions/hl/classify/","title":"classify","text":"<p>Short Description</p> <p><code>sm.hl.classify</code>: This utility function enables users to annotate cells by assessing  the presence or absence of specific markers. It offers flexibility to apply classifications  across the entire dataset or within previously defined subsets, such as phenotyped or  clustered cell groups, facilitating targeted analyses based on marker expression.</p>"},{"location":"Functions/hl/classify/#scimap.helpers.classify--function","title":"Function","text":""},{"location":"Functions/hl/classify/#scimap.helpers.classify.classify","title":"<code>classify(adata, pos=None, neg=None, classify_label='passed_classify', failed_label='failed_classify', phenotype=None, subclassify_phenotype=None, threshold=0.5, collapse_failed=True, label='classify', showPhenotypeLabel=False, verbose=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The annotated data matrix for classification.</p> required <code>pos</code> <code>list</code> <p>Markers that should be expressed in the cells of interest.</p> <code>None</code> <code>neg</code> <code>list</code> <p>Markers that should not be expressed in the cells of interest.</p> <code>None</code> <code>classify_label</code> <code>str</code> <p>Label for cells that meet the classification criteria.</p> <code>'passed_classify'</code> <code>failed_label</code> <code>str</code> <p>Label for cells that do not meet the classification criteria.</p> <code>'failed_classify'</code> <code>phenotype</code> <code>str, required if subclassify_phenotype or collapse_failed is used</code> <p>Column in <code>adata.obs</code> containing the phenotype information.</p> <code>None</code> <code>subclassify_phenotype</code> <code>list</code> <p>Phenotypes within which classification should be performed.</p> <code>None</code> <code>threshold</code> <code>float</code> <p>Threshold for determining positive or negative expression.</p> <code>0.5</code> <code>collapse_failed</code> <code>bool</code> <p>If True, unclassified cells are grouped under a single failed label.</p> <code>True</code> <code>label</code> <code>str</code> <p>Key under which classification results are stored in <code>adata.obs</code>.</p> <code>'classify'</code> <code>showPhenotypeLabel</code> <code>bool</code> <p>If True, appends classification status to existing phenotype labels in the results. If True, classification results will instead be stored under \"[phenotype]_[label]\" key in  <code>adata.obs</code></p> <code>False</code> <code>verbose</code> <code>bool</code> <p>If True, prints progress and informational messages during the classification process.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>The input AnnData object, updated with classification results in <code>adata.obs[label]</code>.</p> Example <pre><code># Basic classification with positive and negative markers\nadata = sm.hl.classify(adata, pos=['CD3D', 'CD8A'], neg=['PDGFRB'], label='T_cell_classification')\n\n# Classify specific phenotypes, preserving original phenotype labels for unclassified cells\nadata = sm.hl.classify(adata, pos=['CD19'], neg=['CD3D'], subclassify_phenotype=['B cells'],\n                 phenotype='cell_type', collapse_failed=False, label='B_cell_subclassification')\n\n# Use showPhenotypeLabel to append classification status to existing phenotype labels\nadata = sm.hl.classify(adata, pos=['CD34'], neg=['CD45'], phenotype='cell_type',\n                 showPhenotypeLabel=True, label='stem_cell_classification', verbose=True)\n</code></pre> Source code in <code>scimap/helpers/classify.py</code> <pre><code>def classify (adata, \n              pos=None, \n              neg=None, \n              classify_label='passed_classify', \n              failed_label='failed_classify',\n              phenotype=None,\n              subclassify_phenotype=None,\n              threshold = 0.5,\n              collapse_failed=True,\n              label=\"classify\",\n              showPhenotypeLabel=False,\n              verbose=True):\n\n    \"\"\"\nParameters:\n        adata (anndata.AnnData):  \n            The annotated data matrix for classification.\n\n        pos (list, optional):  \n            Markers that should be expressed in the cells of interest.\n\n        neg (list, optional):  \n            Markers that should not be expressed in the cells of interest.\n\n        classify_label (str, optional):  \n            Label for cells that meet the classification criteria.\n\n        failed_label (str, optional):  \n            Label for cells that do not meet the classification criteria.\n\n        phenotype (str, required if subclassify_phenotype or collapse_failed is used):  \n            Column in `adata.obs` containing the phenotype information.\n\n        subclassify_phenotype (list, optional):  \n            Phenotypes within which classification should be performed.\n\n        threshold (float, optional):  \n            Threshold for determining positive or negative expression.\n\n        collapse_failed (bool, optional):  \n            If True, unclassified cells are grouped under a single failed label.\n\n        label (str, optional):  \n            Key under which classification results are stored in `adata.obs`.\n\n        showPhenotypeLabel (bool, optional):  \n            If True, appends classification status to existing phenotype labels in the results. If True, classification\n              results will instead be stored under \"[phenotype]_[label]\" key in  `adata.obs`\n\n        verbose (bool, optional):  \n            If True, prints progress and informational messages during the classification process.\n\nReturns:\n        adata (anndata.AnnData):  \n            The input AnnData object, updated with classification results in `adata.obs[label]`.\n\nExample:\n    ```python\n\n    # Basic classification with positive and negative markers\n    adata = sm.hl.classify(adata, pos=['CD3D', 'CD8A'], neg=['PDGFRB'], label='T_cell_classification')\n\n    # Classify specific phenotypes, preserving original phenotype labels for unclassified cells\n    adata = sm.hl.classify(adata, pos=['CD19'], neg=['CD3D'], subclassify_phenotype=['B cells'],\n                     phenotype='cell_type', collapse_failed=False, label='B_cell_subclassification')\n\n    # Use showPhenotypeLabel to append classification status to existing phenotype labels\n    adata = sm.hl.classify(adata, pos=['CD34'], neg=['CD45'], phenotype='cell_type',\n                     showPhenotypeLabel=True, label='stem_cell_classification', verbose=True)\n\n    ```\n    \"\"\"\n    # clean the input\n    if isinstance(pos, str):\n        pos = [pos]\n    if isinstance(neg, str):\n        neg = [neg]\n    if phenotype is not None:\n        if isinstance(subclassify_phenotype, str):\n            subclassify_phenotype = [subclassify_phenotype]\n        if (showPhenotypeLabel):\n            phenotype_label=phenotype+\"_\"+label\n    elif phenotype is None:\n         if isinstance(subclassify_phenotype, str) or (showPhenotypeLabel): \n            raise TypeError(\"You must pass a column name to the PHENOTYPE argument in order to use `subclassify_phenotype` or to set `showPhenotypeLabel = True`\")\n\n\n    # Create a dataFrame with the necessary inforamtion\n    data = pd.DataFrame(adata.X, index= adata.obs.index, columns = adata.var.index)\n\n    # if user requests to subset a specific phenotype   \n    if subclassify_phenotype is not None:\n        meta = pd.DataFrame(adata.obs[phenotype])\n        subset_index = meta[meta[phenotype].isin(subclassify_phenotype)].index\n        data = data.loc[subset_index]\n\n    # Subset cells that pass the pos criteria\n    if pos is not None:\n        for i in pos:\n            data = data[data[i] &gt;= threshold]\n\n    # Subset cells that pass the neg criteria \n    if neg is not None and not data.empty:\n        for j in neg:\n            data = data[data[j] &lt; threshold]\n\n    # Cells that passed the classify criteria\n    if data.empty:\n        raise TypeError(\"No cells were found to satisfy your `classify` criteria\")\n    else:\n        # create new naming scheme for label and phenotype_label cols in classified\n        classify_idx=data.index\n        if showPhenotypeLabel is True:\n            non_summary = pd.DataFrame({phenotype: adata.obs[phenotype]}) # gets the index and phenotype\n            non_summary[phenotype] = non_summary[phenotype].astype(str)\n\n            classified = pd.DataFrame(non_summary.loc[data.index]) #subsets phenotype rows to only classified cells\n\n            classified[phenotype_label] = classified[phenotype]+\"_\"+classify_label # add phenotype_label col\n            classified.drop([phenotype], axis='columns', inplace=True) # drop phenotype col, for merge        \n        else:\n            classified=pd.DataFrame(np.repeat(classify_label, len(classify_idx)),index= classify_idx, columns=[label]) # add label col\n\n\n\n    if collapse_failed is True: \n        if showPhenotypeLabel is True:\n            meta = non_summary # has index and phenotype col\n        else:\n            meta = pd.DataFrame(index= adata.obs.index)\n\n        meta = meta.merge(classified, how='outer', left_index=True, right_index=True) # gain classified col(s) and NaNs for non-matches\n\n        if showPhenotypeLabel is True:\n            meta[phenotype_label]= meta[phenotype_label].fillna(meta[phenotype].astype(str)+\"_\"+failed_label)\n            meta=meta[phenotype_label]\n        else: \n            meta[label]=meta[label].fillna(failed_label)\n            meta=meta[label]\n\n\n    else:\n        if phenotype is None:\n            raise ValueError(\"Please pass a column name to the PHENOTYPE argument\")\n\n        if showPhenotypeLabel is True: \n            meta=non_summary # phenotype col\n            classified=pd.DataFrame({phenotype: classified[phenotype_label]}) # takes phenotype_label col and renames to phenotype, ensures it's a df\n            meta.update(classified) # updates with phenotype_label for only the classified cells\n        else:\n            meta= pd.DataFrame(adata.obs[phenotype])\n            meta = meta[phenotype].astype(\"object\")\n            classified = pd.DataFrame(np.repeat(classify_label, len(classify_idx)), index = classify_idx, columns = [phenotype])\n            classified = classified[phenotype].astype(\"object\")\n            meta.update(classified) # updates with label for only the classified cells\n\n\n    # Add to Anndata \n    meta = meta.reindex(adata.obs.index)\n    if showPhenotypeLabel is True:\n        adata.obs[phenotype_label]=meta\n    else:\n        adata.obs[label]=meta \n    # return\n    return adata\n</code></pre>"},{"location":"Functions/hl/dropFeatures/","title":"dropFeatures","text":"<p>Short Description</p> <p><code>sm.hl.dropFeatures</code>: This versatile function streamlines the process of  refining an AnnData object by enabling users to selectively remove markers,  cells, metadata columns, and specific cell groups. It facilitates targeted  dataset curation, ensuring analyses are performed on relevant and clean data subsets.</p>"},{"location":"Functions/hl/dropFeatures/#scimap.helpers.dropFeatures--function","title":"Function","text":""},{"location":"Functions/hl/dropFeatures/#scimap.helpers.dropFeatures.dropFeatures","title":"<code>dropFeatures(adata, drop_markers=None, drop_cells=None, drop_meta_columns=None, drop_groups=None, groups_column=None, subset_raw=True, verbose=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix or path to an AnnData object, containing spatial gene expression data.</p> required <code>drop_markers</code> <code>list</code> <p>A list of gene or marker names to be removed from <code>adata.var</code>. </p> <code>None</code> <code>drop_cells</code> <code>list</code> <p>A list of cell identifiers (index names) to be removed from <code>adata.obs</code>. </p> <code>None</code> <code>drop_meta_columns</code> <code>list</code> <p>A list of metadata column names to be removed from <code>adata.obs</code>. </p> <code>None</code> <code>drop_groups</code> <code>list</code> <p>A list of category names to be removed based on the column specified by <code>groups_column</code>. </p> <code>None</code> <code>groups_column</code> <code>str</code> <p>The name of the column in <code>adata.obs</code> that contains the categorical data for <code>drop_groups</code>. </p> <code>None</code> <code>subset_raw</code> <code>bool</code> <p>If True, the same dropping operations are applied to <code>adata.raw</code>.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>If True, print messages about the dropping process. </p> <code>True</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>The AnnData object after the specified features have been removed.</p> Example <pre><code># Example 1: Drop specific markers from the dataset\nadata = sm.hl.dropFeatures(adata, drop_markers=['CD3D', 'CD19'])\n\n# Example 2: Remove cells based on their identifiers\nadata = sm.hl.dropFeatures(adata, drop_cells=['cell_001', 'cell_002'])\n\n# Example 3: Remove metadata columns from adata.obs\nadata = sm.hl.dropFeatures(adata, drop_meta_columns=['Batch', 'Condition'])\n\n# Example 4: Exclude specific groups from a categorical column in adata.obs\nadata = sm.hl.dropFeatures(adata, drop_groups=['B cell', 'NK cell'], groups_column='Cell_Type')\n</code></pre> Source code in <code>scimap/helpers/dropFeatures.py</code> <pre><code>def dropFeatures (adata, \n                  drop_markers=None, \n                  drop_cells=None, \n                  drop_meta_columns=None,\n                  drop_groups=None, \n                  groups_column=None,\n                  subset_raw=True,\n                  verbose=True):\n    \"\"\"\nParameters:\n        adata (anndata.AnnData):  \n            Annotated data matrix or path to an AnnData object, containing spatial gene expression data.\n\n        drop_markers (list, optional):  \n            A list of gene or marker names to be removed from `adata.var`. \n\n        drop_cells (list, optional):  \n            A list of cell identifiers (index names) to be removed from `adata.obs`. \n\n        drop_meta_columns (list, optional):  \n            A list of metadata column names to be removed from `adata.obs`. \n\n        drop_groups (list, optional):  \n            A list of category names to be removed based on the column specified by `groups_column`. \n\n        groups_column (str, optional):  \n            The name of the column in `adata.obs` that contains the categorical data for `drop_groups`. \n\n        subset_raw (bool, optional):  \n            If True, the same dropping operations are applied to `adata.raw`.\n\n        verbose (bool, optional):  \n            If True, print messages about the dropping process. \n\nReturns:\n        adata (anndata.AnnData):  \n            The AnnData object after the specified features have been removed.\n\nExample:\n        ```python\n        # Example 1: Drop specific markers from the dataset\n        adata = sm.hl.dropFeatures(adata, drop_markers=['CD3D', 'CD19'])\n\n        # Example 2: Remove cells based on their identifiers\n        adata = sm.hl.dropFeatures(adata, drop_cells=['cell_001', 'cell_002'])\n\n        # Example 3: Remove metadata columns from adata.obs\n        adata = sm.hl.dropFeatures(adata, drop_meta_columns=['Batch', 'Condition'])\n\n        # Example 4: Exclude specific groups from a categorical column in adata.obs\n        adata = sm.hl.dropFeatures(adata, drop_groups=['B cell', 'NK cell'], groups_column='Cell_Type')\n\n        ```\n\n    \"\"\"\n\n    # Drop Markers\n    if drop_markers is not None:\n        if isinstance(drop_markers, str):\n            drop_markers = [drop_markers]\n        # find the index of the given markers\n        idx_markers = [adata.var.index.get_loc(x) for x in drop_markers]\n        # remove from adata\n        keep_markes = list(set(adata.var.index).difference(drop_markers))\n        adata = adata[:, keep_markes]\n        # remove from raw\n        if subset_raw is True:\n            raw = np.delete(adata.raw.X, idx_markers, axis=1)\n            del adata.raw\n            adata.raw = ad.AnnData (raw)\n\n    # Drop cells\n    if drop_cells is not None:\n        if isinstance(drop_cells, str):\n            drop_cells = [drop_cells]\n        # find the index of the given markers\n        idx_markers = [adata.obs.index.get_loc(x) for x in drop_cells]\n        # remove from adata\n        keep_markes = list(set(adata.obs.index).difference(drop_cells))\n        adata = adata[keep_markes, :]\n        # remove from raw\n        if subset_raw is True:\n            raw = np.delete(adata.raw.X, idx_markers, axis=1)\n            del adata.raw\n            adata.raw = ad.AnnData (raw)\n\n    # Drop meta columns\n    if drop_meta_columns is not None:\n        if isinstance(drop_meta_columns, str):\n            drop_meta_columns = [drop_meta_columns]\n        # remove from adata\n        adata.obs = adata.obs.drop(drop_meta_columns, axis=1)\n\n    # Drop specific categories of cells\n    if drop_groups is not None:\n        if isinstance(drop_groups, str):\n            drop_groups = [drop_groups]\n        if isinstance(groups_column, list):\n            groups_column = groups_column[0]\n        # find the index of the given markers\n        idx = adata[adata.obs[groups_column].isin(drop_groups)].obs.index\n        idx_markers = [adata.obs.index.get_loc(x) for x in idx]\n        # remove from raw\n        if subset_raw is True:\n            raw = np.delete(adata.raw.X, idx_markers, axis=0)\n        # remove from adata\n        adata = adata[~adata.obs[groups_column].isin(drop_groups)]\n        # return adata raw\n        if subset_raw is True:\n            del adata.raw\n            adata.raw = ad.AnnData (raw)\n\n\n    # return\n    return adata\n</code></pre>"},{"location":"Functions/hl/merge_adata_obs/","title":"merge_adata_obs","text":"<p>Short Description</p> <p><code>sm.pl.merge_adata_obs</code>: This function is designed to consolidate multiple AnnData  objects originating from the same image or dataset into a single cohesive unit.  It is particularly useful when each object contains distinct metadata in <code>.obs</code>,  such as results from various clustering algorithms executed in parallel.  By merging these objects, users can streamline analyses and comparisons within  a unified framework. It's important to note that this function is intended for  merging objects from the same source and may not be suitable for combining  data across different images or datasets.</p>"},{"location":"Functions/hl/merge_adata_obs/#scimap.helpers.merge_adata_obs--function","title":"Function","text":""},{"location":"Functions/hl/merge_adata_obs/#scimap.helpers.merge_adata_obs.merge_adata_obs","title":"<code>merge_adata_obs(adata, output_dir=None, verbose=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>list of anndata.AnnData or list of str</code> <p>A list containing AnnData objects to be merged or paths to AnnData files.  Each item in the list should either be an AnnData object already loaded into memory  or a string representing the path to an AnnData file.</p> required <code>output_dir</code> <code>str</code> <p>The directory where the merged AnnData object should be saved.  If specified, the merged object is saved to this directory as 'merged_adata.h5ad'. If not specified, the merged AnnData object is not automatically saved to disk.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If True, prints messages about the renaming process. </p> <code>True</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>A single AnnData object resulting from the merger of input AnnData objects or files.</p> Example <pre><code># Example 1: Merge AnnData objects already loaded in memory\ncombined_adata = sm.hl.merge_adata_obs(adata=[adata1, adata2])\n\n# Example 2: Merge AnnData objects from file paths\ncombined_adata = sm.hl.merge_adata_obs(adata=['./data/adata1.h5ad', './data/adata2.h5ad'])\n\n# Example 3: Merge AnnData objects and save the combined object to a specified directory\ncombined_adata = sm.hl.merge_adata_obs(adata=[adata1, adata2], output_dir='./merged_data')\n</code></pre> Source code in <code>scimap/helpers/merge_adata_obs.py</code> <pre><code>def merge_adata_obs (adata, \n                     output_dir=None,\n                     verbose=True):\n\n\n    \"\"\"\nParameters:\n        adata (list of anndata.AnnData or list of str):  \n            A list containing AnnData objects to be merged or paths to AnnData files. \n            Each item in the list should either be an AnnData object already loaded into memory \n            or a string representing the path to an AnnData file.\n\n        output_dir (str, optional):  \n            The directory where the merged AnnData object should be saved. \n            If specified, the merged object is saved to this directory as 'merged_adata.h5ad'.\n            If not specified, the merged AnnData object is not automatically saved to disk.\n\n        verbose (bool, optional):  \n            If True, prints messages about the renaming process. \n\nReturns:\n        adata (anndata.AnnData):  \n            A single AnnData object resulting from the merger of input AnnData objects or files.\n\nExample:\n        ```python\n\n        # Example 1: Merge AnnData objects already loaded in memory\n        combined_adata = sm.hl.merge_adata_obs(adata=[adata1, adata2])\n\n        # Example 2: Merge AnnData objects from file paths\n        combined_adata = sm.hl.merge_adata_obs(adata=['./data/adata1.h5ad', './data/adata2.h5ad'])\n\n        # Example 3: Merge AnnData objects and save the combined object to a specified directory\n        combined_adata = sm.hl.merge_adata_obs(adata=[adata1, adata2], output_dir='./merged_data')\n\n        ```\n    \"\"\"\n\n    #adata = [\"/Users/aj/Downloads/mcmicro_output.h5ad\", \"/Users/aj/Downloads/mcmicro_output_1.h5ad\"]\n\n\n    # Convert to list of anndata objects\n    if isinstance (adata, list):\n        adata = adata\n    else:\n        adata = [adata]\n\n    # Resoluve the OBS and UNS section\n    if isinstance(adata[0], str):\n        df = pd.DataFrame()\n        uns_count = []\n        for i in adata:\n            tmp = ad.read_h5ad(i)\n            # OBS\n            tmp_df = tmp.obs\n            df = pd.concat([df, tmp_df], axis=1)\n            # UNS\n            uns_count.append(len(tmp.uns))\n        # Keep non-duplicate obs columns\n        df = df.loc[:,~df.columns.duplicated()]\n        # Highest UNS\n        uns_index = [i for i, j in enumerate(uns_count) if j == max(uns_count)][0]\n    else:\n        df = pd.DataFrame()\n        uns_count = []\n        for i in adata:\n            # OBS\n            tmp_df = i.obs\n            df = pd.concat([df, tmp_df], axis=1)\n            # UNS\n            uns_count.append(len(i.uns))\n        # Keep non-duplicate obs columns\n        df = df.loc[:,~df.columns.duplicated()]\n        # Highest UNS\n        uns_index = [i for i, j in enumerate(uns_count) if j == max(uns_count)][0]\n\n\n    # create the final anndata object\n    # Load the data \n    if isinstance(adata[0], str):\n        final_adata = ad.read_h5ad(adata[uns_index])\n    else:\n        final_adata = adata[uns_index]\n\n    # reindex\n    df = df.reindex (final_adata.obs.index)\n\n    # replace obs\n    final_adata.obs = df\n\n\n    # Save data if requested\n    if output_dir is not None:\n        output_dir = pathlib.Path(output_dir)\n        output_dir.mkdir(exist_ok=True, parents=True)\n        final_adata.write(output_dir / 'combined_adata.h5ad')\n    else:    \n        # Return data\n        return final_adata\n</code></pre>"},{"location":"Functions/hl/rename/","title":"rename","text":"<p>Short Description</p> <p><code>sm.hl.rename</code>: This function offers a straightforward way to rename specific  categories within a chosen column of an AnnData object, with the new names  being stored in a separate column. It streamlines the process of updating or  consolidating category labels for enhanced data clarity and analysis.</p>"},{"location":"Functions/hl/rename/#scimap.helpers.rename--function","title":"Function","text":""},{"location":"Functions/hl/rename/#scimap.helpers.rename.rename","title":"<code>rename(adata, rename, from_column='phenotype', to_column='phenotype_renamed', verbose=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix or path to an AnnData object, containing spatial gene expression data.</p> required <code>rename</code> <code>dict</code> <p>A dictionary mapping existing category names (values) to new category names (keys).  Each key corresponds to the new name, and its value is a list of existing names to be consolidated under this new name.</p> required <code>from_column</code> <code>str</code> <p>The name of the column in <code>adata.obs</code> where the categories to be renamed are located. Defaults to 'phenotype'.</p> <code>'phenotype'</code> <code>to_column</code> <code>str</code> <p>The name of the new column in <code>adata.obs</code> where the renamed categories will be stored. Defaults to 'phenotype_renamed'.</p> <code>'phenotype_renamed'</code> <code>verbose</code> <code>bool</code> <p>If True, prints messages about the renaming process. </p> <code>True</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>The AnnData object after applying the renaming operation, with the newly named categories stored in the specified <code>adata.obs[to_column]</code>.</p> Example <pre><code># Example 1: Simplify phenotype labels\nrename_dict = {'tumor': ['cd45 neg tumor', 'cd8 tumor', 'cd4 tumor'],\n               'macrophages': ['m1 macrophages', 'm2 macrophages']}\nadata = sm.hl.rename(adata, rename=rename_dict, from_column='phenotype', to_column='simplified_phenotype')\n\n# Example 2: Merge similar phenotypes under a common name\nmerge_dict = {'immune cells': ['cd45+', 't-cells', 'b-cells']}\nadata = sm.hl.rename(adata, rename=merge_dict, from_column='cell_type', to_column='merged_cell_type')\n\n# Example 3: Rename and create a new column for easier identification\nnew_names = {'activated': ['activated_tcells', 'activated_bcells'],\n             'resting': ['resting_tcells', 'resting_bcells']}\nadata = sm.hl.rename(adata, rename=new_names, from_column='status', to_column='status_simplified')\n</code></pre> Source code in <code>scimap/helpers/rename.py</code> <pre><code>def rename (adata, \n            rename, \n            from_column='phenotype', \n            to_column='phenotype_renamed',\n            verbose=True):\n    \"\"\"\nParameters:\n        adata (anndata.AnnData):  \n            Annotated data matrix or path to an AnnData object, containing spatial gene expression data.\n\n        rename (dict):  \n            A dictionary mapping existing category names (values) to new category names (keys). \n            Each key corresponds to the new name, and its value is a list of existing names to be consolidated under this new name.\n\n        from_column (str, optional):  \n            The name of the column in `adata.obs` where the categories to be renamed are located. Defaults to 'phenotype'.\n\n        to_column (str, optional):  \n            The name of the new column in `adata.obs` where the renamed categories will be stored. Defaults to 'phenotype_renamed'.\n\n        verbose (bool, optional):  \n            If True, prints messages about the renaming process. \n\nReturns:\n        adata (anndata.AnnData):  \n            The AnnData object after applying the renaming operation, with the newly named categories stored in the specified `adata.obs[to_column]`.\n\nExample:\n    ```python\n\n    # Example 1: Simplify phenotype labels\n    rename_dict = {'tumor': ['cd45 neg tumor', 'cd8 tumor', 'cd4 tumor'],\n                   'macrophages': ['m1 macrophages', 'm2 macrophages']}\n    adata = sm.hl.rename(adata, rename=rename_dict, from_column='phenotype', to_column='simplified_phenotype')\n\n    # Example 2: Merge similar phenotypes under a common name\n    merge_dict = {'immune cells': ['cd45+', 't-cells', 'b-cells']}\n    adata = sm.hl.rename(adata, rename=merge_dict, from_column='cell_type', to_column='merged_cell_type')\n\n    # Example 3: Rename and create a new column for easier identification\n    new_names = {'activated': ['activated_tcells', 'activated_bcells'],\n                 'resting': ['resting_tcells', 'resting_bcells']}\n    adata = sm.hl.rename(adata, rename=new_names, from_column='status', to_column='status_simplified')\n\n    ```\n    \"\"\"\n\n    # Sanity check: if the values are not list convert them into list\n    for i in rename:\n        if isinstance(rename[i], str):\n            rename[i] = [rename[i]]\n\n    # Get the from_column\n    rename_from = list(adata.obs[from_column].values)\n\n    # Split multiple renaming events into independent events\n    name = functools.reduce( lambda x,y: dict(x, **y), (dict(map(lambda x: (x,i), rename[i])) for i in rename))\n\n    # Rename\n    for i in name:\n        if verbose:\n            print ('Renaming ' + str(i) + ' to ' + str(name[i]))\n        #rename_from = [x.replace(i, name[i]) for x in rename_from]\n        s = str(i)\n        s = s.replace('+', '\\+')\n        #rename_from = [re.sub(r'^\\b%s\\b$' % s,  name[i], j) for j in rename_from]\n        rename_from = [re.sub(r'^\\b%s$' % s,  name[i], j) for j in rename_from]\n\n\n    # Append to adata as a new column\n    adata.obs[to_column] = rename_from\n\n    # Return\n    return adata\n</code></pre>"},{"location":"Functions/hl/scimap_to_csv/","title":"scimap_to_csv","text":"<p>Short Description</p> <p><code>sm.hl.scimap_to_csv</code>: This utility function facilitates exporting the contents of a  <code>scimap</code> object (AnnData) to a CSV file, combining gene expression data from  <code>adata.X</code> or <code>adata.raw.X</code> with cell metadata from <code>adata.obs</code>.  It provides a streamlined way to save and share data for further analysis or  documentation. Note that the export focuses on the expression matrix and  associated cell annotations. It does not export information saved in <code>adata.uns</code></p>"},{"location":"Functions/hl/scimap_to_csv/#scimap.helpers.scimap_to_csv--function","title":"Function","text":""},{"location":"Functions/hl/scimap_to_csv/#scimap.helpers.scimap_to_csv.scimap_to_csv","title":"<code>scimap_to_csv(adata, layer='raw', output_dir=None, file_name=None, CellID='CellID', verbose=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The annotated data matrix to export.</p> required <code>layer</code> <code>str</code> <p>Specifies the layer to export: - 'raw': Exports the raw data. - 'log': Exports the data after applying a log transformation with <code>np.log1p</code>. - 'None': Exports the data  in <code>adata.X</code></p> <code>'raw'</code> <code>output_dir</code> <code>str</code> <p>The directory where the CSV file will be saved. If not specified, the file is saved in the current working directory.</p> <code>None</code> <code>file_name</code> <code>str</code> <p>The name of the output CSV file. If not provided, a default name <code>scimap_to_csv_file.csv</code> is used.</p> <code>None</code> <code>CellID</code> <code>str</code> <p>The column name in the output CSV file that will contain the Cell IDs.</p> <code>'CellID'</code> <code>verbose</code> <code>bool</code> <p>If True, prints messages about the export process.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>DataFrame</code> <code>csv</code> <p>The function does not return a value but saves the specified data to a CSV file in the designated directory.</p> Example <pre><code>    # Export raw data to CSV\n    sm.hl.scimap_to_csv(adata, layer='raw', output_dir='/path/to/save', file_name='raw_data.csv')\n\n    # Export log-transformed data to CSV, with a custom CellID column name\n    sm.hl.scimap_to_csv(adata, layer='log', output_dir='/path/to/save', file_name='log_data.csv', CellID='UniqueCellID')\n\n    # Export scaled data to Cobject\n    data = sm.hl.scimap_to_csv(adata, layer='scaled')\n</code></pre> Source code in <code>scimap/helpers/scimap_to_csv.py</code> <pre><code>def scimap_to_csv(\n    adata, layer='raw', output_dir=None, file_name=None, CellID='CellID', verbose=True\n):\n    \"\"\"\n    Parameters:\n            adata (anndata.AnnData):\n                The annotated data matrix to export.\n\n            layer (str, optional):\n                Specifies the layer to export:\n                - 'raw': Exports the raw data.\n                - 'log': Exports the data after applying a log transformation with `np.log1p`.\n                - 'None': Exports the data  in `adata.X`\n\n            output_dir (str, optional):\n                The directory where the CSV file will be saved. If not specified, the file is saved in the current working directory.\n\n            file_name (str, optional):\n                The name of the output CSV file. If not provided, a default name `scimap_to_csv_file.csv` is used.\n\n            CellID (str, optional):\n                The column name in the output CSV file that will contain the Cell IDs.\n\n            verbose (bool, optional):\n                If True, prints messages about the export process.\n\n    Returns:\n            DataFrame (csv):\n                The function does not return a value but saves the specified data to a CSV file in the designated directory.\n\n    Example:\n        ```python\n\n            # Export raw data to CSV\n            sm.hl.scimap_to_csv(adata, layer='raw', output_dir='/path/to/save', file_name='raw_data.csv')\n\n            # Export log-transformed data to CSV, with a custom CellID column name\n            sm.hl.scimap_to_csv(adata, layer='log', output_dir='/path/to/save', file_name='log_data.csv', CellID='UniqueCellID')\n\n            # Export scaled data to Cobject\n            data = sm.hl.scimap_to_csv(adata, layer='scaled')\n\n        ```\n    \"\"\"\n\n    # Load the andata object\n    if isinstance(adata, str):\n        if file_name is None:\n            imid = str(adata.rsplit('/', 1)[-1])\n        else:\n            imid = str(file_name)\n        adata = ad.read_h5ad(adata)\n    else:\n        if file_name is None:\n            imid = \"scimap_to_csv_file.csv\"\n        else:\n            imid = str(file_name)\n        adata = adata\n\n    # Expression matrix\n    if layer == 'raw':\n        data = pd.DataFrame(adata.raw.X, index=adata.obs.index, columns=adata.var.index)\n    elif layer is None:\n        data = pd.DataFrame(adata.X, index=adata.obs.index, columns=adata.var.index)\n    else:\n        data = pd.DataFrame(\n            adata.layers[layer], index=adata.obs.index, columns=adata.var.index\n        )\n\n    # =============================================================================\n    #     # Expression matrix\n    #     if data_type == 'raw':\n    #         data = pd.DataFrame(adata.raw.X, index=adata.obs.index, columns=adata.var.index)\n    #     if data_type == 'log':\n    #         data = pd.DataFrame(np.log1p(adata.raw.X), index=adata.obs.index, columns=adata.var.index)\n    #     if data_type == 'scaled':\n    #         data = pd.DataFrame(adata.X, index=adata.obs.index, columns=adata.var.index)\n    # =============================================================================\n\n    # Metadata\n    meta = pd.DataFrame(adata.obs)\n\n    # Merge the two dataframes\n    merged = pd.concat([data, meta], axis=1, sort=False)\n\n    # Add a column to save cell-id\n    # merged['CellID'] = merged.index\n    # make cellID the first column\n    if CellID in merged.columns:\n        first_column = merged.pop(CellID)\n        merged.insert(0, CellID, first_column)\n    else:\n        merged['CellID'] = merged.index\n        first_column = merged.pop(CellID)\n        merged.insert(0, CellID, first_column)\n\n    # reset index\n    merged = merged.reset_index(drop=True)\n\n    # Save data if requested\n    if output_dir is not None:\n        output_dir = pathlib.Path(output_dir)\n        output_dir.mkdir(exist_ok=True, parents=True)\n        merged.to_csv(output_dir / f'{imid}.csv', index=False)\n    else:\n        # Return data\n        return merged\n</code></pre>"},{"location":"Functions/pl/addROI_image/","title":"addROI_image","text":"<p>Short Description</p> <p><code>sm.pl.addROI_image</code>: This function enhances spatial data analysis by enabling the addition o f Regions of Interest (ROIs) directly onto images within an AnnData object, utilizing the  <code>napari</code> viewer for intuitive graphical interaction. Users can delineate distinct areas such  as 'Tumor', 'Stroma', or 'Tumor-Stromal-interface' on separate <code>shape layers</code> within the viewer,  allowing for detailed spatial annotations.</p> <p>Multiple, non-overlapping annotations within a single shape layer are aggregated  into one ROI, facilitating categorization based on spatial characteristics.  Shape layers can be conveniently renamed to reflect the desired ROI names, ensuring  clarity and specificity in annotations.</p> <p>It's crucial that each ROI is unique and non-overlapping to maintain data integrity. </p> <p>Additionally, this tool serves as a valuable quality control (QC) step, allowing  users to mark regions of varying quality for selective inclusion or exclusion in subsequent analyses.</p>"},{"location":"Functions/pl/addROI_image/#scimap.plotting.addROI_image--function","title":"Function","text":""},{"location":"Functions/pl/addROI_image/#scimap.plotting.addROI_image.addROI_image","title":"<code>addROI_image(image_path, adata, subset=None, imageid='imageid', overlay=None, flip_y=True, overlay_category=None, markers=None, channel_names='default', x_coordinate='X_centroid', y_coordinate='Y_centroid', point_size=10, point_color=None, seg_mask=None, n_jobs=-1, verbose=False, overwrite=True, label='ROI', **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>Path to the image file. Supports TIFF, OME.TIFF, and ZARR formats.</p> required <code>adata</code> <code>AnnData</code> <p>The annotated data matrix to which ROIs will be added.</p> required <code>subset</code> <code>list</code> <p>Specifies the image(s) within <code>adata</code> to annotate. Necessary if <code>adata</code> contains multiple images.</p> <code>None</code> <code>imageid</code> <code>str</code> <p>Column in <code>adata.obs</code> identifying images, for datasets with multiple images.</p> <code>'imageid'</code> <code>overlay</code> <code>str</code> <p>Column in <code>adata.obs</code> with categorical data to overlay on the image, such as cell phenotypes.</p> <code>None</code> <code>flip_y</code> <code>bool</code> <p>If True, inverts the Y-axis to match image coordinates. Default is True.</p> <code>True</code> <code>overlay_category</code> <code>list</code> <p>Specific categories within <code>overlay</code> to visualize. If None, all categories are shown.</p> <code>None</code> <code>markers</code> <code>list</code> <p>Specific markers to display. If None, all available markers are included.</p> <code>None</code> <code>channel_names</code> <code>list or str</code> <p>Names of image channels, in order as they appear in the image. Defaults to markers in <code>adata.uns['all_markers']</code> if 'default'.</p> <code>'default'</code> <code>x_coordinate,</code> <code>y_coordinate (str</code> <p>Column names in <code>adata.obs</code> for cell coordinates. Defaults are 'X_centroid' and 'Y_centroid'.</p> required <code>point_size</code> <code>int</code> <p>Size of points in the visualization.</p> <code>10</code> <code>point_color</code> <code>str</code> <p>Color of points in the visualization. If None, colors are automatically assigned.</p> <code>None</code> <code>seg_mask</code> <code>str</code> <p>Path to a segmentation mask file to be overlaid.</p> <code>None</code> <code>n_jobs</code> <code>int</code> <p>Number of parallel jobs to use. Defaults to -1, using all available cores.</p> <code>-1</code> <code>verbose</code> <code>bool</code> <p>If True, prints messages about the process.</p> <code>False</code> <code>overwrite</code> <code>bool</code> <p>If True, overwrites existing ROI data in <code>adata.obs</code>.</p> <code>True</code> <code>label</code> <code>str</code> <p>Key under which ROI data will be stored in <code>adata.obs</code>.</p> <code>'ROI'</code> <code>**kwargs</code> <p>Additional keyword arguments passed to the napari viewer.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>The AnnData object with updated ROI annotations.</p> Example <pre><code># Add ROIs to an image with specific overlays\nsm.pl.addROI_image(image_path='/path/to/image.ome.tif', adata=adata, overlay='cell_type', label='Detailed_ROI')\n\n# Add ROIs with segmentation masks and specific overlay categories\nsm.pl.addROI_image(image_path='/path/to/image.ome.tif', adata=adata, seg_mask='/path/to/seg_mask.tif',\n             overlay='phenotype', overlay_category=['Tumor', 'Stroma'], label='Cancer_Tissue_ROI')\n</code></pre> Source code in <code>scimap/plotting/addROI_image.py</code> <pre><code>def addROI_image(\n    image_path,\n    adata,\n    subset=None,\n    imageid='imageid',\n    overlay=None,\n    flip_y=True,\n    overlay_category=None,\n    markers=None,\n    channel_names='default',\n    x_coordinate='X_centroid',\n    y_coordinate='Y_centroid',\n    point_size=10,\n    point_color=None,\n    seg_mask=None,\n    n_jobs=-1,\n    verbose=False,\n    overwrite=True,\n    label='ROI',\n    **kwargs,\n):\n    \"\"\"\n    Parameters:\n            image_path (str):\n                Path to the image file. Supports TIFF, OME.TIFF, and ZARR formats.\n\n            adata (anndata.AnnData):\n                The annotated data matrix to which ROIs will be added.\n\n            subset (list, optional):\n                Specifies the image(s) within `adata` to annotate. Necessary if `adata` contains multiple images.\n\n            imageid (str, optional):\n                Column in `adata.obs` identifying images, for datasets with multiple images.\n\n            overlay (str, optional):\n                Column in `adata.obs` with categorical data to overlay on the image, such as cell phenotypes.\n\n            flip_y (bool, optional):\n                If True, inverts the Y-axis to match image coordinates. Default is True.\n\n            overlay_category (list, optional):\n                Specific categories within `overlay` to visualize. If None, all categories are shown.\n\n            markers (list, optional):\n                Specific markers to display. If None, all available markers are included.\n\n            channel_names (list or str, optional):\n                Names of image channels, in order as they appear in the image. Defaults to markers in `adata.uns['all_markers']` if 'default'.\n\n            x_coordinate, y_coordinate (str, optional):\n                Column names in `adata.obs` for cell coordinates. Defaults are 'X_centroid' and 'Y_centroid'.\n\n            point_size (int, optional):\n                Size of points in the visualization.\n\n            point_color (str, optional):\n                Color of points in the visualization. If None, colors are automatically assigned.\n\n            seg_mask (str, optional):\n                Path to a segmentation mask file to be overlaid.\n\n            n_jobs (int, optional):\n                Number of parallel jobs to use. Defaults to -1, using all available cores.\n\n            verbose (bool, optional):\n                If True, prints messages about the process.\n\n            overwrite (bool, optional):\n                If True, overwrites existing ROI data in `adata.obs`.\n\n            label (str, optional):\n                Key under which ROI data will be stored in `adata.obs`.\n\n            **kwargs:\n                Additional keyword arguments passed to the napari viewer.\n\n    Returns:\n            adata (anndata.AnnData):\n                The AnnData object with updated ROI annotations.\n\n    Example:\n        ```python\n\n        # Add ROIs to an image with specific overlays\n        sm.pl.addROI_image(image_path='/path/to/image.ome.tif', adata=adata, overlay='cell_type', label='Detailed_ROI')\n\n        # Add ROIs with segmentation masks and specific overlay categories\n        sm.pl.addROI_image(image_path='/path/to/image.ome.tif', adata=adata, seg_mask='/path/to/seg_mask.tif',\n                     overlay='phenotype', overlay_category=['Tumor', 'Stroma'], label='Cancer_Tissue_ROI')\n\n\n        ```\n    \"\"\"\n\n    # TODO\n    # - ADD Subset markers for ZARR ssection\n    # - Ability to use ZARR metadata if available\n\n    # create data matrix that has the co-ordinates\n    data = pd.DataFrame(adata.obs)[[x_coordinate, y_coordinate, imageid]]\n\n    # subset the data if needed\n    if subset is not None:\n        # convert string to list\n        if isinstance(subset, str):\n            subset = [subset]\n        # subset data\n        sub_data = data[data[imageid].isin(subset)]\n    else:\n        sub_data = data\n\n    # adding option to load just the image without an adata object\n    if adata is None:\n        channel_names = None\n    else:\n        # All operations on the AnnData object is performed first\n        # Plot only the Image that is requested\n        if subset is not None:\n            adata_subset = adata[adata.obs[imageid].isin(subset)]\n        else:\n            adata_subset = adata.copy()\n\n        # Recover the channel names from adata\n        if channel_names == 'default':\n            channel_names = adata_subset.uns['all_markers']\n        else:\n            channel_names = channel_names\n\n        # Index of the marker of interest and corresponding names\n        if markers is None:\n            idx = list(range(len(channel_names)))\n            channel_names = channel_names\n        else:\n            idx = []\n            for i in markers:\n                idx.append(list(channel_names).index(i))\n            channel_names = markers\n\n        # Load the segmentation mask\n        if seg_mask is not None:\n            seg_m = tiff.imread(seg_mask)\n            if (len(seg_m.shape) &gt; 2) and (seg_m.shape[0] &gt; 1):\n                seg_m = seg_m[0]\n\n    # Operations on the OME TIFF image is performed next\n    # check the format of image\n    if os.path.isfile(image_path) is True:\n        image = tiff.TiffFile(image_path, is_ome=False)  # is_ome=False\n        z = zarr.open(image.aszarr(), mode='r')  # convert image to Zarr array\n        # Identify the number of pyramids\n        n_levels = len(image.series[0].levels)  # pyramid\n\n        # If and if not pyramids are available\n        if n_levels &gt; 1:\n            pyramid = [da.from_zarr(z[i]) for i in range(n_levels)]\n            multiscale = True\n        else:\n            pyramid = da.from_zarr(z)\n            multiscale = False\n\n        # subset channels of interest\n        if markers is not None:\n            if n_levels &gt; 1:\n                for i in range(n_levels - 1):\n                    pyramid[i] = pyramid[i][idx, :, :]\n                n_channels = pyramid[0].shape[0]  # identify the number of channels\n            else:\n                pyramid = pyramid[idx, :, :]\n                n_channels = pyramid.shape[0]  # identify the number of channels\n        else:\n            if n_levels &gt; 1:\n                n_channels = pyramid[0].shape[0]\n            else:\n                n_channels = pyramid.shape[0]\n\n        # check if channel names have been passed to all channels\n        if channel_names is not None:\n            assert n_channels == len(channel_names), (\n                f'number of channel names ({len(channel_names)}) must '\n                f'match number of channels ({n_channels})'\n            )\n\n        # Load the viewer\n        viewer = napari.view_image(\n            pyramid,\n            multiscale=multiscale,\n            channel_axis=0,\n            visible=False,\n            name=None if channel_names is None else channel_names,\n            **kwargs,\n        )\n\n    # Operations on the ZARR image\n    # check the format of image\n    if os.path.isfile(image_path) is False:\n        # print(image_path)\n        viewer = napari.Viewer()\n        viewer.open(\n            image_path,\n            multiscale=True,\n            visible=False,\n            name=None if channel_names is None else channel_names,\n        )\n\n    # Add the seg mask\n    if seg_mask is not None:\n        viewer.add_labels(seg_m, name='segmentation mask', visible=False)\n\n    # Add phenotype layer function\n    def add_phenotype_layer(\n        adata, overlay, phenotype_layer, x, y, viewer, point_size, point_color\n    ):\n        coordinates = adata[adata.obs[overlay] == phenotype_layer]\n        # Flip Y AXIS if needed\n        if flip_y is True:\n            coordinates = pd.DataFrame(\n                {'y': coordinates.obs[y], 'x': coordinates.obs[x]}\n            )\n        else:\n            coordinates = pd.DataFrame(\n                {'x': coordinates.obs[x], 'y': coordinates.obs[y]}\n            )\n\n        # points = coordinates.values.tolist()\n        points = coordinates.values\n        if point_color is None:\n            r = lambda: random.randint(0, 255)  # random color generator\n            point_color = '#%02X%02X%02X' % (r(), r(), r())  # random color generator\n        viewer.add_points(\n            points,\n            size=point_size,\n            face_color=point_color,\n            visible=False,\n            name=phenotype_layer,\n        )\n\n    if overlay is not None:\n        # categories under investigation\n        if overlay_category is None:\n            available_phenotypes = list(adata_subset.obs[overlay].unique())\n        else:\n            available_phenotypes = overlay_category\n\n        # Run the function on all phenotypes\n        for i in available_phenotypes:\n            add_phenotype_layer(\n                adata=adata_subset,\n                overlay=overlay,\n                phenotype_layer=i,\n                x=x_coordinate,\n                y=y_coordinate,\n                viewer=viewer,\n                point_size=point_size,\n                point_color=point_color,\n            )\n\n    # Intiate an ROI layer\n    shape_layer = viewer.add_shapes(name=label)\n    shape_layer.mode = 'add_polygon'\n    # _ = show_info('Draw ROIs')\n\n    # helper functions\n    def ellipse_points_to_patch(vertex_1, vertex_2, co_vertex_1, co_vertex_2):\n        \"\"\"\n        Parameters\n        ----------\n        vertex_1, vertex_2, co_vertex_1, co_vertex_2: array like, in the form of (x-coordinate, y-coordinate)\n        \"\"\"\n        v_and_co_v = np.array([vertex_1, vertex_2, co_vertex_1, co_vertex_2])\n        centers = v_and_co_v.mean(axis=0)\n\n        d = sdistance.cdist(v_and_co_v, v_and_co_v, metric='euclidean')\n        width = d[0, 1]\n        height = d[2, 3]\n\n        vector_2 = v_and_co_v[1] - v_and_co_v[0]\n        vector_2 /= np.linalg.norm(vector_2)\n\n        angle = np.degrees(np.arccos([1, 0] @ vector_2))\n\n        ellipse_patch = mpatches.Ellipse(\n            centers, width=width, height=height, angle=angle\n        )\n        return ellipse_patch\n\n    # block the viewer until ROI is added\n    a = \"\"\"\n        Opening Napari;\n        Add shape layers (on left) to draw ROI's. \n        Rename the shape layer to give a name to your ROI\n        Multiple shape layers are supported\n        ROI's should not overlap\n        Close Napari to save ROI's.\n        \"\"\"\n    print(a)\n    viewer.show(block=True)\n\n    # Find all the shape layers\n    my_shapes = [layer for layer in viewer.layers if isinstance(layer, Shapes)]\n    # loop through the layers to find their names\n    shape_names = []\n    added_rois = []\n    for i in my_shapes:\n        shape_names.append(i.name)\n        added_rois.append(len(viewer.layers[i.name].data))\n\n    if any(y &gt; 0 for y in added_rois):\n        # Loop through all the Shape layers and extract the vertices and shape type\n        all_rois = pd.DataFrame()\n        for i in shape_names:\n            # return shape vertices\n            ver = viewer.layers[i].data\n            # return shape shape\n            structure = viewer.layers[i].shape_type\n            # Each layer may contain multiple ROI's with different shapes (handle that)\n            napari_roi_table = pd.DataFrame(\n                dict(\n                    vertices=[np.fliplr(v) for v in ver],\n                    type=[str(s) for s in structure],\n                    ROI=i,\n                )\n            )\n\n            # convert gathered ROIs into mpatches\n            for i in range(len(napari_roi_table.index)):\n                # ellipse\n                if napari_roi_table['type'][i] == 'ellipse':\n                    napari_roi_table.loc[i:, 'mpatch'] = ellipse_points_to_patch(\n                        napari_roi_table['vertices'][i][0],\n                        napari_roi_table['vertices'][i][1],\n                        napari_roi_table['vertices'][i][2],\n                        napari_roi_table['vertices'][i][3],\n                    )\n                # polygon, rectangle, line\n                elif napari_roi_table['type'][i] in ['rectangle', 'polygon', 'path']:\n                    napari_roi_table.loc[i:, 'mpatch'] = mpatches.Polygon(\n                        napari_roi_table['vertices'][i], closed=True\n                    )\n                else:\n                    raise ValueError\n\n            # merge the final ROI's across all shape layers\n            all_rois = pd.concat([all_rois, napari_roi_table])\n            all_rois['id'] = range(all_rois.shape[0])\n            all_rois.index = all_rois['id']\n\n        # Find cells within ROI and add it to the dataframe\n        def add_roi_internal(roi_id):\n            roi_mpatch = all_rois[all_rois['id'] == roi_id]['mpatch'][roi_id]\n            inside = sub_data[\n                roi_mpatch.contains_points(sub_data[[x_coordinate, y_coordinate]])\n            ]\n            inside_copy = inside.copy()\n            inside_copy['ROI_internal'] = all_rois.loc[all_rois['id'] == roi_id, 'ROI'][\n                roi_id\n            ]\n            # inside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n            # return\n            return inside_copy\n\n        print(\"Identifying cells within selected ROI's\")\n        # all ROI cells\n        roi_list = all_rois['id'].unique()\n        # final_roi = list()\n        # for i in roi_list:\n        #    roi_mpatch = all_rois[all_rois['id'] == i]['mpatch'][i]\n        #    inside = sub_data[roi_mpatch.contains_points(sub_data[[x_coordinate, y_coordinate]])]\n        #    inside['ROI_internal'] = all_rois[all_rois['id'] == i]['ROI'][i]\n        #    final_roi.append(inside)\n\n        final_roi = Parallel(n_jobs=n_jobs, verbose=verbose)(\n            delayed(add_roi_internal)(roi_id=i) for i in roi_list\n        )\n\n        # Merge all into a single DF\n        final_roi = pd.concat(final_roi)[['ROI_internal']]\n\n        # Add the list to obs\n        result = pd.merge(\n            data, final_roi, left_index=True, right_index=True, how='outer'\n        )\n\n        # Reindex\n        result = result.reindex(adata.obs.index)\n\n        # check if adata already has a column with the supplied label\n        # if avaialble overwrite or append depending on users choice\n        if label in adata.obs.columns:\n            if overwrite is False:\n                # Append\n                # retreive the ROI information\n                old_roi = adata.obs[label]\n                combined_roi = pd.merge(\n                    result, old_roi, left_index=True, right_index=True, how='outer'\n                )\n                combined_roi['ROI_internal'] = combined_roi['ROI_internal'].fillna(\n                    combined_roi[label]\n                )\n            else:\n                # Over write\n                combined_roi = result.copy()\n                combined_roi['ROI_internal'] = combined_roi['ROI_internal'].fillna(\n                    'Other'\n                )\n        else:\n            # if label is not present just create a new one\n            combined_roi = result.copy()\n            combined_roi['ROI_internal'] = combined_roi['ROI_internal'].fillna('Other')\n\n        # Add to adata\n        adata.obs[label] = combined_roi['ROI_internal']\n\n        print(\"ROIs saved under adata.obs['\" + str(label) + \"']\")\n\n        # return\n        return adata\n</code></pre>"},{"location":"Functions/pl/cluster_plots/","title":"cluster_plots","text":"<p>Short Description</p> <p><code>sm.pl.cluster_plots</code>: This versatile function streamlines the visualization  process by generating UMAP plots, heatmaps of the expression matrix, and  lists of ranked marker genes for each user-defined group, typically following  clustering analysis via <code>sm.tl.cluster</code>. It offers a comprehensive overview of  clustering results, facilitating the exploration of spatial patterns,  molecular profiles, and key markers distinguishing each cluster.</p>"},{"location":"Functions/pl/cluster_plots/#scimap.plotting.cluster_plots--function","title":"Function","text":""},{"location":"Functions/pl/cluster_plots/#scimap.plotting.cluster_plots.cluster_plots","title":"<code>cluster_plots(adata, group_by, subsample=100000, palette='viridis', use_raw=False, size=None, output_dir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The annotated data matrix.</p> required <code>group_by</code> <code>str</code> <p>The column name in <code>adata.obs</code> that contains the clustering labels to visualize.</p> required <code>subsample</code> <code>int</code> <p>The number of cells to randomly subsample from the dataset for visualization to enhance performance. Default is 100000. If set to None, no subsampling is performed.</p> <code>100000</code> <code>palette</code> <code>str</code> <p>The name of a matplotlib colormap to use for coloring clusters. Default is 'viridis'.</p> <code>'viridis'</code> <code>use_raw</code> <code>bool</code> <p>If True, uses the <code>.raw</code> attribute of <code>adata</code> for extracting expression data for the matrix plot. Default is False.</p> <code>False</code> <code>size</code> <code>int</code> <p>The size of the points in the UMAP plot. Default is 40.</p> <code>None</code> <code>output_dir</code> <code>str</code> <p>The directory where the plots should be saved. If not specified, plots are shown but not saved.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>plots</code> <code>matplotlib</code> <p>The function does not return a value but generates and optionally saves the specified plots.</p> Example <pre><code># Generate cluster plots using default settings\nsm.pl.cluster_plots(adata, group_by='leiden')\n\n# Generate cluster plots with a custom palette and subsampling\nsm.pl.cluster_plots(adata, group_by='leiden', palette='plasma', subsample=50000)\n\n# Generate cluster plots without subsampling, using raw data, and save them to a directory\nsm.pl.cluster_plots(adata, group_by='leiden', subsample=None, use_raw=True, output_dir='./cluster_plots')\n</code></pre> Source code in <code>scimap/plotting/cluster_plots.py</code> <pre><code>def cluster_plots(\n    adata,\n    group_by,\n    subsample=100000,\n    palette='viridis',\n    use_raw=False,\n    size=None,\n    output_dir=None,\n):\n    \"\"\"\n    Parameters:\n            adata (anndata.AnnData):\n                The annotated data matrix.\n\n            group_by (str):\n                The column name in `adata.obs` that contains the clustering labels to visualize.\n\n            subsample (int, optional):\n                The number of cells to randomly subsample from the dataset for visualization to enhance performance.\n                Default is 100000. If set to None, no subsampling is performed.\n\n            palette (str, optional):\n                The name of a matplotlib colormap to use for coloring clusters. Default is 'viridis'.\n\n            use_raw (bool, optional):\n                If True, uses the `.raw` attribute of `adata` for extracting expression data for the matrix plot.\n                Default is False.\n\n            size (int, optional):\n                The size of the points in the UMAP plot. Default is 40.\n\n            output_dir (str, optional):\n                The directory where the plots should be saved. If not specified, plots are shown but not saved.\n\n    Returns:\n            plots (matplotlib):\n                The function does not return a value but generates and optionally saves the specified plots.\n\n    Example:\n        ```python\n\n        # Generate cluster plots using default settings\n        sm.pl.cluster_plots(adata, group_by='leiden')\n\n        # Generate cluster plots with a custom palette and subsampling\n        sm.pl.cluster_plots(adata, group_by='leiden', palette='plasma', subsample=50000)\n\n        # Generate cluster plots without subsampling, using raw data, and save them to a directory\n        sm.pl.cluster_plots(adata, group_by='leiden', subsample=None, use_raw=True, output_dir='./cluster_plots')\n\n        ```\n    \"\"\"\n\n    # Load the data\n    if isinstance(adata, str):\n        imid = pathlib.Path(adata).stem\n        adata = ad.read_h5ad(adata)\n    else:\n        adata = adata\n        imid = \"\"\n\n    # Subset data if needed\n    if subsample is not None:\n        if adata.shape[0] &gt; subsample:\n            sc.pp.subsample(adata, n_obs=subsample)\n\n    # UMAP\n    try:\n        sc.pp.neighbors(adata)  # Computing the neighborhood graph\n        sc.tl.umap(adata)\n        fig = sc.pl.umap(\n            adata,\n            color=group_by,\n            palette=palette,\n            size=size,\n            return_fig=True,\n            show=False,\n        )  # View the clustering\n        fig.tight_layout()\n        # save figure\n        if output_dir is not None:\n            output_dir = pathlib.Path(output_dir)\n            output_dir.mkdir(exist_ok=True, parents=True)\n            # fig.savefig(output_dir / f\"{imid}_umap.pdf\")\n            fig.savefig(pathlib.Path(output_dir) / f\"{imid}_umap.pdf\")\n\n    except Exception as exc:\n        print('UMAP could not be generated')\n        print(exc)\n\n    # Matrix plot\n    try:\n        mat_fig = sc.pl.matrixplot(\n            adata,\n            var_names=adata.var.index,\n            groupby=group_by,\n            use_raw=use_raw,\n            cmap='RdBu_r',\n            dendrogram=True,\n            title=group_by,\n            return_fig=True,\n        )\n        if output_dir is not None:\n            # mat_fig.savefig(output_dir / 'matrixplot.pdf')\n            mat_fig.savefig(pathlib.Path(output_dir) / f\"{imid}_matrixplot.pdf\")\n\n    except Exception as exc:\n        print('Heatmap could not be generated')\n        print(exc)\n\n    # Marker expression per group\n    try:\n        sc.tl.rank_genes_groups(adata, group_by, method='t-test')\n\n        # find number of genes in dataset\n        if len(adata.var.index) &gt; 20:\n            n_genes = 20\n        else:\n            n_genes = len(adata.var.index)\n\n        if output_dir is not None:\n            sc.pl.rank_genes_groups(\n                adata, sharey=False, n_genes=n_genes, fontsize=12, show=False\n            )\n            plt.suptitle(group_by, fontsize=20)\n            # plt.savefig(output_dir / 'ranked_markers_per_cluster.pdf')\n            plt.savefig(\n                pathlib.Path(output_dir) / f\"{imid}_ranked_markers_per_cluster.pdf\"\n            )\n        else:\n            sc.pl.rank_genes_groups(adata, sharey=False, n_genes=n_genes, fontsize=12)\n\n    except Exception as exc:\n        print('Finding differential markers per group cannot be completed')\n        print(exc)\n</code></pre>"},{"location":"Functions/pl/densityPlot2D/","title":"densityPlot2D","text":"<p>Short Description</p> <p>The <code>sm.pl.densityPlot2D</code> function crafts 2D density plots to visualize expression  levels of one or two specified markers. When a single marker is provided, it depicts  its expression distribution across the dataset. With two markers, it contrasts the expression  of the first against the second, offering insights into their co-expression or distribution patterns. </p>"},{"location":"Functions/pl/densityPlot2D/#scimap.plotting.densityPlot2D--function","title":"Function","text":""},{"location":"Functions/pl/densityPlot2D/#scimap.plotting.densityPlot2D.densityPlot2D","title":"<code>densityPlot2D(adata, markerA, markerB=None, layer=None, subset=None, imageid='imageid', ncols=None, cmap='jet', figsize=(3, 3), hline='auto', vline='auto', fontsize=None, dpi=100, xticks=None, yticks=None, saveDir=None, fileName='densityPlot2D.pdf')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix containing single-cell gene expression data.</p> required <code>markerA</code> <code>str</code> <p>The name of the first marker whose expression will be plotted.</p> required <code>markerB</code> <code>list</code> <p>The name of the second marker or a list of second markers whose expression will be plotted. If not provided, a 2D density plot of <code>markerA</code> against all markers in the dataset will be plotted.</p> <code>None</code> <code>layer</code> <code>str or list of str</code> <p>The layer in adata.layers that contains the expression data to use. If None, adata.X is used. use <code>raw</code> to use the data stored in <code>adata.raw.X</code></p> <code>None</code> <code>subset</code> <code>list</code> <p><code>imageid</code> of a single or multiple images to be subsetted for plotting purposes.</p> <code>None</code> <code>imageid</code> <code>str</code> <p>Column name of the column containing the image id. Use in conjunction with <code>subset</code>.</p> <code>'imageid'</code> <code>ncols</code> <code>int</code> <p>The number of columns in the grid of density plots.</p> <code>None</code> <code>cmap</code> <code>str</code> <p>The name of the colormap to use. Defaults to 'jet'.</p> <code>'jet'</code> <code>figsize</code> <code>tuple</code> <p>The size of the figure in inches.</p> <code>(3, 3)</code> <code>hline</code> <code>float or auto</code> <p>The y-coordinate of the horizontal line to plot. If set to <code>None</code>, a horizontal line is not plotted. Use 'auto' to draw a vline at the center point.</p> <code>'auto'</code> <code>vline</code> <code>float or auto</code> <p>The x-coordinate of the vertical line to plot. If set to <code>None</code>, a vertical line is not plotted. Use 'auto' to draw a vline at the center point.</p> <code>'auto'</code> <code>fontsize</code> <code>int</code> <p>The size of the font of the axis labels.</p> <code>None</code> <code>dpi</code> <code>int</code> <p>The DPI of the figure. Use this to control the point size. Lower the dpi, larger the point size.</p> <code>100</code> <code>xticks</code> <code>list of float</code> <p>Custom x-axis tick values.</p> <code>None</code> <code>yticks</code> <code>list of float</code> <p>Custom y-axis tick values.</p> <code>None</code> <code>saveDir</code> <code>str</code> <p>The directory to save the output plot.</p> <code>None</code> <code>fileName</code> <code>str</code> <p>The name of the output file. Use desired file format as suffix (e.g. <code>.png</code> or <code>.pdf</code>).</p> <code>'densityPlot2D.pdf'</code> <p>Returns:</p> Name Type Description <code>Plot</code> <code>image</code> <p>If <code>outputDir</code> is not provided, the plot is displayed on the screen. Otherwise, the plot is saved in the provided <code>outputDir</code> directory.</p> Example <pre><code># create a 2D density plot of the expression of 'CD3D' against 'CD8A' in the dataset 'adata'\nsm.pl.densityPlot2D(adata, markerA='CD3D', markerB='CD8A')\n\n# create a 2D density plot of the expression of 'CD3D' against all markers in the dataset 'adata'\nsm.pl.densityPlot2D(adata, markerA='CD3D')\n</code></pre> Source code in <code>scimap/plotting/densityPlot2D.py</code> <pre><code>def densityPlot2D(\n    adata,\n    markerA,\n    markerB=None,\n    layer=None,\n    subset=None,\n    imageid='imageid',\n    ncols=None,\n    cmap='jet',\n    figsize=(3, 3),\n    hline='auto',\n    vline='auto',\n    fontsize=None,\n    dpi=100,\n    xticks=None,\n    yticks=None,\n    saveDir=None,\n    fileName='densityPlot2D.pdf',\n):\n    \"\"\"\n    Parameters:\n        adata (anndata.AnnData):\n            Annotated data matrix containing single-cell gene expression data.\n\n        markerA (str):\n            The name of the first marker whose expression will be plotted.\n\n        markerB (list, optional):\n            The name of the second marker or a list of second markers whose expression will be plotted.\n            If not provided, a 2D density plot of `markerA` against all markers in the dataset will be plotted.\n\n        layer (str or list of str, optional):\n            The layer in adata.layers that contains the expression data to use.\n            If None, adata.X is used. use `raw` to use the data stored in `adata.raw.X`\n\n        subset (list, optional):\n            `imageid` of a single or multiple images to be subsetted for plotting purposes.\n\n        imageid (str, optional):\n            Column name of the column containing the image id. Use in conjunction with `subset`.\n\n        ncols (int, optional):\n            The number of columns in the grid of density plots.\n\n        cmap (str, optional):\n            The name of the colormap to use. Defaults to 'jet'.\n\n        figsize (tuple, optional):\n            The size of the figure in inches.\n\n        hline (float or 'auto', optional):\n            The y-coordinate of the horizontal line to plot. If set to `None`, a horizontal line is not plotted.\n            Use 'auto' to draw a vline at the center point.\n\n        vline (float or 'auto', optional):\n            The x-coordinate of the vertical line to plot. If set to `None`, a vertical line is not plotted.\n            Use 'auto' to draw a vline at the center point.\n\n        fontsize (int, optional):\n            The size of the font of the axis labels.\n\n        dpi (int, optional):\n            The DPI of the figure. Use this to control the point size. Lower the dpi, larger the point size.\n\n        xticks (list of float, optional):\n            Custom x-axis tick values.\n\n        yticks (list of float, optional):\n            Custom y-axis tick values.\n\n        saveDir (str, optional):\n            The directory to save the output plot.\n\n        fileName (str, optional):\n            The name of the output file. Use desired file format as suffix (e.g. `.png` or `.pdf`).\n\n    Returns:\n        Plot (image):\n            If `outputDir` is not provided, the plot is displayed on the screen.\n            Otherwise, the plot is saved in the provided `outputDir` directory.\n\n    Example:\n        ```python\n\n        # create a 2D density plot of the expression of 'CD3D' against 'CD8A' in the dataset 'adata'\n        sm.pl.densityPlot2D(adata, markerA='CD3D', markerB='CD8A')\n\n        # create a 2D density plot of the expression of 'CD3D' against all markers in the dataset 'adata'\n        sm.pl.densityPlot2D(adata, markerA='CD3D')\n        ```\n\n    \"\"\"\n    # testing\n    # import anndata as ad\n    # adata = ad.read(r\"C:\\Users\\aj\\Dropbox (Partners HealthCare)\\nirmal lab\\softwares\\scimap\\scimap\\tests\\_data\\example_data.h5ad\")\n    # adata = ad.read('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/softwares/scimap/scimap/tests/_data/example_data.h5ad')\n    # markerA ='CD3E'; layers=None; markerB='CD163'; plotGrid=True; ncols=None; color=None; figsize=(10, 10); fontsize=None; subset=None; imageid='imageid'; xticks=None; dpi=200; outputDir=None;\n    # hline = 'auto'; vline = 'auto'\n    # outputFileName='densityPlot2D.png'\n    # color = {'markerA': '#000000', 'markerB': '#FF0000'}\n    # outputDir = r\"C:\\Users\\aj\\Downloads\"\n\n    # densityPlot2D (adata, markerA='CD3D', markerB=['CD2', 'CD10', 'CD163'], dpi=50, outputDir=r\"C:\\Users\\aj\\Downloads\")\n\n    # set color\n    # cp = copy.copy(cm.get_cmap(cmap))\n    # cp.set_under(alpha=0)\n\n    cp = copy.copy(plt.colormaps[cmap])\n    cp.set_under(alpha=0)\n\n    # subset data if neede\n    if subset is not None:\n        if isinstance(subset, str):\n            subset = [subset]\n        if layer == 'raw':\n            bdata = adata.copy()\n            bdata.X = adata.raw.X\n            bdata = bdata[bdata.obs[imageid].isin(subset)]\n        else:\n            bdata = adata.copy()\n            bdata = bdata[bdata.obs[imageid].isin(subset)]\n    else:\n        bdata = adata.copy()\n\n    # isolate the data\n    if layer is None:\n        data = pd.DataFrame(bdata.X, index=bdata.obs.index, columns=bdata.var.index)\n    elif layer == 'raw':\n        data = pd.DataFrame(bdata.raw.X, index=bdata.obs.index, columns=bdata.var.index)\n    else:\n        data = pd.DataFrame(\n            bdata.layers[layer], index=bdata.obs.index, columns=bdata.var.index\n        )\n\n    # keep only columns that are required\n    x = data[markerA]\n\n    if markerB is None:\n        y = data.drop(markerA, axis=1)\n    else:\n        if isinstance(markerB, str):\n            markerB = [markerB]\n        y = data[markerB]\n\n    # auto identify rows and columns in the grid plot\n    def calculate_grid_dimensions(num_items, num_columns=None):\n        \"\"\"\n        Calculates the number of rows and columns for a square grid\n        based on the number of items.\n        \"\"\"\n        if num_columns is None:\n            num_rows_columns = int(math.ceil(math.sqrt(num_items)))\n            return num_rows_columns, num_rows_columns\n        else:\n            num_rows = int(math.ceil(num_items / num_columns))\n            return num_rows, num_columns\n\n    # calculate the number of rows and columns\n    num_rows, num_cols = calculate_grid_dimensions(len(y.columns), num_columns=ncols)\n\n    fig, axs = plt.subplots(\n        nrows=num_rows,\n        ncols=num_cols,\n        figsize=(num_cols * figsize[0], num_rows * figsize[0]),\n        subplot_kw={'projection': 'scatter_density'},\n    )\n    if num_rows == 1 and num_cols == 1:\n        axs = [axs]  # wrap single subplot in a list\n    else:\n        axs = axs.flatten()\n    for i, col in enumerate(y.columns):\n        ax = axs[i]\n        ax.scatter_density(\n            x, y[col], dpi=dpi, cmap=cp, norm=LogNorm(vmin=0.5, vmax=x.size)\n        )\n        ax.set_xlabel(markerA, size=fontsize)\n        ax.set_ylabel(col, size=fontsize)\n\n        if hline == 'auto':\n            ax.axhline((y[col].max() + y[col].min()) / 2, color='grey')\n        elif hline is None:\n            pass\n        else:\n            ax.axhline(hline, color='grey')\n\n        if vline == 'auto':\n            ax.axvline((x.max() + x.min()) / 2, color='grey')\n        elif vline is None:\n            pass\n        else:\n            ax.axvline(vline, color='grey')\n\n        # control and x and y ticks\n        if xticks is not None:\n            ax.set_xticks(xticks)\n            ax.set_xticklabels([str(x) for x in xticks])\n\n        if yticks is not None:\n            ax.set_yticks(yticks)\n            ax.set_yticklabels([str(x) for x in yticks])\n\n    # Remove any empty subplots\n    num_plots = len(y.columns)\n    for i in range(num_plots, num_rows * num_cols):\n        ax = axs[i]\n        fig.delaxes(ax)\n\n    plt.tick_params(axis='both', labelsize=fontsize)\n    plt.tight_layout()\n\n    # Save the figure to a file\n    if saveDir:\n        if not os.path.exists(saveDir):\n            os.makedirs(saveDir)\n        full_path = os.path.join(saveDir, fileName)\n        plt.savefig(full_path, dpi=300)\n        plt.close(fig)\n        print(f\"Saved heatmap to {full_path}\")\n    else:\n        plt.show()\n</code></pre>"},{"location":"Functions/pl/distPlot/","title":"distPlot","text":"<p>Short Description</p> <p>The <code>sm.pl.distPlot</code> function is used to create distribution plots of  marker intensity data.</p>"},{"location":"Functions/pl/distPlot/#scimap.plotting.distPlot--function","title":"Function","text":""},{"location":"Functions/pl/distPlot/#scimap.plotting.distPlot.distPlot","title":"<code>distPlot(adata, layer=None, markers=None, subset=None, imageid='imageid', vline=None, plotGrid=True, ncols=None, color=None, xticks=None, figsize=(5, 5), fontsize=None, dpi=200, saveDir=None, fileName='scimapDistPlot.png')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data object.</p> required <code>layer</code> <code>str</code> <p>Layer of data to plot.</p> <code>None</code> <code>markers</code> <code>list</code> <p>List of marker genes to plot.</p> <code>None</code> <code>subset</code> <code>list or None</code> <p><code>imageid</code> of a single or multiple images to be subsetted for plotting purposes.</p> <code>None</code> <code>imageid</code> <code>str</code> <p>The column name in <code>spatial feature table</code> that contains the image ID for each cell.</p> <code>'imageid'</code> <code>vline</code> <code>float or auto</code> <p>The x-coordinate of the vertical line to plot. If set to <code>None</code>, a vertical line is not plotted. Use 'auto' to draw a vline at the center point.</p> <code>None</code> <code>plotGrid</code> <code>bool</code> <p>Whether to plot each marker in it's own sub plot. If <code>False</code> and multiple markers are passed in via <code>markers</code>, all distributions will be plotted within a single plot.</p> <code>True</code> <code>ncols</code> <code>int</code> <p>The number of columns in the final plot when multiple variables are plotted.</p> <code>None</code> <code>color</code> <code>str</code> <p>Color of the distribution plot.</p> <code>None</code> <code>xticks</code> <code>list of float</code> <p>Custom x-axis tick values.</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>Figure size. Defaults to (5, 5).</p> <code>(5, 5)</code> <code>fontsize</code> <code>int</code> <p>The size of the font of the axis labels.</p> <code>None</code> <code>dpi</code> <code>int</code> <p>The DPI of the figure. Use this to control the point size. Lower the dpi, larger the point size.</p> <code>200</code> <code>saveDir</code> <code>str</code> <p>The directory to save the output plot.</p> <code>None</code> <code>fileName</code> <code>str</code> <p>The name of the output file. Use desired file format as suffix (e.g. <code>.png</code> or <code>.pdf</code>).</p> <code>'scimapDistPlot.png'</code> <p>Returns:</p> Name Type Description <code>Plot</code> <code>image</code> <p>If <code>outputDir</code> is provided the plot will saved within the provided outputDir.</p> Example <pre><code>sm.pl.distPlot(adata,\n             layer=None,\n             markers=['CD45','CD3D','CD20'],\n             plotGrid=True,\n             ncols=5)\n</code></pre> Source code in <code>scimap/plotting/distPlot.py</code> <pre><code>def distPlot(\n    adata,\n    layer=None,\n    markers=None,\n    subset=None,\n    imageid='imageid',\n    vline=None,\n    plotGrid=True,\n    ncols=None,\n    color=None,\n    xticks=None,\n    figsize=(5, 5),\n    fontsize=None,\n    dpi=200,\n    saveDir=None,\n    fileName='scimapDistPlot.png',\n):\n    \"\"\"\n    Parameters:\n        adata (anndata.AnnData):\n            Annotated data object.\n\n        layer (str, optional):\n            Layer of data to plot.\n\n        markers (list, optional):\n            List of marker genes to plot.\n\n        subset (list or None, optional):\n            `imageid` of a single or multiple images to be subsetted for plotting purposes.\n\n        imageid (str, optional):\n            The column name in `spatial feature table` that contains the image ID\n            for each cell.\n\n        vline (float or 'auto', optional):\n            The x-coordinate of the vertical line to plot. If set to `None`, a vertical line is not plotted.\n            Use 'auto' to draw a vline at the center point.\n\n        plotGrid (bool, optional):\n            Whether to plot each marker in it's own sub plot. If `False` and multiple markers\n            are passed in via `markers`, all distributions will be plotted within a single plot.\n\n        ncols (int, optional):\n            The number of columns in the final plot when multiple variables are plotted.\n\n        color (str, optional):\n            Color of the distribution plot.\n\n        xticks (list of float, optional):\n            Custom x-axis tick values.\n\n        figsize (tuple, optional):\n            Figure size. Defaults to (5, 5).\n\n        fontsize (int, optional):\n            The size of the font of the axis labels.\n\n        dpi (int, optional):\n            The DPI of the figure. Use this to control the point size. Lower the dpi, larger the point size.\n\n        saveDir (str, optional):\n            The directory to save the output plot.\n\n        fileName (str, optional):\n            The name of the output file. Use desired file format as suffix (e.g. `.png` or `.pdf`).\n\n    Returns:\n        Plot (image):\n            If `outputDir` is provided the plot will saved within the provided outputDir.\n\n    Example:\n            ```python\n\n            sm.pl.distPlot(adata,\n                         layer=None,\n                         markers=['CD45','CD3D','CD20'],\n                         plotGrid=True,\n                         ncols=5)\n            ```\n\n    \"\"\"\n\n    # testing\n    # layers=None; markers=None; plotGrid=True; ncols=None; color=None; figsize=(10, 10); fontsize=None; subset=None; imageid='imageid'; xticks=None; dpi=200; outputDir=None;\n    # outputFileName='distPlot.png'\n    # color = {'markerA': '#000000', 'markerB': '#FF0000'}\n    # outputDir = r\"C:\\Users\\aj\\Downloads\"\n\n    # subset data if neede\n    if subset is not None:\n        if isinstance(subset, str):\n            subset = [subset]\n        if layer == 'raw':\n            bdata = adata.copy()\n            bdata.X = adata.raw.X\n            bdata = bdata[bdata.obs[imageid].isin(subset)]\n        else:\n            bdata = adata.copy()\n            bdata = bdata[bdata.obs[imageid].isin(subset)]\n    else:\n        bdata = adata.copy()\n\n    # isolate the data\n    if layer is None:\n        data = pd.DataFrame(bdata.X, index=bdata.obs.index, columns=bdata.var.index)\n    elif layer == 'raw':\n        data = pd.DataFrame(bdata.raw.X, index=bdata.obs.index, columns=bdata.var.index)\n    else:\n        data = pd.DataFrame(\n            bdata.layers[layer], index=bdata.obs.index, columns=bdata.var.index\n        )\n\n    # keep only columns that are required\n    if markers is not None:\n        if isinstance(markers, str):\n            markers = [markers]\n        # subset the list\n        data = data[markers]\n\n    # auto identify rows and columns in the grid plot\n    def calculate_grid_dimensions(num_items, num_columns=None):\n        \"\"\"\n        Calculates the number of rows and columns for a square grid\n        based on the number of items.\n        \"\"\"\n        if num_columns is None:\n            num_rows_columns = int(math.ceil(math.sqrt(num_items)))\n            return num_rows_columns, num_rows_columns\n        else:\n            num_rows = int(math.ceil(num_items / num_columns))\n            return num_rows, num_columns\n\n    if plotGrid is False:\n        # Create a figure and axis object\n        fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n        # Loop through each column in the DataFrame and plot a KDE with the\n        # user-defined color or the default color (grey)\n        if color is None:\n            for column in data.columns:\n                data[column].plot.kde(ax=ax, label=column)\n        else:\n            for column in data.columns:\n                c = color.get(column, 'grey')\n                data[column].plot.kde(ax=ax, label=column, color=c)\n        ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5), fontsize=fontsize)\n        ax.tick_params(axis='both', which='major', width=1, labelsize=fontsize)\n        plt.tight_layout()\n        if xticks is not None:\n            ax.set_xticks(xticks)\n            ax.set_xticklabels([str(x) for x in xticks])\n\n        if vline == 'auto':\n            ax.axvline((data[column].max() + data[column].min()) / 2, color='black')\n        elif vline is None:\n            pass\n        else:\n            ax.axvline(vline, color='black')\n\n        # save figure\n        if outputDir is not None:\n            plt.savefig(pathlib.Path(outputDir) / outputFileName)\n\n    else:\n        # calculate the number of rows and columns\n        num_rows, num_cols = calculate_grid_dimensions(\n            len(data.columns), num_columns=ncols\n        )\n\n        # set colors\n        if color is None:\n            # Define a color cycle of 10 colors\n            color_cycle = itertools.cycle(\n                plt.rcParams['axes.prop_cycle'].by_key()['color']\n            )\n            # Assign a different color to each column\n            color = {col: next(color_cycle) for col in data.columns}\n\n        # Set the size of the figure\n        fig, axes = plt.subplots(\n            nrows=num_rows, ncols=num_cols, figsize=figsize, dpi=dpi\n        )\n        axes = np.atleast_2d(axes)\n        # Set the spacing between subplots\n        # fig.subplots_adjust(bottom=0.1, hspace=0.1)\n\n        # Loop through each column in the DataFrame and plot a KDE with the\n        # user-defined color or the default color (grey) in the corresponding subplot\n        for i, column in enumerate(data.columns):\n            c = color.get(column, 'grey')\n            row_idx = i // num_cols\n            col_idx = i % num_cols\n            data[column].plot.kde(ax=axes[row_idx, col_idx], label=column, color=c)\n            axes[row_idx, col_idx].set_title(column)\n            axes[row_idx, col_idx].tick_params(\n                axis='both', which='major', width=1, labelsize=fontsize\n            )\n            axes[row_idx, col_idx].set_ylabel('')\n\n            if vline == 'auto':\n                axes[row_idx, col_idx].axvline(\n                    (data[column].max() + data[column].min()) / 2, color='black'\n                )\n            elif vline is None:\n                pass\n            else:\n                axes[row_idx, col_idx].axvline(vline, color='black')\n\n            if xticks is not None:\n                axes[row_idx, col_idx].set_xticks(xticks)\n                axes[row_idx, col_idx].set_xticklabels([str(x) for x in xticks])\n\n        # Remove any empty subplots\n        num_plots = len(data.columns)\n        for i in range(num_plots, num_rows * num_cols):\n            row_idx = i // num_cols\n            col_idx = i % num_cols\n            fig.delaxes(axes[row_idx, col_idx])\n\n        # Set font size for tick labels on both axes\n        plt.tick_params(axis='both', labelsize=fontsize)\n        plt.tight_layout()\n\n        # Save the figure to a file\n        if saveDir:\n            if not os.path.exists(saveDir):\n                os.makedirs(saveDir)\n            full_path = os.path.join(saveDir, fileName)\n            plt.savefig(full_path, dpi=300)\n            plt.close()\n            print(f\"Saved heatmap to {full_path}\")\n        else:\n            plt.show()\n</code></pre>"},{"location":"Functions/pl/foldchange/","title":"foldchange","text":"<p>Short Description</p> <p><code>sm.pl.foldchange</code>: This function facilitates the visualization of fold changes in cell type  abundance across samples or Regions of Interest (ROIs), offering insights into differential  expression or abundance patterns. It is designed to work with data processed by <code>sm.tl.foldchange</code>,  which should be executed beforehand to calculate the fold changes. Through heatmap or parallel  coordinates presentations, users can effectively interpret variations, highlighting significant  shifts and guiding further analyses.</p>"},{"location":"Functions/pl/foldchange/#scimap.plotting.foldchange--function","title":"Function","text":""},{"location":"Functions/pl/foldchange/#scimap.plotting.foldchange.foldchange","title":"<code>foldchange(adata, label='foldchange', p_val=0.05, nonsig_color='grey', subset_xaxis=None, subset_yaxis=None, cmap='vlag', log=True, center=0, method='heatmap', invert_axis=None, parallel_coordinates_color=None, matplotlib_bbox_to_anchor=(1.04, 1), matplotlib_legend_loc='upper left', xticks_rotation=90, return_data=False, fileName='foldchange.pdf', saveDir=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The annotated data matrix with fold change calculations.</p> required <code>label</code> <code>str</code> <p>Label key from <code>adata.uns</code> indicating the fold change data to visualize.</p> <code>'foldchange'</code> <code>p_val</code> <code>float</code> <p>P-value threshold for significance; values above this threshold are considered non-significant.</p> <code>0.05</code> <code>nonsig_color</code> <code>str</code> <p>Color for non-significant changes in the visualization.</p> <code>'grey'</code> <code>subset_xaxis</code> <code>list</code> <p>Categories to include from the x-axis for plotting.</p> <code>None</code> <code>subset_yaxis</code> <code>list</code> <p>Categories to include from the y-axis for plotting.</p> <code>None</code> <code>cmap</code> <code>str</code> <p>Colormap for the heatmap visualization.</p> <code>'vlag'</code> <code>log</code> <code>bool</code> <p>If True, fold changes are converted to log2 scale for visualization.</p> <code>True</code> <code>center</code> <code>float</code> <p>The value at which the colormap is centered.</p> <code>0</code> <code>method</code> <code>str</code> <p>Plotting method, either 'heatmap' for a heatmap or 'parallel_coordinates' for a parallel coordinates plot.</p> <code>'heatmap'</code> <code>invert_axis</code> <code>bool</code> <p>If True, inverts the x and y axes in the plot. Default is False.</p> <code>None</code> <code>parallel_coordinates_color</code> <code>list</code> <p>Specifies custom colors for parallel coordinates plot.</p> <code>None</code> <code>matplotlib_bbox_to_anchor</code> <code>tuple</code> <p>Adjusts the legend position in parallel coordinates plot.</p> <code>(1.04, 1)</code> <code>matplotlib_legend_loc</code> <code>str</code> <p>Specifies the location of the legend.</p> <code>'upper left'</code> <code>xticks_rotation</code> <code>int</code> <p>Rotation angle for x-axis tick labels.</p> <code>90</code> <code>return_data</code> <code>bool</code> <p>If True, returns the data frame used for plotting instead of the plot.</p> <code>False</code> <p>Returns:</p> Type Description <p>Dataframe; plot (pandas, matplotlib): If <code>return_data</code> is True, returns a pandas DataFrame used for plotting. Otherwise, displays the plot.</p> Example <pre><code># Generate a heatmap of fold changes with custom settings\nsm.pl.foldchange(adata, label='foldchange', method='heatmap', cmap='coolwarm', log=True,\n                 p_val=0.05, nonsig_color='lightgrey', xticks_rotation=45)\n\n# Create a parallel coordinates plot to visualize fold changes across groups\nsm.pl.foldchange(adata, label='foldchange', method='parallel_coordinates', log=True,\n                 parallel_coordinates_color=['red', 'blue', 'green'], invert_axis=True)\n\n# Return the data frame used for fold change visualization\ndf_foldchange = sm.pl.foldchange(adata, label='foldchange', return_data=True)\n</code></pre> Source code in <code>scimap/plotting/foldchange.py</code> <pre><code>def foldchange(\n    adata,\n    label='foldchange',\n    p_val=0.05,\n    nonsig_color='grey',\n    subset_xaxis=None,\n    subset_yaxis=None,\n    cmap='vlag',\n    log=True,\n    center=0,\n    method='heatmap',\n    invert_axis=None,\n    parallel_coordinates_color=None,\n    matplotlib_bbox_to_anchor=(1.04, 1),\n    matplotlib_legend_loc='upper left',\n    xticks_rotation=90,\n    return_data=False,\n    fileName='foldchange.pdf',\n    saveDir=None,\n    **kwargs,\n):\n    \"\"\"\n    Parameters:\n            adata (anndata.AnnData):\n                The annotated data matrix with fold change calculations.\n\n            label (str):\n                Label key from `adata.uns` indicating the fold change data to visualize.\n\n            p_val (float):\n                P-value threshold for significance; values above this threshold are considered non-significant.\n\n            nonsig_color (str):\n                Color for non-significant changes in the visualization.\n\n            subset_xaxis (list, optional):\n                Categories to include from the x-axis for plotting.\n\n            subset_yaxis (list, optional):\n                Categories to include from the y-axis for plotting.\n\n            cmap (str):\n                Colormap for the heatmap visualization.\n\n            log (bool):\n                If True, fold changes are converted to log2 scale for visualization.\n\n            center (float):\n                The value at which the colormap is centered.\n\n            method (str):\n                Plotting method, either 'heatmap' for a heatmap or 'parallel_coordinates' for a parallel coordinates plot.\n\n            invert_axis (bool, optional):\n                If True, inverts the x and y axes in the plot. Default is False.\n\n            parallel_coordinates_color (list, optional):\n                Specifies custom colors for parallel coordinates plot.\n\n            matplotlib_bbox_to_anchor (tuple):\n                Adjusts the legend position in parallel coordinates plot.\n\n            matplotlib_legend_loc (str):\n                Specifies the location of the legend.\n\n            xticks_rotation (int):\n                Rotation angle for x-axis tick labels.\n\n            return_data (bool):\n                If True, returns the data frame used for plotting instead of the plot.\n\n    Returns:\n            Dataframe; plot (pandas, matplotlib):\n                If `return_data` is True, returns a pandas DataFrame used for plotting. Otherwise, displays the plot.\n\n    Example:\n            ```python\n\n            # Generate a heatmap of fold changes with custom settings\n            sm.pl.foldchange(adata, label='foldchange', method='heatmap', cmap='coolwarm', log=True,\n                             p_val=0.05, nonsig_color='lightgrey', xticks_rotation=45)\n\n            # Create a parallel coordinates plot to visualize fold changes across groups\n            sm.pl.foldchange(adata, label='foldchange', method='parallel_coordinates', log=True,\n                             parallel_coordinates_color=['red', 'blue', 'green'], invert_axis=True)\n\n            # Return the data frame used for fold change visualization\n            df_foldchange = sm.pl.foldchange(adata, label='foldchange', return_data=True)\n\n            ```\n    \"\"\"\n\n    # set color for heatmap\n    # cmap_updated = copy.copy(matplotlib.cm.get_cmap(cmap))\n    cmap_updated = matplotlib.cm.get_cmap(cmap)\n    cmap_updated.set_bad(color=nonsig_color)\n\n    # get the data\n    fc = adata.uns[str(label) + '_fc']\n    p = adata.uns[str(label) + '_pval']\n\n    # fold\n    fold = fc.copy()\n    p_mask = p.copy()\n\n    # reference image\n    ref = fold.index.name\n\n    # log\n    if log is True:\n        fold = np.log2(fold)\n\n    # create a mask for non-sig values\n    p_mask[p_mask &gt; p_val] = np.nan\n\n    # subset x axis data\n    if subset_xaxis is not None:\n        if isinstance(subset_xaxis, str):\n            subset_xaxis = [subset_xaxis]\n        fold = fold[subset_xaxis]\n        p_mask = p_mask[subset_xaxis]\n        # reorder\n\n    # subset y axis data\n    if subset_yaxis is not None:\n        if isinstance(subset_yaxis, str):\n            subset_yaxis = [subset_yaxis]\n        fold = fold.loc[subset_yaxis]\n        p_mask = p_mask.loc[subset_yaxis]\n        # reorder\n\n    # invert axis if user requests\n    if invert_axis is True:\n        fold = fold.T\n        p_mask = p_mask.T\n\n    # mask\n    mask = p_mask.isnull()  # identify the NAN's for masking\n\n    if method == 'heatmap':\n        # heatmap of the foldchange\n        # g= sns.clustermap(fold, cmap=cmap, mask=mask, center=center, col_cluster=False, row_cluster=False)\n        fig = sns.clustermap(fold, cmap=cmap, mask=mask, center=center, **kwargs)\n        plt.suptitle('reference: ' + str(ref))\n        plt.setp(fig.ax_heatmap.get_xticklabels(), rotation=xticks_rotation)\n        plt.tight_layout()\n\n    if method == 'parallel_coordinates':\n        fold['sample'] = fold.index\n        # plotting\n        fig, axes = plt.subplots()\n        if parallel_coordinates_color is not None:\n            parallel_coordinates(\n                fold, 'sample', color=parallel_coordinates_color, **kwargs\n            )\n        else:\n            # parallel_coordinates(fold, 'sample', colormap=cmap_updated)\n            parallel_coordinates(fold, 'sample', colormap=cmap_updated, **kwargs)\n        axes.grid(False)\n        plt.legend(bbox_to_anchor=matplotlib_bbox_to_anchor, loc=matplotlib_legend_loc)\n        plt.axhline(y=0, color='black', linestyle='-')\n        plt.xticks(rotation=xticks_rotation)\n        plt.suptitle('reference: ' + str(ref))\n        fig.tight_layout()\n\n    # save\n    if saveDir:\n        if not os.path.exists(saveDir):\n            os.makedirs(saveDir)\n        full_path = os.path.join(saveDir, fileName)\n        plt.savefig(full_path, dpi=300)\n        plt.close()\n        print(f\"Saved plot to {full_path}\")\n    else:\n        plt.show()\n\n    # return data\n    if return_data is True:\n        return fold\n</code></pre>"},{"location":"Functions/pl/gate_finder/","title":"gate_finder","text":"<p>Short Description</p> <p><code>sm.pl.gate_finder</code>: This function leverages Napari to display OME-TIFF images,  overlaying points that assist in manually determining gating thresholds for specific markers.  By visualizing marker expression spatially, users can more accurately define gates.  Subsequently, the identified gating parameters can be applied to the dataset using <code>sm.pp.rescale</code>,  enabling precise control over data segmentation and analysis based on marker expression levels.</p> <p><code>gate_finder()</code> is deprecated and will be removed in a future version. Please use <code>sm.pl.napariGater()</code> instead.</p>"},{"location":"Functions/pl/gate_finder/#scimap.plotting.gate_finder--function","title":"Function","text":""},{"location":"Functions/pl/gate_finder/#scimap.plotting.gate_finder.gate_finder","title":"<code>gate_finder(image_path, adata, marker_of_interest, layer='raw', log=True, from_gate=6, to_gate=8, increment=0.1, markers=None, channel_names='default', flip_y=True, x_coordinate='X_centroid', y_coordinate='Y_centroid', point_size=10, imageid='imageid', subset=None, seg_mask=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>Path to the high-resolution image file (supports formats like TIFF, OME.TIFF).</p> required <code>adata</code> <code>AnnData</code> <p>The annotated data matrix.</p> required <code>marker_of_interest</code> <code>str</code> <p>The target marker for which the gating threshold is to be determined.</p> required <code>layer</code> <code>str</code> <p>Specifies the layer in <code>adata</code> containing expression data. Defaults to 'raw' for <code>adata.raw.X</code>.</p> <code>'raw'</code> <code>log</code> <code>bool</code> <p>Applies log transformation to expression data if set to True.</p> <code>True</code> <code>from_gate</code> <code>int</code> <p>Starting gate threshold value for the marker of interest.</p> <code>6</code> <code>to_gate</code> <code>int</code> <p>Ending gate threshold value for the marker of interest.</p> <code>8</code> <code>increment</code> <code>float</code> <p>Incremental step size between <code>from_gate</code> and <code>to_gate</code>.</p> <code>0.1</code> <code>markers</code> <code>list</code> <p>A list of additional markers to include in visualization for context.</p> <code>None</code> <code>channel_names</code> <code>list or str</code> <p>Names of the channels in the image, in order. Defaults to 'default', using <code>adata.uns['all_markers']</code>.</p> <code>'default'</code> <code>flip_y</code> <code>bool</code> <p>Inverts the Y-axis to match image coordinates if set to True. Defaults to True.</p> <code>True</code> <code>x_coordinate,</code> <code>y_coordinate (str</code> <p>Columns in <code>adata.obs</code> specifying cell coordinates. Defaults are 'X_centroid' and 'Y_centroid'.</p> required <code>point_size</code> <code>int</code> <p>Size of points in the visualization.</p> <code>10</code> <code>imageid</code> <code>str</code> <p>Column in <code>adata.obs</code> identifying images for datasets with multiple images.</p> <code>'imageid'</code> <code>subset</code> <code>str</code> <p>Specific image identifier for targeted analysis, typically an image ID.</p> <code>None</code> <code>seg_mask</code> <code>str</code> <p>Path to a segmentation mask file to overlay.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to the visualization tool.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Image</code> <code>napari</code> <p>Displays the visualization using napari viewer.</p> Example <pre><code># Visualize gating thresholds for CD45 on a specific image\nsm.pl.gate_finder(\n    image_path='/path/to/image.ome.tif', adata=adata, marker_of_interest='CD45',\n    from_gate=4, to_gate=10, increment=0.2, flip_y=False, point_size=12,\n    subset='Sample1', seg_mask='/path/to/seg_mask.tif')\n\n# Log-transformed gating for a marker with additional markers and custom channel names\nsm.pl.gate_finder(\n    image_path='/path/to/image.ome.tif', adata=adata, marker_of_interest='CD3',\n    log=True, from_gate=3, to_gate=7, increment=0.1, markers=['CD19', 'CD4'],\n    channel_names=['DAPI', 'CD3', 'CD19', 'CD4'], point_size=15)\n\n# Explore gating for multiple markers across different segments\nsm.pl.gate_finder(\n    image_path='/path/to/image.ome.tif', adata=adata, marker_of_interest='CD8',\n    layer='expression', from_gate=5, to_gate=9, increment=0.05, markers=['CD8', 'PD1'],\n    subset='TumorRegion', seg_mask='/path/to/tumor_seg_mask.tif')\n</code></pre> Source code in <code>scimap/plotting/gate_finder.py</code> <pre><code>def gate_finder(\n    image_path,\n    adata,\n    marker_of_interest,\n    layer='raw',\n    log=True,\n    from_gate=6,\n    to_gate=8,\n    increment=0.1,\n    markers=None,\n    channel_names='default',\n    flip_y=True,\n    x_coordinate='X_centroid',\n    y_coordinate='Y_centroid',\n    point_size=10,\n    imageid='imageid',\n    subset=None,\n    seg_mask=None,\n    **kwargs,\n):\n    \"\"\"\n    Parameters:\n            image_path (str):\n                Path to the high-resolution image file (supports formats like TIFF, OME.TIFF).\n\n            adata (anndata.AnnData):\n                The annotated data matrix.\n\n            marker_of_interest (str):\n                The target marker for which the gating threshold is to be determined.\n\n            layer (str, optional):\n                Specifies the layer in `adata` containing expression data. Defaults to 'raw' for `adata.raw.X`.\n\n            log (bool, optional):\n                Applies log transformation to expression data if set to True.\n\n            from_gate (int, optional):\n                Starting gate threshold value for the marker of interest.\n\n            to_gate (int, optional):\n                Ending gate threshold value for the marker of interest.\n\n            increment (float, optional):\n                Incremental step size between `from_gate` and `to_gate`.\n\n            markers (list, optional):\n                A list of additional markers to include in visualization for context.\n\n            channel_names (list or str, optional):\n                Names of the channels in the image, in order. Defaults to 'default', using `adata.uns['all_markers']`.\n\n            flip_y (bool, optional):\n                Inverts the Y-axis to match image coordinates if set to True. Defaults to True.\n\n            x_coordinate, y_coordinate (str, optional):\n                Columns in `adata.obs` specifying cell coordinates. Defaults are 'X_centroid' and 'Y_centroid'.\n\n            point_size (int, optional):\n                Size of points in the visualization.\n\n            imageid (str, optional):\n                Column in `adata.obs` identifying images for datasets with multiple images.\n\n            subset (str, optional):\n                Specific image identifier for targeted analysis, typically an image ID.\n\n            seg_mask (str, optional):\n                Path to a segmentation mask file to overlay.\n\n            **kwargs:\n                Additional arguments passed to the visualization tool.\n\n    Returns:\n            Image (napari):\n                Displays the visualization using napari viewer.\n\n    Example:\n        ```python\n\n        # Visualize gating thresholds for CD45 on a specific image\n        sm.pl.gate_finder(\n            image_path='/path/to/image.ome.tif', adata=adata, marker_of_interest='CD45',\n            from_gate=4, to_gate=10, increment=0.2, flip_y=False, point_size=12,\n            subset='Sample1', seg_mask='/path/to/seg_mask.tif')\n\n        # Log-transformed gating for a marker with additional markers and custom channel names\n        sm.pl.gate_finder(\n            image_path='/path/to/image.ome.tif', adata=adata, marker_of_interest='CD3',\n            log=True, from_gate=3, to_gate=7, increment=0.1, markers=['CD19', 'CD4'],\n            channel_names=['DAPI', 'CD3', 'CD19', 'CD4'], point_size=15)\n\n        # Explore gating for multiple markers across different segments\n        sm.pl.gate_finder(\n            image_path='/path/to/image.ome.tif', adata=adata, marker_of_interest='CD8',\n            layer='expression', from_gate=5, to_gate=9, increment=0.05, markers=['CD8', 'PD1'],\n            subset='TumorRegion', seg_mask='/path/to/tumor_seg_mask.tif')\n\n        ```\n    \"\"\"\n\n    warnings.warn(\n    \"gate_finder() is deprecated and will be removed in a future version. \"\n    \"Please use sm.pl.napariGater() instead.\",\n    FutureWarning,\n    stacklevel=2,\n    )\n\n    # If no raw data is available make a copy\n    if adata.raw is None:\n        adata.raw = adata\n\n    # subset data if neede\n    if subset is not None:\n        if isinstance(subset, str):\n            subset = [subset]\n        if layer == 'raw':\n            bdata = adata.copy()\n            bdata.X = adata.raw.X\n            bdata = bdata[bdata.obs[imageid].isin(subset)]\n        else:\n            bdata = adata.copy()\n            bdata = bdata[bdata.obs[imageid].isin(subset)]\n    else:\n        bdata = adata.copy()\n\n    # isolate the data\n    if layer is None:\n        data = pd.DataFrame(bdata.X, index=bdata.obs.index, columns=bdata.var.index)[\n            [marker_of_interest]\n        ]\n    elif layer == 'raw':\n        data = pd.DataFrame(\n            bdata.raw.X, index=bdata.obs.index, columns=bdata.var.index\n        )[[marker_of_interest]]\n    else:\n        data = pd.DataFrame(\n            bdata.layers[layer], index=bdata.obs.index, columns=bdata.var.index\n        )[[marker_of_interest]]\n\n    if log is True:\n        data = np.log1p(data)\n\n    # Copy of the raw data if it exisits\n    # if adata.raw is not None:\n    #    adata.X = adata.raw.X\n\n    # Plot only the Image that is requested\n    # if subset is not None:\n    #    adata = adata[adata.obs[imageid] == subset]\n\n    # Make a copy of the data with the marker of interest\n    # data = pd.DataFrame(np.log1p(adata.X), columns = adata.var.index, index= adata.obs.index)[[marker_of_interest]]\n\n    # Generate a dataframe with various gates\n    def gate(g, d):\n        dd = d.values\n        dd = np.where(dd &lt; g, np.nan, dd)\n        # np.warnings.filterwarnings('ignore')\n        np.seterr('ignore')\n        dd = np.where(dd &gt; g, 1, dd)\n        dd = pd.DataFrame(dd, index=d.index, columns=['gate-' + str(g)])\n        return dd\n\n    # Identify the list of increments\n    inc = list(np.arange(from_gate, to_gate, increment))\n    inc = [round(num, 3) for num in inc]\n\n    # Apply the function\n    r_gate = lambda x: gate(g=x, d=data)  # Create lamda function\n    gated_data = list(map(r_gate, inc))  # Apply function\n    # Concat all the results into a single dataframe\n    gates = pd.concat(gated_data, axis=1)\n\n    # Recover the channel names from adata\n    if channel_names == 'default':\n        channel_names = adata.uns['all_markers']\n    else:\n        channel_names = channel_names\n\n    # if markers is a string convert to list\n    if isinstance(markers, str):\n        markers = [markers]\n\n    # Index of the marker of interest and corresponding names\n    if markers is not None:\n        markers.extend([marker_of_interest])\n        idx = np.where(np.isin(channel_names, markers))[0]\n        channel_names = [channel_names[i] for i in idx]\n    else:\n        idx = list(range(len(channel_names)))\n        channel_names = channel_names\n\n    # Load the segmentation mask\n    if seg_mask is not None:\n        seg_m = tiff.imread(seg_mask)\n        if (len(seg_m.shape) &gt; 2) and (seg_m.shape[0] &gt; 1):\n            seg_m = seg_m[0]\n\n    ##########################################################################\n    # Visulaisation using Napari\n\n    # load OME TIFF\n    if os.path.isfile(image_path) is True:\n        # Load the image\n        image = tiff.TiffFile(image_path, is_ome=False)\n        z = zarr.open(image.aszarr(), mode='r')  # convert image to Zarr array\n        # Identify the number of pyramids and number of channels\n        n_levels = len(image.series[0].levels)  # pyramid\n        # If and if not pyramids are available\n        if n_levels &gt; 1:\n            pyramid = [da.from_zarr(z[i]) for i in range(n_levels)]\n            multiscale = True\n        else:\n            pyramid = da.from_zarr(z)\n            multiscale = False\n        # subset channels of interest\n        if markers is not None:\n            if n_levels &gt; 1:\n                for i in range(n_levels - 1):\n                    pyramid[i] = pyramid[i][idx, :, :]\n                n_channels = pyramid[0].shape[0]  # identify the number of channels\n            else:\n                pyramid = pyramid[idx, :, :]\n                n_channels = pyramid.shape[0]  # identify the number of channels\n        else:\n            if n_levels &gt; 1:\n                n_channels = pyramid[0].shape[0]\n            else:\n                n_channels = pyramid.shape[\n                    0\n                ]  # check if channel names have been passed to all channels\n        if channel_names is not None:\n            assert n_channels == len(channel_names), (\n                f'number of channel names ({len(channel_names)}) must '\n                f'match number of channels ({n_channels})'\n            )\n\n        # Load the viewer\n        viewer = napari.view_image(\n            pyramid,\n            channel_axis=0,\n            multiscale=multiscale,\n            name=None if channel_names is None else channel_names,\n            visible=False,\n            **kwargs,\n        )\n\n    # Operations on the ZARR image\n    # check the format of image\n    if os.path.isfile(image_path) is False:\n        # print(image_path)\n        viewer = napari.Viewer()\n        viewer.open(\n            image_path,\n            multiscale=True,\n            visible=False,\n            name=None if channel_names is None else channel_names,\n        )\n\n    # Add the seg mask\n    if seg_mask is not None:\n        viewer.add_labels(seg_m, name='segmentation mask', visible=False)\n\n    # subset the gates to include only the image of interest\n    gates = gates.loc[bdata.obs.index,]\n\n    # Add gating layer\n    def add_phenotype_layer(adata, gates, phenotype_layer, x, y, viewer, point_size):\n        cells = gates[gates[phenotype_layer] == 1].index\n        coordinates = adata[cells]\n        # Flip Y axis if needed\n        if flip_y is True:\n            coordinates = pd.DataFrame(\n                {'y': coordinates.obs[y], 'x': coordinates.obs[x]}\n            )\n        else:\n            coordinates = pd.DataFrame(\n                {'x': coordinates.obs[x], 'y': coordinates.obs[y]}\n            )\n        # points = coordinates.values.tolist()\n        points = coordinates.values\n        # import time\n        # start = time.time()\n        viewer.add_points(\n            points,\n            size=point_size,\n            face_color='white',\n            visible=False,\n            name=phenotype_layer,\n        )\n        # stop = time.time()\n        # print(stop-start)\n\n    # Run the function on all gating layer\n    for i in gates.columns:\n        add_phenotype_layer(\n            adata=bdata,\n            gates=gates,\n            phenotype_layer=i,\n            x=x_coordinate,\n            y=y_coordinate,\n            viewer=viewer,\n            point_size=point_size,\n        )\n</code></pre>"},{"location":"Functions/pl/groupCorrelation/","title":"groupCorrelation","text":"<p>Short Description</p> <p>The <code>sm.pl.groupCorrelation</code> function calculates and visualizes the correlation between group abundances across various conditions within an <code>AnnData</code> object. Customizable features such as normalization, hierarchical clustering, and manual ordering are available.</p>"},{"location":"Functions/pl/groupCorrelation/#scimap.plotting.groupCorrelation--function","title":"Function","text":""},{"location":"Functions/pl/groupCorrelation/#scimap.plotting.groupCorrelation.groupCorrelation","title":"<code>groupCorrelation(adata, groupBy, condition, normalize=False, subsetGroups=None, orderRow=None, orderColumn=None, clusterRows=True, clusterColumns=True, cmap='vlag', figsize=None, overlayValues=False, fontSize=10, fontColor='black', fileName='groupCorrelation.pdf', saveDir=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData or str</code> <p>An AnnData object containing the dataset, or a string path to an AnnData file to be loaded.</p> required <code>groupBy</code> <code>str</code> <p>The column in <code>adata.obs</code> used for defining groups.</p> required <code>condition</code> <code>str</code> <p>The column in <code>adata.obs</code> that distinguishes different conditions or samples.</p> required <code>normalize</code> <code>bool</code> <p>If True, apply z-score normalization to the group counts across conditions.</p> <code>False</code> <code>subsetGroups</code> <code>list of str</code> <p>A list specifying a subset of groups to include in the analysis. If None, all groups are included.</p> <code>None</code> <code>orderRow</code> <code>list of str</code> <p>Custom order for the rows in the heatmap. If None, the order is determined by clustering or the original group order.</p> <code>None</code> <code>orderColumn</code> <code>list of str</code> <p>Custom order for the columns in the heatmap.</p> <code>None</code> <code>clusterRows</code> <code>bool</code> <p>Whether to apply hierarchical clustering to rows.</p> <code>True</code> <code>clusterColumns</code> <code>bool</code> <p>Whether to apply hierarchical clustering to columns.</p> <code>True</code> <code>cmap</code> <code>str</code> <p>The colormap for the heatmap.</p> <code>'vlag'</code> <code>figsize</code> <code>tuple of float</code> <p>The size of the figure to create (width, height). If None, the size is inferred.</p> <code>None</code> <code>overlayValues</code> <code>bool</code> <p>If True, overlays the correlation coefficient values on the heatmap.</p> <code>False</code> <code>fontSize</code> <code>int</code> <p>Font size for overlay values.</p> <code>10</code> <code>fontColor</code> <code>str</code> <p>Color of the font used for overlay values.</p> <code>'black'</code> <code>fileName</code> <code>str</code> <p>Name of the file to save the heatmap. Relevant only if <code>saveDir</code> is specified.</p> <code>'groupCorrelation.pdf'</code> <code>saveDir</code> <code>str</code> <p>Directory to save the generated heatmap. If None, the heatmap is not saved.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>plot</code> <code>matplotlib</code> <p>Displays or saves a heatmap visualizing the correlation between specified groups.</p> Example <pre><code># Basic usage with auto-detected conditions and groups\nsm.pl.groupCorrelation(adata, groupBy='cell_type', condition='patient_id')\n\n# Normalized group counts with specific groups and custom clustering disabled\nsm.pl.groupCorrelation(adata, groupBy='cell_type', condition='patient_id', normalize=True,\n                 subsetGroups=['B cells', 'T cells'], clusterRows=False, clusterColumns=False)\n\n# Using custom ordering and overlaying values with specified font size and color\nsm.pl.groupCorrelation(adata, groupBy='cell_type', condition='patient_id', overlayValues=True,\n                 orderRow=['T cells', 'B cells'], fontSize=12, fontColor='blue',\n                 saveDir='/path/to/results', fileName='customGroupCorrelation.pdf')\n</code></pre> Source code in <code>scimap/plotting/groupCorrelation.py</code> <pre><code>def groupCorrelation(\n    adata,\n    groupBy,\n    condition,\n    normalize=False,\n    subsetGroups=None,\n    orderRow=None,\n    orderColumn=None,\n    clusterRows=True,\n    clusterColumns=True,\n    cmap='vlag',\n    figsize=None,\n    overlayValues=False,\n    fontSize=10,\n    fontColor='black',\n    fileName='groupCorrelation.pdf',\n    saveDir=None,\n    **kwargs,\n):\n    \"\"\"\n    Parameters:\n        adata (AnnData or str):\n            An AnnData object containing the dataset, or a string path to an AnnData file to be loaded.\n\n        groupBy (str):\n            The column in `adata.obs` used for defining groups.\n\n        condition (str):\n            The column in `adata.obs` that distinguishes different conditions or samples.\n\n        normalize (bool, optional):\n            If True, apply z-score normalization to the group counts across conditions.\n\n        subsetGroups (list of str, optional):\n            A list specifying a subset of groups to include in the analysis. If None, all groups are included.\n\n        orderRow (list of str, optional):\n            Custom order for the rows in the heatmap. If None, the order is determined by clustering or the original group order.\n\n        orderColumn (list of str, optional):\n            Custom order for the columns in the heatmap.\n\n        clusterRows (bool, optional):\n            Whether to apply hierarchical clustering to rows.\n\n        clusterColumns (bool, optional):\n            Whether to apply hierarchical clustering to columns.\n\n        cmap (str, optional):\n            The colormap for the heatmap.\n\n        figsize (tuple of float, optional):\n            The size of the figure to create (width, height). If None, the size is inferred.\n\n        overlayValues (bool, optional):\n            If True, overlays the correlation coefficient values on the heatmap.\n\n        fontSize (int, optional):\n            Font size for overlay values.\n\n        fontColor (str, optional):\n            Color of the font used for overlay values.\n\n        fileName (str, optional):\n            Name of the file to save the heatmap. Relevant only if `saveDir` is specified.\n\n        saveDir (str, optional):\n            Directory to save the generated heatmap. If None, the heatmap is not saved.\n\n    Returns:\n            plot (matplotlib):\n                Displays or saves a heatmap visualizing the correlation between specified groups.\n\n    Example:\n        ```python\n\n        # Basic usage with auto-detected conditions and groups\n        sm.pl.groupCorrelation(adata, groupBy='cell_type', condition='patient_id')\n\n        # Normalized group counts with specific groups and custom clustering disabled\n        sm.pl.groupCorrelation(adata, groupBy='cell_type', condition='patient_id', normalize=True,\n                         subsetGroups=['B cells', 'T cells'], clusterRows=False, clusterColumns=False)\n\n        # Using custom ordering and overlaying values with specified font size and color\n        sm.pl.groupCorrelation(adata, groupBy='cell_type', condition='patient_id', overlayValues=True,\n                         orderRow=['T cells', 'B cells'], fontSize=12, fontColor='blue',\n                         saveDir='/path/to/results', fileName='customGroupCorrelation.pdf')\n        ```\n\n    \"\"\"\n\n    # Load adata if a path is provided\n    if isinstance(adata, str):\n        adata = ad.read_h5ad(adata)\n\n    # Calculate group counts\n    group_counts = (\n        adata.obs.groupby([condition, groupBy], observed=False)\n        .size()\n        .unstack(fill_value=0)\n    )\n\n    # Subset groups if needed\n    if subsetGroups:\n        group_counts = group_counts[subsetGroups]\n\n    # Normalize if requested\n    if normalize:\n        group_counts = group_counts.apply(zscore, axis=0)\n\n    # Calculate correlation\n    corr_matrix = group_counts.corr()\n\n    # var_names for axis labels, directly from group_counts columns\n    var_names = group_counts.columns.tolist()\n\n    # Manual ordering takes precedence over clustering\n    if orderRow and clusterRows:\n        warnings.warn(\n            \"Both orderRow and clusterRows were provided. Proceeding with orderRow and ignoring clusterRows.\"\n        )\n        clusterRows = False\n    if orderColumn and clusterColumns:\n        warnings.warn(\n            \"Both orderColumn and clusterColumns were provided. Proceeding with orderColumn and ignoring clusterColumns.\"\n        )\n        clusterColumns = False\n\n    # Apply manual ordering or clustering\n    if orderRow:\n        row_order = [var_names.index(name) for name in orderRow]\n    else:\n        row_order = range(len(var_names))  # Default order if no manual ordering\n        if clusterRows:\n            linkage_row = linkage(pdist(corr_matrix, 'euclidean'), method='average')\n            row_order = dendrogram(linkage_row, no_plot=True)['leaves']\n\n    if orderColumn:\n        col_order = [var_names.index(name) for name in orderColumn]\n    else:\n        col_order = range(len(var_names))  # Default order if no manual ordering\n        if clusterColumns:\n            linkage_col = linkage(pdist(corr_matrix.T, 'euclidean'), method='average')\n            col_order = dendrogram(linkage_col, no_plot=True)['leaves']\n\n    # Reorder the matrix based on row_order and col_order\n    corr_matrix = corr_matrix.iloc[row_order, col_order]\n\n    # Plotting\n    if figsize is None:\n        figsize_width = max(10, len(corr_matrix.columns) * 0.5)\n        figsize_height = max(8, len(corr_matrix.index) * 0.5)\n        figsize = (figsize_width, figsize_height)\n\n    plt.figure(figsize=figsize)\n    im = plt.imshow(corr_matrix, cmap=cmap, aspect='auto', **kwargs)\n    plt.colorbar(im)\n\n    if overlayValues:\n        for i in range(len(row_order)):\n            for j in range(len(col_order)):\n                plt.text(\n                    j,\n                    i,\n                    f\"{corr_matrix.iloc[i, j]:.2f}\",\n                    ha=\"center\",\n                    va=\"center\",\n                    color=fontColor,\n                    fontsize=fontSize,\n                )\n\n    # Set tick labels\n    plt.xticks(\n        ticks=np.arange(len(col_order)),\n        labels=[var_names[i] for i in col_order],\n        rotation=90,\n    )\n    plt.yticks(\n        ticks=np.arange(len(row_order)), labels=[var_names[i] for i in row_order]\n    )\n\n    plt.tight_layout()\n\n    # Save or show the figure\n    if saveDir:\n        if not os.path.exists(saveDir):\n            os.makedirs(saveDir)\n        full_path = os.path.join(saveDir, fileName)\n        plt.savefig(full_path, dpi=300)\n        plt.close()\n        print(f\"Saved heatmap to {full_path}\")\n    else:\n        plt.show()\n</code></pre>"},{"location":"Functions/pl/heatmap/","title":"heatmap","text":"<p>Short Description</p> <p>The <code>sm.pl.heatmap</code> function generates a comprehensive visualization of marker expression or other relevant features across various groups or clusters identified within spatial datasets. Through customizable clustering, normalization, and annotation features, it supports detailed exploratory data analysis and comparison across different conditions or phenotypes. This function effectively consolidates complex datasets into intuitive visual representations, enhancing the interpretability of high-dimensional data.</p>"},{"location":"Functions/pl/heatmap/#scimap.plotting.heatmap--function","title":"Function","text":""},{"location":"Functions/pl/heatmap/#scimap.plotting.heatmap.heatmap","title":"<code>heatmap(adata, groupBy, layer=None, subsetMarkers=None, subsetGroups=None, clusterRows=True, clusterColumns=True, standardScale=None, orderRow=None, orderColumn=None, showPrevalence=False, cmap='vlag', figsize=None, saveDir=None, fileName=None, verbose=True, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An AnnData object or <code>path</code> to an Anndata object containing the dataset to be visualized. It should have features as variables and observations as rows.</p> required <code>groupBy</code> <code>str</code> <p>The key in <code>adata.obs</code> on which to group observations. Typically, this will be a clustering pr phenotype label like 'leiden' or 'phenotype'.</p> required <code>layer</code> <code>str</code> <p>Specifies the layer of <code>adata</code> to use for the heatmap. If None, the <code>.X</code> attribute is used. If you want to plot the raw data use <code>raw</code></p> <code>None</code> <code>subsetMarkers</code> <code>list of str</code> <p>A list of marker genes or features to include in the heatmap. If None, all markers are used.</p> <code>None</code> <code>subsetGroups</code> <code>list of str</code> <p>A list of group labels to include in the heatmap. Useful for focusing on specific clusters or conditions.</p> <code>None</code> <code>clusterRows</code> <code>bool</code> <p>Whether to cluster rows (observations).</p> <code>True</code> <code>clusterColumns</code> <code>bool</code> <p>Whether to cluster columns (features).</p> <code>True</code> <code>standardScale</code> <code>str</code> <p>Determines if and how to normalize the data across rows or columns. Acceptable values are 'row', 'column', or None.</p> <code>None</code> <code>orderRow</code> <code>list of str</code> <p>Specifies a custom order for the rows based on group labels.</p> <code>None</code> <code>orderColumn</code> <code>list of str</code> <p>Specifies a custom order for the columns based on feature names.</p> <code>None</code> <code>showPrevalence</code> <code>bool</code> <p>If True, adds a bar showing the prevalence of the feature across the groups.</p> <code>False</code> <code>cmap</code> <code>str</code> <p>The colormap for the heatmap.</p> <code>'vlag'</code> <code>figsize</code> <code>tuple of float</code> <p>The size of the figure to create. If None, the size is inferred.</p> <code>None</code> <code>saveDir</code> <code>str</code> <p>Directory to save the generated heatmap. If None, the heatmap is not saved.</p> <code>None</code> <code>fileName</code> <code>str</code> <p>Name of the file to save the heatmap. Relevant only if <code>saveDir</code> is not None.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If True, print additional information during execution.</p> <code>True</code> <code>**kwargs</code> <p>Additional keyword arguments are passed to the underlying matplotlib plotting function.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>plot</code> <code>matplotlib</code> <p>Returns a plot, if <code>saveDir</code> and <code>fileName</code> are provided, the plot is saved in the given directory.</p> Example <pre><code># Example 1: Basic usage with clustering and standard scale by column.\n\nsm.pl.heatmap(adata, groupBy='leiden', standardScale='column')\n\n# Example 2: Advanced usage with specified subset markers, custom grouping, and file saving.\n\nsubsetMarkers = ['ELANE', 'CD57', 'CD45', 'CD11B', 'SMA', 'CD16', 'ECAD']\nsubsetGroups = ['0', '1', '3', '6']\norderRow = ['6', '3', '0', '1']\norderColumn = ['SMA', 'CD16', 'ECAD', 'ELANE', 'CD57', 'CD45', 'CD11B']\nsaveDir = '/path/to/save'\nfileName = 'custom_heatmap.pdf'\n\nsm.pl.heatmap(adata, groupBy='leiden', subsetMarkers=subsetMarkers, subsetGroups=subsetGroups, clusterRows=False, clusterColumns=False, standardScale='column', orderRow=orderRow, orderColumn=orderColumn, showPrevalence=True, figsize=(10, 5), saveDir=saveDir, fileName=fileName, vmin=0, vmax=1)\n</code></pre> Source code in <code>scimap/plotting/heatmap.py</code> <pre><code>def heatmap(\n    adata,\n    groupBy,\n    layer=None,\n    subsetMarkers=None,\n    subsetGroups=None,\n    clusterRows=True,\n    clusterColumns=True,\n    standardScale=None,\n    orderRow=None,\n    orderColumn=None,\n    showPrevalence=False,\n    cmap='vlag',\n    figsize=None,\n    saveDir=None,\n    fileName=None,\n    verbose=True,\n    **kwargs,\n):\n    \"\"\"\n\n    Parameters:\n        adata (AnnData):\n            An AnnData object or `path` to an Anndata object containing the dataset to be visualized. It should have features as variables and observations as rows.\n\n        groupBy (str):\n            The key in `adata.obs` on which to group observations. Typically, this will be a clustering pr phenotype label like 'leiden' or 'phenotype'.\n\n        layer (str, optional):\n            Specifies the layer of `adata` to use for the heatmap. If None, the `.X` attribute is used. If you want to plot the raw data use `raw`\n\n        subsetMarkers (list of str, optional):\n            A list of marker genes or features to include in the heatmap. If None, all markers are used.\n\n        subsetGroups (list of str, optional):\n            A list of group labels to include in the heatmap. Useful for focusing on specific clusters or conditions.\n\n        clusterRows (bool):\n            Whether to cluster rows (observations).\n\n        clusterColumns (bool):\n            Whether to cluster columns (features).\n\n        standardScale (str, optional):\n            Determines if and how to normalize the data across rows or columns. Acceptable values are 'row', 'column', or None.\n\n        orderRow (list of str, optional):\n            Specifies a custom order for the rows based on group labels.\n\n        orderColumn (list of str, optional):\n            Specifies a custom order for the columns based on feature names.\n\n        showPrevalence (bool):\n            If True, adds a bar showing the prevalence of the feature across the groups.\n\n        cmap (str):\n            The colormap for the heatmap.\n\n        figsize (tuple of float, optional):\n            The size of the figure to create. If None, the size is inferred.\n\n        saveDir (str, optional):\n            Directory to save the generated heatmap. If None, the heatmap is not saved.\n\n        fileName (str, optional):\n            Name of the file to save the heatmap. Relevant only if `saveDir` is not None.\n\n        verbose (bool):\n            If True, print additional information during execution.\n\n        **kwargs:\n            Additional keyword arguments are passed to the underlying matplotlib plotting function.\n\n    Returns:\n        plot (matplotlib):\n            Returns a plot, if `saveDir` and `fileName` are provided, the plot is saved in the given directory.\n\n    Example:\n            ```python\n\n            # Example 1: Basic usage with clustering and standard scale by column.\n\n            sm.pl.heatmap(adata, groupBy='leiden', standardScale='column')\n\n            # Example 2: Advanced usage with specified subset markers, custom grouping, and file saving.\n\n            subsetMarkers = ['ELANE', 'CD57', 'CD45', 'CD11B', 'SMA', 'CD16', 'ECAD']\n            subsetGroups = ['0', '1', '3', '6']\n            orderRow = ['6', '3', '0', '1']\n            orderColumn = ['SMA', 'CD16', 'ECAD', 'ELANE', 'CD57', 'CD45', 'CD11B']\n            saveDir = '/path/to/save'\n            fileName = 'custom_heatmap.pdf'\n\n            sm.pl.heatmap(adata, groupBy='leiden', subsetMarkers=subsetMarkers, subsetGroups=subsetGroups, clusterRows=False, clusterColumns=False, standardScale='column', orderRow=orderRow, orderColumn=orderColumn, showPrevalence=True, figsize=(10, 5), saveDir=saveDir, fileName=fileName, vmin=0, vmax=1)\n\n            ```\n    \"\"\"\n\n    # load adata\n    if isinstance(adata, str):\n        adata = ad.read_h5ad(adata)\n\n    # check if the location is provided if the user wishes to save the image\n    if (saveDir is None and fileName is not None) or (\n        saveDir is not None and fileName is None\n    ):\n        raise ValueError(\n            \"Both 'saveDir' and 'fileName' must be provided together or not at all.\"\n        )\n\n    # subset data if user requests\n    subsetadata = None  # intialize subsetted data\n    if subsetGroups:\n        subsetGroups = (\n            [subsetGroups] if isinstance(subsetGroups, str) else subsetGroups\n        )  # convert to list\n        subsetadata = adata[adata.obs[groupBy].isin(subsetGroups)]\n        # also identify the categories to be plotted\n        categories = subsetadata.obs[groupBy].values\n    else:\n        # also identify the categories to be plotted\n        categories = adata.obs[groupBy].values\n\n    # subset the markers if user requests\n    if subsetMarkers:\n        subsetMarkers = (\n            [subsetMarkers] if isinstance(subsetMarkers, str) else subsetMarkers\n        )  # convert to list\n        if subsetadata:\n            # isolate the data\n            if layer == 'raw':\n                data = subsetadata[:, subsetMarkers].raw.X\n            elif layer is None:\n                data = subsetadata[:, subsetMarkers].X\n            else:\n                data = subsetadata[:, subsetMarkers].layers[layer]\n        else:\n            # isolate the data\n            if layer == 'raw':\n                data = adata[:, subsetMarkers].raw.X\n            elif layer is None:\n                data = adata[:, subsetMarkers].X\n            else:\n                data = adata[:, subsetMarkers].layers[layer]\n    else:\n        # take the whole data if the user does not subset anything\n        if layer == 'raw':\n            data = adata.raw.X\n        elif layer is None:\n            data = adata.X\n        else:\n            data = adata.layers[layer]\n\n    # intialize the markers to be plotted\n    if subsetMarkers is None:\n        subsetMarkers = adata.var.index.tolist()\n\n    # The actual plotting function\n    def plot_category_heatmap_vectorized(\n        data,\n        marker_names,\n        categories,\n        clusterRows,\n        clusterColumns,\n        standardScale,\n        orderRow,\n        orderColumn,\n        showPrevalence,\n        cmap,\n        figsize,\n        saveDir,\n        fileName,\n        **kwargs,\n    ):\n        # Validate clustering and ordering options\n        if (clusterRows or clusterColumns) and (\n            orderRow is not None or orderColumn is not None\n        ):\n            raise ValueError(\n                \"Cannot use clustering and manual ordering together. Please choose one or the other.\"\n            )\n\n        if standardScale not in [None, 'row', 'column']:\n            raise ValueError(\"standardScale must be 'row', 'column', or None.\")\n\n        # Convert marker_names to list if it's a pandas Index\n        # if isinstance(marker_names, pd.Index):\n        #    marker_names = marker_names.tolist()\n\n        # Data preprocessing\n        sorted_indices = np.argsort(categories)\n        data = data[sorted_indices, :]\n        categories = categories[sorted_indices]\n        unique_categories, category_counts = np.unique(categories, return_counts=True)\n\n        # Compute mean values for each category\n        mean_data = np.array(\n            [\n                np.mean(data[categories == category, :], axis=0)\n                for category in unique_categories\n            ]\n        )\n\n        # Apply standard scaling if specified\n        if standardScale == 'row':\n            scaler = StandardScaler()\n            mean_data = scaler.fit_transform(mean_data)\n        elif standardScale == 'column':\n            scaler = StandardScaler()\n            mean_data = scaler.fit_transform(mean_data.T).T\n\n        # Apply manual ordering if specified\n        if orderRow:\n            # Ensure orderRow is a list\n            if isinstance(orderRow, pd.Index):\n                orderRow = orderRow.tolist()\n            row_order = [unique_categories.tolist().index(r) for r in orderRow]\n            mean_data = mean_data[row_order, :]\n            unique_categories = [unique_categories[i] for i in row_order]\n            category_counts = [category_counts[i] for i in row_order]\n\n        if orderColumn:\n            # Ensure orderColumn is a list\n            if isinstance(orderColumn, pd.Index):\n                orderColumn = orderColumn.tolist()\n            col_order = [marker_names.index(c) for c in orderColumn]\n            mean_data = mean_data[:, col_order]\n            marker_names = [marker_names[i] for i in col_order]\n\n            # Clustering\n        if clusterRows:\n            # Perform hierarchical clustering\n            row_linkage = linkage(pdist(mean_data), method='average')\n            # Reorder data according to the clustering\n            row_order = dendrogram(row_linkage, no_plot=True)['leaves']\n            mean_data = mean_data[row_order, :]\n            unique_categories = unique_categories[row_order]\n            category_counts = category_counts[row_order]\n\n        if clusterColumns:\n            # Perform hierarchical clustering\n            col_linkage = linkage(pdist(mean_data.T), method='average')\n            # Reorder data according to the clustering\n            col_order = dendrogram(col_linkage, no_plot=True)['leaves']\n            mean_data = mean_data[:, col_order]\n            marker_names = [marker_names[i] for i in col_order]\n\n        # Plotting\n        # Dynamic figsize calculation\n        if figsize is None:\n            base_size = 0.5  # Base size for each cell in inches\n            figsize_width = max(10, len(marker_names) * base_size)\n            figsize_height = max(8, len(unique_categories) * base_size)\n            figsize = (figsize_width, figsize_height)\n\n        fig, ax = plt.subplots(figsize=figsize, constrained_layout=True)\n\n        # Heatmap\n        # Extract vmin and vmax from kwargs if present, else default to min and max of mean_data\n        vmin = kwargs.pop('vmin', np.min(mean_data))\n        vmax = kwargs.pop('vmax', np.max(mean_data))\n\n        # Create the Normalize instance with vmin and vmax\n        norm = Normalize(vmin=vmin, vmax=vmax)\n\n        c = ax.imshow(mean_data, aspect='auto', cmap=cmap, norm=norm, **kwargs)\n\n        # Prevalence text\n        if showPrevalence:\n            # Calculate text offset from the last column of the heatmap\n            text_offset = (\n                mean_data.shape[1] * 0.001\n            )  # Small offset from the right edge of the heatmap\n\n            for index, count in enumerate(category_counts):\n                # Position text immediately to the right of the heatmap\n                ax.text(\n                    mean_data.shape[1] + text_offset,\n                    index,\n                    f\"n={count}\",\n                    va='center',\n                    ha='left',\n                )\n\n        # Setting the tick labels\n        ax.set_xticks(np.arange(mean_data.shape[1]))\n        ax.set_xticklabels(marker_names, rotation=90, ha=\"right\")\n        ax.set_yticks(np.arange(mean_data.shape[0]))\n        ax.set_yticklabels(unique_categories)\n\n        # Move the colorbar to the top left corner\n        # cbar_ax = fig.add_axes([0.125, 0.92, 0.2, 0.02])  # x, y, width, height\n        cbar_ax = ax.inset_axes([-0.5, -1.5, 4, 0.5], transform=ax.transData)\n        cbar = plt.colorbar(c, cax=cbar_ax, orientation='horizontal')\n        cbar_ax.xaxis.set_ticks_position('top')\n        cbar_ax.xaxis.set_label_position('top')\n        cbar.set_label('Mean expression in group')\n\n        ax.set_xlabel('Markers')\n        ax.set_ylabel('Categories')\n\n        # plt.tight_layout(rect=[0, 0, 0.9, 0.9]) # Adjust the layout\n\n        # Saving the figure if saveDir and fileName are provided\n        if saveDir:\n            if not os.path.exists(saveDir):\n                os.makedirs(saveDir)\n            full_path = os.path.join(saveDir, fileName)\n            plt.savefig(full_path, dpi=300)\n            plt.close(fig)\n            print(f\"Saved heatmap to {full_path}\")\n        else:\n            plt.show()\n\n    # call the plotting function\n    plot_category_heatmap_vectorized(\n        data=data,\n        marker_names=subsetMarkers,\n        categories=categories,\n        clusterRows=clusterRows,\n        clusterColumns=clusterColumns,\n        standardScale=standardScale,\n        orderRow=orderRow,\n        orderColumn=orderColumn,\n        showPrevalence=showPrevalence,\n        cmap=cmap,\n        figsize=figsize,\n        saveDir=saveDir,\n        fileName=fileName,\n        **kwargs,\n    )\n</code></pre>"},{"location":"Functions/pl/image_viewer/","title":"image_viewer","text":"<p>Short Description</p> <p><code>sm.pl.image_viewer</code>: This function enables users to view OME-TIFF images within  the Napari viewer, offering the capability to overlay points based on any categorical  column, such as cluster annotations or phenotypes. It provides a dynamic and interactive  way to visually explore spatial distributions and relationships of cells directly  on the source images, enriching the analysis with spatial context and insights.</p>"},{"location":"Functions/pl/image_viewer/#scimap.plotting.image_viewer--function","title":"Function","text":""},{"location":"Functions/pl/image_viewer/#scimap.plotting.image_viewer.image_viewer","title":"<code>image_viewer(image_path, adata, overlay=None, flip_y=True, overlay_category=None, markers=None, channel_names='default', x_coordinate='X_centroid', y_coordinate='Y_centroid', point_size=10, point_color=None, subset=None, imageid='imageid', seg_mask=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>Path to the image file. Supports TIFF, OME.TIFF, and ZARR formats.</p> required <code>adata</code> <code>AnnData</code> <p>The annotated data matrix.</p> required <code>overlay</code> <code>str</code> <p>Column in <code>adata.obs</code> containing categorical data for visualization, such as phenotypes or clusters.</p> <code>None</code> <code>flip_y</code> <code>bool</code> <p>If True, inverts the Y-axis to match image coordinates.</p> <code>True</code> <code>overlay_category</code> <code>list</code> <p>Specific categories within <code>overlay</code> to display. If None, all categories are shown.</p> <code>None</code> <code>markers</code> <code>list</code> <p>List of markers to include in the visualization. If None, all available markers are displayed.</p> <code>None</code> <code>channel_names</code> <code>list or str</code> <p>Specifies the order of channels in the image. Default uses all markers in <code>adata.uns['all_markers']</code>.</p> <code>'default'</code> <code>x_coordinate,</code> <code>y_coordinate (str</code> <p>Columns in <code>adata.obs</code> specifying cell coordinates. Default to 'X_centroid' and 'Y_centroid'.</p> required <code>point_size</code> <code>int</code> <p>Size of the points in the visualization.</p> <code>10</code> <code>point_color</code> <code>str or dict</code> <p>Color(s) for the points. Can specify a single color or a dictionary mapping categories to colors.</p> <code>None</code> <code>imageid</code> <code>str</code> <p>Column in <code>adata.obs</code> identifying different images in the dataset. Useful for datasets with multiple images.</p> <code>'imageid'</code> <code>subset</code> <code>str</code> <p>Identifier for a specific image to analyze, used in conjunction with <code>imageid</code>.</p> <code>None</code> <code>seg_mask</code> <code>str</code> <p>Path to a segmentation mask file to overlay.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to the napari viewer.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Image</code> <code>napari</code> <p>Displays the visualization using napari viewer.</p> Example <pre><code># Basic visualization with phenotype overlay\nsm.pl.image_viewer(image_path='/path/to/image.ome.tif', adata=adata, overlay='phenotype', point_size=5)\n\n# Visualization with segmentation mask and custom point colors\nsm.pl.image_viewer(image_path='/path/to/image.ome.tif', adata=adata, seg_mask='/path/to/mask.tif',\n             overlay='phenotype', point_color={'T cell': 'green', 'B cell': 'blue'}, point_size=7)\n</code></pre> Source code in <code>scimap/plotting/image_viewer.py</code> <pre><code>def image_viewer(\n    image_path,\n    adata,\n    overlay=None,\n    flip_y=True,\n    overlay_category=None,\n    markers=None,\n    channel_names='default',\n    x_coordinate='X_centroid',\n    y_coordinate='Y_centroid',\n    point_size=10,\n    point_color=None,\n    subset=None,\n    imageid='imageid',\n    seg_mask=None,\n    **kwargs,\n):\n    \"\"\"\n    Parameters:\n            image_path (str):\n                Path to the image file. Supports TIFF, OME.TIFF, and ZARR formats.\n\n            adata (anndata.AnnData):\n                The annotated data matrix.\n\n            overlay (str, optional):\n                Column in `adata.obs` containing categorical data for visualization, such as phenotypes or clusters.\n\n            flip_y (bool, optional):\n                If True, inverts the Y-axis to match image coordinates.\n\n            overlay_category (list, optional):\n                Specific categories within `overlay` to display. If None, all categories are shown.\n\n            markers (list, optional):\n                List of markers to include in the visualization. If None, all available markers are displayed.\n\n            channel_names (list or str, optional):\n                Specifies the order of channels in the image. Default uses all markers in `adata.uns['all_markers']`.\n\n            x_coordinate, y_coordinate (str, optional):\n                Columns in `adata.obs` specifying cell coordinates. Default to 'X_centroid' and 'Y_centroid'.\n\n            point_size (int, optional):\n                Size of the points in the visualization.\n\n            point_color (str or dict, optional):\n                Color(s) for the points. Can specify a single color or a dictionary mapping categories to colors.\n\n            imageid (str, optional):\n                Column in `adata.obs` identifying different images in the dataset. Useful for datasets with multiple images.\n\n            subset (str, optional):\n                Identifier for a specific image to analyze, used in conjunction with `imageid`.\n\n            seg_mask (str, optional):\n                Path to a segmentation mask file to overlay.\n\n            **kwargs:\n                Additional arguments passed to the napari viewer.\n\n    Returns:\n            Image (napari):\n                Displays the visualization using napari viewer.\n\n    Example:\n        ```python\n\n        # Basic visualization with phenotype overlay\n        sm.pl.image_viewer(image_path='/path/to/image.ome.tif', adata=adata, overlay='phenotype', point_size=5)\n\n        # Visualization with segmentation mask and custom point colors\n        sm.pl.image_viewer(image_path='/path/to/image.ome.tif', adata=adata, seg_mask='/path/to/mask.tif',\n                     overlay='phenotype', point_color={'T cell': 'green', 'B cell': 'blue'}, point_size=7)\n\n        ```\n    \"\"\"\n\n    # TODO\n    # - ADD Subset markers for ZARR ssection\n    # - Ability to use ZARR metadata if available\n\n    # adding option to load just the image without an adata object\n    if adata is None:\n        channel_names = None\n    else:\n        # All operations on the AnnData object is performed first\n        # Plot only the Image that is requested\n        if subset is not None:\n            adata = adata[adata.obs[imageid] == subset]\n\n        # Recover the channel names from adata\n        if channel_names == 'default':\n            channel_names = adata.uns['all_markers']\n        else:\n            channel_names = channel_names\n\n        # Index of the marker of interest and corresponding names\n        if markers is None:\n            idx = list(range(len(channel_names)))\n            channel_names = channel_names\n        else:\n            idx = []\n            for i in markers:\n                idx.append(list(channel_names).index(i))\n            channel_names = markers\n\n        # Load the segmentation mask\n        if seg_mask is not None:\n            seg_m = tiff.imread(seg_mask)\n            if (len(seg_m.shape) &gt; 2) and (seg_m.shape[0] &gt; 1):\n                seg_m = seg_m[0]\n\n    # Operations on the OME TIFF image is performed next\n    # check the format of image\n    if os.path.isfile(image_path) is True:\n        image = tiff.TiffFile(image_path, is_ome=False)  # is_ome=False\n        z = zarr.open(image.aszarr(), mode='r')  # convert image to Zarr array\n        # Identify the number of pyramids\n        n_levels = len(image.series[0].levels)  # pyramid\n\n        # If and if not pyramids are available\n        if n_levels &gt; 1:\n            pyramid = [da.from_zarr(z[i]) for i in range(n_levels)]\n            multiscale = True\n        else:\n            pyramid = da.from_zarr(z)\n            multiscale = False\n\n        # subset channels of interest\n        if markers is not None:\n            if n_levels &gt; 1:\n                for i in range(n_levels - 1):\n                    pyramid[i] = pyramid[i][idx, :, :]\n                n_channels = pyramid[0].shape[0]  # identify the number of channels\n            else:\n                pyramid = pyramid[idx, :, :]\n                n_channels = pyramid.shape[0]  # identify the number of channels\n        else:\n            if n_levels &gt; 1:\n                n_channels = pyramid[0].shape[0]\n            else:\n                n_channels = pyramid.shape[0]\n\n        # check if channel names have been passed to all channels\n        if channel_names is not None:\n            assert n_channels == len(channel_names), (\n                f'number of channel names ({len(channel_names)}) must '\n                f'match number of channels ({n_channels})'\n            )\n\n        # Load the viewer\n        viewer = napari.view_image(\n            pyramid,\n            multiscale=multiscale,\n            channel_axis=0,\n            visible=False,\n            name=None if channel_names is None else channel_names,\n            **kwargs,\n        )\n\n    # Operations on the ZARR image\n    # check the format of image\n    if os.path.isfile(image_path) is False:\n        # print(image_path)\n        viewer = napari.Viewer()\n        viewer.open(\n            image_path,\n            multiscale=True,\n            visible=False,\n            name=None if channel_names is None else channel_names,\n        )\n\n    # Add the seg mask\n    if seg_mask is not None:\n        viewer.add_labels(seg_m, name='segmentation mask', visible=False)\n\n    # Add phenotype layer function\n    def add_phenotype_layer(\n        adata,\n        overlay,\n        phenotype_layer,\n        x,\n        y,\n        viewer,\n        point_size,\n        point_color,\n        available_phenotypes,\n    ):\n        coordinates = adata[adata.obs[overlay] == phenotype_layer]\n        # Flip Y AXIS if needed\n        if flip_y is True:\n            coordinates = pd.DataFrame(\n                {'y': coordinates.obs[y], 'x': coordinates.obs[x]}\n            )\n        else:\n            coordinates = pd.DataFrame(\n                {'x': coordinates.obs[x], 'y': coordinates.obs[y]}\n            )\n\n        # points = coordinates.values.tolist()\n        points = coordinates.values\n        if point_color is None:\n            r = lambda: random.randint(0, 255)  # random color generator\n            point_color = '#%02X%02X%02X' % (r(), r(), r())  # random color generator\n        elif isinstance(point_color, dict):\n            # if dict identify the color for the given phenotype\n            # also if a color is not provided in the dict assign it to white\n            try:\n                point_color = point_color[available_phenotypes]\n            except KeyError:\n                point_color = 'white'\n                # if the dict has list, we need to account for it and so the following two lines\n                if isinstance(point_color, list):\n                    point_color = point_color[0]\n\n        # check if point_color is a dict and if so isolate the color to the specific categoty\n        viewer.add_points(\n            points,\n            size=point_size,\n            face_color=point_color,\n            visible=False,\n            name=phenotype_layer,\n        )\n\n    if overlay is not None:\n        # categories under investigation\n        if overlay_category is None:\n            available_phenotypes = list(adata.obs[overlay].unique())\n        else:\n            available_phenotypes = overlay_category\n\n        # Run the function on all phenotypes\n        for i in available_phenotypes:\n            add_phenotype_layer(\n                adata=adata,\n                overlay=overlay,\n                phenotype_layer=i,\n                x=x_coordinate,\n                y=y_coordinate,\n                viewer=viewer,\n                point_size=point_size,\n                point_color=point_color,\n                available_phenotypes=i,\n            )\n</code></pre>"},{"location":"Functions/pl/markerCorrelation/","title":"markerCorrelation","text":"<p>Short Description</p> <p>The <code>sm.pl.markerCorrelation</code> function computes and visualizes the correlation among selected markers (genes, proteins, etc.) within an <code>AnnData</code> object.</p>"},{"location":"Functions/pl/markerCorrelation/#scimap.plotting.markerCorrelation--function","title":"Function","text":""},{"location":"Functions/pl/markerCorrelation/#scimap.plotting.markerCorrelation.markerCorrelation","title":"<code>markerCorrelation(adata, layer='log', subsetMarkers=None, orderRow=None, orderColumn=None, clusterRows=True, clusterColumns=True, cmap='vlag', figsize=None, overlayValues=False, fontSize=10, fontColor='black', fileName='markerCorrelation.pdf', saveDir=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData or str</code> <p>An AnnData object containing the dataset, or a string path to an AnnData file to be loaded.</p> required <code>layer</code> <code>str</code> <p>Specifies the layer of <code>adata</code> to use for the heatmap. If None, the <code>.X</code> attribute is used. If you want to plot the raw data use <code>raw</code></p> <code>'log'</code> <code>subsetMarkers</code> <code>list of str</code> <p>A list of marker names to include in the correlation analysis. If None, all markers are used.</p> <code>None</code> <code>orderRow</code> <code>list of str</code> <p>Specifies a custom order for the rows (markers) based on their names.</p> <code>None</code> <code>orderColumn</code> <code>list of str</code> <p>Specifies a custom order for the columns (markers) based on their names.</p> <code>None</code> <code>clusterRows</code> <code>bool</code> <p>Whether to apply hierarchical clustering to rows.</p> <code>True</code> <code>clusterColumns</code> <code>bool</code> <p>Whether to apply hierarchical clustering to columns.</p> <code>True</code> <code>cmap</code> <code>str</code> <p>The colormap for the heatmap.</p> <code>'vlag'</code> <code>figsize</code> <code>tuple of float</code> <p>The size of the figure to create. If None, the size is inferred based on the data.</p> <code>None</code> <code>overlayValues</code> <code>bool</code> <p>If True, overlays the actual correlation values on the heatmap.</p> <code>False</code> <code>fontSize</code> <code>int</code> <p>Font size for the overlay values.</p> <code>10</code> <code>fontColor</code> <code>str</code> <p>Color of the font used for overlay values.</p> <code>'black'</code> <code>fileName</code> <code>str</code> <p>Name of the file to save the heatmap. Relevant only if <code>saveDir</code> is not None.</p> <code>'markerCorrelation.pdf'</code> <code>saveDir</code> <code>str</code> <p>Directory to save the generated heatmap. If None, the heatmap is not saved.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>plot</code> <code>matplotlib</code> <p>Displays or saves a heatmap visualizing the correlation between specified markers.</p> Example <pre><code>    # Example 1: Basic usage with all markers and default parameters\n    sm.pl.markerCorrelation(adata)\n\n    # Example 2: With subset of markers, custom clustering, and overlaying correlation values\n    sm.pl.markerCorrelation(adata, subsetMarkers=['Marker1', 'Marker2', 'Marker3'], clusterRows=False, overlayValues=True, fontSize=12)\n\n    # Example 3: Saving the heatmap to a specific directory\n    sm.pl.markerCorrelation(adata, fileName='myHeatmap.pdf', saveDir='/path/to/save')\n</code></pre> Source code in <code>scimap/plotting/markerCorrelation.py</code> <pre><code>def markerCorrelation(\n    adata,\n    layer='log',\n    subsetMarkers=None,\n    orderRow=None,\n    orderColumn=None,\n    clusterRows=True,\n    clusterColumns=True,\n    cmap='vlag',\n    figsize=None,\n    overlayValues=False,\n    fontSize=10,\n    fontColor='black',\n    fileName='markerCorrelation.pdf',\n    saveDir=None,\n    **kwargs,\n):\n    \"\"\"\n    Parameters:\n            adata (AnnData or str):\n                An AnnData object containing the dataset, or a string path to an AnnData file to be loaded.\n\n            layer (str, optional):\n                Specifies the layer of `adata` to use for the heatmap. If None, the `.X` attribute is used. If you want to plot the raw data use `raw`\n\n            subsetMarkers (list of str, optional):\n                A list of marker names to include in the correlation analysis. If None, all markers are used.\n\n            orderRow (list of str, optional):\n                Specifies a custom order for the rows (markers) based on their names.\n\n            orderColumn (list of str, optional):\n                Specifies a custom order for the columns (markers) based on their names.\n\n            clusterRows (bool, optional):\n                Whether to apply hierarchical clustering to rows.\n\n            clusterColumns (bool, optional):\n                Whether to apply hierarchical clustering to columns.\n\n            cmap (str, optional):\n                The colormap for the heatmap.\n\n            figsize (tuple of float, optional):\n                The size of the figure to create. If None, the size is inferred based on the data.\n\n            overlayValues (bool, optional):\n                If True, overlays the actual correlation values on the heatmap.\n\n            fontSize (int, optional):\n                Font size for the overlay values.\n\n            fontColor (str, optional):\n                Color of the font used for overlay values.\n\n            fileName (str, optional):\n                Name of the file to save the heatmap. Relevant only if `saveDir` is not None.\n\n            saveDir (str, optional):\n                Directory to save the generated heatmap. If None, the heatmap is not saved.\n\n    Returns:\n            plot (matplotlib):\n                Displays or saves a heatmap visualizing the correlation between specified markers.\n\n    Example:\n        ```python\n\n            # Example 1: Basic usage with all markers and default parameters\n            sm.pl.markerCorrelation(adata)\n\n            # Example 2: With subset of markers, custom clustering, and overlaying correlation values\n            sm.pl.markerCorrelation(adata, subsetMarkers=['Marker1', 'Marker2', 'Marker3'], clusterRows=False, overlayValues=True, fontSize=12)\n\n            # Example 3: Saving the heatmap to a specific directory\n            sm.pl.markerCorrelation(adata, fileName='myHeatmap.pdf', saveDir='/path/to/save')\n\n        ```\n    \"\"\"\n\n    # load adata\n    if isinstance(adata, str):\n        adata = ad.read_h5ad(adata)\n\n    # subset the markers if user requests\n    if subsetMarkers:\n        subsetMarkers = (\n            [subsetMarkers] if isinstance(subsetMarkers, str) else subsetMarkers\n        )  # convert to list\n        # isolate the data\n        if layer == 'raw':\n            matrix = adata[:, subsetMarkers].raw.X\n        elif layer is None:\n            matrix = adata[:, subsetMarkers].X\n        else:\n            matrix = adata[:, subsetMarkers].layers[layer]\n    else:\n        # take the whole data if the user does not subset anything\n        if layer == 'raw':\n            matrix = adata.raw.X\n        elif layer is None:\n            matrix = adata.X\n        else:\n            matrix = adata.layers[layer]\n\n    # intialize the markers to be plotted\n    if subsetMarkers is None:\n        var_names = adata.var_names.tolist()\n    else:\n        var_names = subsetMarkers\n\n    # run correlation\n    corr_matrix = np.corrcoef(matrix.T)\n\n    row_order = np.arange(corr_matrix.shape[0])\n    col_order = np.arange(corr_matrix.shape[1])\n\n    if orderRow:\n        if clusterRows:\n            warnings.warn(\n                \"Both orderRow and clusterRows were provided. Proceeding with orderRow and ignoring clusterRows.\"\n            )\n            clusterRows = False\n        row_order = [var_names.index(name) for name in orderRow]\n\n    if orderColumn:\n        if clusterColumns:\n            warnings.warn(\n                \"Both orderColumn and clusterColumns were provided. Proceeding with orderColumn and ignoring clusterColumns.\"\n            )\n            clusterColumns = False\n        col_order = [var_names.index(name) for name in orderColumn]\n\n    corr_matrix = corr_matrix[np.ix_(row_order, col_order)]\n\n    if clusterRows:\n        linkage_row = linkage(pdist(corr_matrix), method='average')\n        row_order = dendrogram(linkage_row, no_plot=True)['leaves']\n        corr_matrix = corr_matrix[row_order, :]\n\n    if clusterColumns:\n        linkage_col = linkage(pdist(corr_matrix.T), method='average')\n        col_order = dendrogram(linkage_col, no_plot=True)['leaves']\n        corr_matrix = corr_matrix[:, col_order]\n\n    if figsize is None:\n        base_size = 0.5  # Base size for each cell in inches\n        figsize_width = max(10, len(corr_matrix) * base_size)\n        figsize_height = max(8, len(corr_matrix) * base_size)\n        figsize = (figsize_width, figsize_height)\n\n    plt.figure(figsize=figsize)\n    im = plt.imshow(corr_matrix, cmap=cmap, aspect='auto', **kwargs)\n    plt.colorbar(im)\n\n    if overlayValues:\n        for i in range(corr_matrix.shape[0]):\n            for j in range(corr_matrix.shape[1]):\n                text = plt.text(\n                    j,\n                    i,\n                    f\"{corr_matrix[i, j]:.2f}\",\n                    ha=\"center\",\n                    va=\"center\",\n                    color=fontColor,\n                    fontsize=fontSize,\n                )\n\n    plt.xticks(\n        ticks=np.arange(len(col_order)),\n        labels=np.array(var_names)[col_order],\n        rotation=90,\n    )\n    plt.yticks(ticks=np.arange(len(row_order)), labels=np.array(var_names)[row_order])\n    plt.tight_layout()\n\n    # Saving the figure if saveDir and fileName are provided\n    if saveDir:\n        if not os.path.exists(saveDir):\n            os.makedirs(saveDir)\n        full_path = os.path.join(saveDir, fileName)\n        plt.savefig(full_path, dpi=300)\n        plt.close()\n        print(f\"Saved plot to {full_path}\")\n    else:\n        plt.show()\n</code></pre>"},{"location":"Functions/pl/napariGater/","title":"napariGater","text":"<p>Short Description</p> <p><code>sm.pl.napariGater()</code>: This function leverages Napari to display OME-TIFF images,  overlaying points that assist in manually determining gating thresholds for specific markers.  By visualizing marker expression spatially, users can more accurately define gates.  Subsequently, the identified gating parameters can be applied to the dataset using <code>sm.pp.rescale</code>,  enabling precise control over data segmentation and analysis based on marker expression levels.</p> <p>Replacement for <code>sm.pl.gate_finder()</code></p>"},{"location":"Functions/pl/napariGater/#scimap.plotting.napariGater.napariGater","title":"<code>napariGater(image_path, adata, layer='raw', log=True, x_coordinate='X_centroid', y_coordinate='Y_centroid', imageid='imageid', subset=None, flip_y=True, channel_names='default', point_size=10, calculate_contrast=True, verbose=False)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>Path to the high-resolution multi-channel image (TIFF or OME-TIFF supported).</p> required <code>adata</code> <code>AnnData</code> <p>Annotated data matrix containing single-cell expression and spatial metadata.</p> required <code>layer</code> <code>str</code> <p>Specifies which layer in <code>adata</code> to use for expression data (e.g., 'raw' or a named layer). Defaults to 'raw'.</p> <code>'raw'</code> <code>log</code> <code>bool</code> <p>If True, applies a log1p transformation to expression values before visualization. Defaults to True.</p> <code>True</code> <code>x_coordinate,</code> <code>y_coordinate (str</code> <p>Keys in <code>adata.obs</code> specifying X and Y spatial coordinates of cells. Defaults are 'X_centroid' and 'Y_centroid'.</p> required <code>imageid</code> <code>str</code> <p>Column name in <code>adata.obs</code> indicating the image source (used for filtering and metadata grouping). Defaults to 'imageid'.</p> <code>'imageid'</code> <code>subset</code> <code>str</code> <p>Specific image ID or sample name to filter and visualize. If None, uses the first available entry in <code>adata.obs[imageid]</code>.</p> <code>None</code> <code>flip_y</code> <code>bool</code> <p>If True, inverts the Y-axis to match image coordinate system. Defaults to True.</p> <code>True</code> <code>channel_names</code> <code>list or str</code> <p>List of marker/channel names corresponding to the order in the image.  Defaults to 'default', which uses <code>adata.uns['all_markers']</code>.</p> <code>'default'</code> <code>point_size</code> <code>int</code> <p>Size of the points representing gated cells. Defaults to 10.</p> <code>10</code> <code>calculate_contrast</code> <code>bool</code> <p>If True, contrast settings are estimated automatically for each channel. If False, existing settings in <code>adata.uns</code> are reused or defaulted. Defaults to True.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>If True, prints detailed information about data ranges and transformations.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>None</code> <p>Launches an interactive napari viewer for manual gate threshold adjustment. The gating values are stored in <code>adata.uns['gates']</code>, and user edits are tracked under <code>adata.uns['napariGaterProvenance']</code>.</p> Example <pre><code># Launch napariGater with default settings\nsm.pl.napariGater('/path/to/image.ome.tif', adata=adata)\n\n# Use expression layer, flip Y-axis off, and focus on a specific sample\nsm.pl.napariGater('/path/to/image.tif', adata=adata, layer='expression',\n                  flip_y=False, subset='Sample_A')\n\n# Specify custom channels and disable contrast calculation\nsm.pl.napariGater('/path/to/image.tif', adata=adata,\n                  channel_names=['DAPI', 'CD45', 'CD3'], calculate_contrast=False)\n</code></pre> Source code in <code>scimap/plotting/napariGater.py</code> <pre><code>def napariGater(\n    image_path,\n    adata,\n    layer='raw',\n    log=True,\n    x_coordinate='X_centroid',\n    y_coordinate='Y_centroid',\n    imageid='imageid',\n    subset=None,\n    flip_y=True,\n    channel_names='default',\n    point_size=10,\n    calculate_contrast=True,\n    verbose=False\n):\n\n    \"\"\"    \n    Parameters:\n        image_path (str):\n            Path to the high-resolution multi-channel image (TIFF or OME-TIFF supported).\n\n        adata (anndata.AnnData):\n            Annotated data matrix containing single-cell expression and spatial metadata.\n\n        layer (str, optional):\n            Specifies which layer in `adata` to use for expression data (e.g., 'raw' or a named layer). Defaults to 'raw'.\n\n        log (bool, optional):\n            If True, applies a log1p transformation to expression values before visualization. Defaults to True.\n\n        x_coordinate, y_coordinate (str, optional):\n            Keys in `adata.obs` specifying X and Y spatial coordinates of cells. Defaults are 'X_centroid' and 'Y_centroid'.\n\n        imageid (str, optional):\n            Column name in `adata.obs` indicating the image source (used for filtering and metadata grouping). Defaults to 'imageid'.\n\n        subset (str, optional):\n            Specific image ID or sample name to filter and visualize. If None, uses the first available entry in `adata.obs[imageid]`.\n\n        flip_y (bool, optional):\n            If True, inverts the Y-axis to match image coordinate system. Defaults to True.\n\n        channel_names (list or str, optional):\n            List of marker/channel names corresponding to the order in the image. \n            Defaults to 'default', which uses `adata.uns['all_markers']`.\n\n        point_size (int, optional):\n            Size of the points representing gated cells. Defaults to 10.\n\n        calculate_contrast (bool, optional):\n            If True, contrast settings are estimated automatically for each channel. If False, existing settings in `adata.uns` are reused or defaulted. Defaults to True.\n\n        verbose (bool, optional):\n            If True, prints detailed information about data ranges and transformations.\n\n    Returns:\n        None:\n            Launches an interactive napari viewer for manual gate threshold adjustment.\n            The gating values are stored in `adata.uns['gates']`, and user edits are tracked under `adata.uns['napariGaterProvenance']`.\n\n    Example:\n        ```python\n        # Launch napariGater with default settings\n        sm.pl.napariGater('/path/to/image.ome.tif', adata=adata)\n\n        # Use expression layer, flip Y-axis off, and focus on a specific sample\n        sm.pl.napariGater('/path/to/image.tif', adata=adata, layer='expression',\n                          flip_y=False, subset='Sample_A')\n\n        # Specify custom channels and disable contrast calculation\n        sm.pl.napariGater('/path/to/image.tif', adata=adata,\n                          channel_names=['DAPI', 'CD45', 'CD3'], calculate_contrast=False)\n        ```\n\"\"\"\n\n    os.environ['QT_MAC_WANTS_LAYER'] = '1'\n\n    warnings.warn(\n        \"NOTE: napariGater() is currently in beta testing. \"\n        \"If you encounter any issues, please report them at: \"\n        \"https://github.com/labsyspharm/scimap/issues\",\n        UserWarning,\n        stacklevel=2,\n    )\n\n    print(\"Initializing...\")\n    start_time = time.time()\n\n    # Initialize gates with the chosen layer and log settings.\n    adata = initialize_gates(adata, imageid, layer, log, verbose)\n\n    if channel_names == 'default':\n        channel_names = adata.uns['all_markers']\n    else:\n        channel_names = channel_names \n\n    print(\"Loading image data...\")\n    img_data, tiff_file, multiscale = load_image_efficiently(image_path)\n    if img_data is None:\n        raise ValueError(\"Failed to load image data\")\n\n    current_image = adata.obs[imageid].iloc[0] if subset is None else subset\n\n    if calculate_contrast:\n        print(\"Calculating contrast settings...\")\n        adata = initialize_contrast_settings(\n            adata,\n            img_data,\n            channel_names,\n            imageid=imageid,\n            subset=subset,\n        )\n    else:\n        if 'image_contrast_settings' not in adata.uns:\n            adata.uns['image_contrast_settings'] = {}\n        current_image = adata.obs[imageid].iloc[0] if subset is None else subset\n        should_initialize = False\n        if current_image not in adata.uns['image_contrast_settings']:\n            should_initialize = True\n        else:\n            existing_channels = set(adata.uns['image_contrast_settings'][current_image].keys())\n            new_channels = set(channel_names)\n            missing_channels = new_channels - existing_channels\n            if missing_channels:\n                print(f\"Adding default contrast settings for new channels: {missing_channels}\")\n                should_initialize = True\n        if should_initialize:\n            contrast_settings = adata.uns['image_contrast_settings'].get(current_image, {})\n            for channel in channel_names:\n                if channel not in contrast_settings:\n                    try:\n                        if isinstance(img_data, list):\n                            channel_idx = channel_names.index(channel)\n                            channel_data = img_data[-1][channel_idx]\n                            if hasattr(channel_data, 'compute'):\n                                min_val = float(channel_data.min().compute())\n                                max_val = float(channel_data.max().compute())\n                            else:\n                                min_val = float(channel_data.min())\n                                max_val = float(channel_data.max())\n                        else:\n                            channel_idx = channel_names.index(channel)\n                            min_val = float(img_data[channel_idx].min())\n                            max_val = float(img_data[channel_idx].max())\n                    except Exception as e:\n                        print(f\"Warning: Could not determine data range for {channel}, using defaults. Error: {str(e)}\")\n                        min_val, max_val = 0.0, 1.0\n                    contrast_settings[channel] = {'low': min_val, 'high': max_val}\n            adata.uns['image_contrast_settings'][current_image] = contrast_settings\n            print(f\"Initialized contrast settings for {current_image} with {len(channel_names)} channels\")\n\n    print(f\"Initialization completed in {time.time() - start_time:.2f} seconds\")\n    print(\"Opening napari viewer...\")\n\n    viewer = napari.Viewer()\n\n    default_colormaps = [\n        'magenta', 'cyan', 'yellow', 'red', 'green', 'blue',\n        'magenta', 'cyan', 'yellow', 'red', 'green', 'blue'\n    ]\n\n    add_channels_to_viewer(\n        viewer,\n        img_data,\n        channel_names,\n        adata.uns['image_contrast_settings'][current_image],\n        colormaps=default_colormaps\n    )\n\n    loaded_channels = [lyr.name for lyr in viewer.layers if isinstance(lyr, napari.layers.Image)]\n    if len(loaded_channels) != len(channel_names):\n        print(f\"\\nWarning: Only loaded {len(loaded_channels)}/{len(channel_names)} channels\")\n        missing = set(channel_names) - set(loaded_channels)\n        if missing:\n            print(f\"Missing channels: {', '.join(missing)}\")\n\n    points_layer = viewer.add_points(\n        np.zeros((0, 2)),\n        size=point_size,\n        face_color='white',\n        name='gated_points',\n        visible=True,\n    )\n\n    # Use the chosen layer when creating the initial marker data.\n    initial_marker = list(adata.var.index)[0]\n    initial_data = get_marker_data(initial_marker, adata, layer, log, verbose)\n\n    # Calculate initial min/max from the specified layer using .iloc[0] for explicit float conversion\n    marker_data = get_marker_data(initial_marker, adata, layer, log, verbose=False)\n    min_val = round(float(marker_data.min().iloc[0]), 2)\n    max_val = round(float(marker_data.max().iloc[0]), 2)\n\n    current_image = adata.obs[imageid].iloc[0] if subset is None else subset\n    initial_gate = adata.uns['gates'].loc[initial_marker, current_image]\n    if pd.isna(initial_gate) or initial_gate &lt; min_val or initial_gate &gt; max_val:\n        initial_gate = min_val\n    else:\n        initial_gate = round(float(initial_gate), 2)\n\n    @magicgui(\n        auto_call=True,\n        layout='vertical',\n        marker={\n            'choices': list(adata.var.index), \n            'value': initial_marker,\n            'label': 'Select Marker:'\n        },\n        gate={\n            'widget_type': 'FloatSpinBox',\n            'min': min_val,\n            'max': max_val,\n            'value': initial_gate,\n            'step': 0.01,\n            'label': 'Gate Threshold:'\n        },\n        marker_status={\n            'widget_type': 'Label',\n            'value': '\u26aa Not adjusted'\n        },\n        confirm_gate={\n            'widget_type': 'PushButton', \n            'text': 'Confirm Gate'\n        },\n        finish={\n            'widget_type': 'PushButton', \n            'text': 'Finish Gating'\n        },\n    )\n    def gate_controls(\n        marker: str,\n        gate: float = initial_gate,\n        marker_status: str = '\u26aa Not adjusted',\n        confirm_gate=False,\n        finish=False,\n    ):\n        data = get_marker_data(marker, adata, layer, log, verbose)\n        if subset is not None:\n            mask = adata.obs[imageid] == subset\n            data = data[mask]\n        mask = data.values &gt;= gate\n        cells = data.index[mask.flatten()]\n        coordinates = adata[cells]\n        if flip_y:\n            coordinates = pd.DataFrame(\n                {'y': coordinates.obs[y_coordinate], 'x': coordinates.obs[x_coordinate]}\n            )\n        else:\n            coordinates = pd.DataFrame(\n                {'x': coordinates.obs[x_coordinate], 'y': coordinates.obs[y_coordinate]}\n            )\n        points_layer.data = coordinates.values\n\n\n\n\n    # Create the histogram figure and canvas\n    hist_fig = Figure()\n    hist_canvas = FigureCanvas(hist_fig)\n    hist_ax = hist_fig.add_subplot(111)\n\n    # QLabel to show the gate threshold outside the plot\n    gate_label = QLabel(\"Gate Threshold: N/A\")\n    gate_label.setAlignment(Qt.AlignCenter)\n    gate_label.setStyleSheet(\"color: white; font-size: 15pt; padding-top: 1px;\")\n\n    # Create and configure the Qt layout\n    hist_widget = QWidget()\n    hist_layout = QVBoxLayout()\n    hist_layout.addWidget(hist_canvas)\n    hist_layout.addWidget(gate_label)\n    hist_widget.setLayout(hist_layout)\n    hist_widget.setMinimumHeight(350)\n    hist_widget.setMinimumWidth(350)\n\n    # Define the histogram update function\n    def update_histogram(marker: str, gate_value: float = None):\n        hist_ax.clear()\n        data = get_marker_data(marker, adata, layer, log, verbose)\n        if subset is not None:\n            data = data[adata.obs[imageid] == subset]\n        flat_data = data.values.flatten()\n\n        # Exclude outliers using 0.1\u201399th percentile\n        p_low, p_high = np.percentile(flat_data, [1, 99.99])\n        flat_data = flat_data[(flat_data &gt;= p_low) &amp; (flat_data &lt;= p_high)]\n\n        # Plot histogram\n        hist_ax.hist(flat_data, bins=100, color='#264653', edgecolor='#2a9d8f')\n\n        # Gate line\n        if gate_value is None:\n            gate_value = adata.uns['gates'].loc[marker, current_image]\n        if pd.notna(gate_value):\n            hist_ax.axvline(gate_value, color='#582f0e', linewidth=0.75)\n            gate_label.setText(f\"Gate Threshold: {gate_value:.2f}\")\n        else:\n            gate_label.setText(\"Gate Threshold: N/A\")\n\n        # Dynamic font scaling (clamped)\n        canvas_width = hist_canvas.width() / hist_canvas.devicePixelRatioF()\n        font_size = min(10, max(6, int(canvas_width / 45)))\n\n        # Axis and title labels\n        title = f'{marker} (log scale)' if log else marker\n        hist_ax.set_title(title, fontsize=font_size)\n        hist_ax.set_xlabel('Expression', fontsize=font_size)\n        hist_ax.set_ylabel('Cell Count', fontsize=font_size)\n        hist_ax.tick_params(axis='both', labelsize=font_size)\n\n        hist_fig.tight_layout()\n        hist_canvas.draw()\n\n    # Redraw on resize\n    def _resize_event(event):\n        update_histogram(gate_controls.marker.value, gate_controls.gate.value)\n        return super(FigureCanvas, hist_canvas).resizeEvent(event)\n\n    hist_canvas.resizeEvent = _resize_event\n\n\n\n\n\n\n    @gate_controls.marker.changed.connect\n    def _on_marker_change(marker: str):\n        current_state = {\n            'zoom': viewer.camera.zoom,\n            'center': viewer.camera.center\n        }\n        marker_data = get_marker_data(marker, adata, layer, log, verbose=False)\n        min_val = round(float(marker_data.min().iloc[0]), 2)\n        max_val = round(float(marker_data.max().iloc[0]), 2)\n        current_image = adata.obs[imageid].iloc[0] if subset is None else subset\n        existing_gate = adata.uns['gates'].loc[marker, current_image]\n        value = existing_gate if (not pd.isna(existing_gate) and min_val &lt;= existing_gate &lt;= max_val) else min_val\n        gate_controls.gate.min = min_val\n        gate_controls.gate.max = max_val\n        gate_controls.gate.value = round(float(value), 2)\n        for lyr in viewer.layers:\n            if isinstance(lyr, napari.layers.Image):\n                if lyr.name == marker:\n                    lyr.visible = True\n                    viewer.layers.selection.active = lyr\n                    viewer.layers.selection.clear()\n                    viewer.layers.selection.add(lyr)\n                else:\n                    lyr.visible = False\n        viewer.camera.zoom = current_state['zoom']\n        viewer.camera.center = current_state['center']\n        current_image = adata.obs[imageid].iloc[0] if subset is None else subset\n        is_adjusted = marker in adata.uns['napariGaterProvenance']['manually_adjusted'].get(current_image, {})\n        if is_adjusted:\n            status_text = \"\u2713 ADJUSTED\"\n            timestamp = adata.uns['napariGaterProvenance']['timestamp'][current_image][marker]\n            from datetime import datetime\n            try:\n                dt = datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\")\n                short_timestamp = dt.strftime(\"%y-%m-%d %H:%M\")\n                status_text += f\" ({short_timestamp})\"\n            except:\n                status_text += f\" ({timestamp})\"\n        else:\n            status_text = \"\u26aa NOT ADJUSTED\"\n        gate_controls.marker_status.value = status_text\n        update_histogram(marker, gate_controls.gate.value)\n\n    @gate_controls.gate.changed.connect\n    def _on_gate_change(gate: float):\n        marker = gate_controls.marker.value\n        update_histogram(marker, gate)\n\n    @gate_controls.confirm_gate.clicked.connect\n    def _on_confirm():\n        marker = gate_controls.marker.value\n        gate = gate_controls.gate.value\n        current_image = adata.obs[imageid].iloc[0] if subset is None else subset\n        adata.uns['gates'].loc[marker, current_image] = float(gate)\n        from datetime import datetime\n        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        if current_image not in adata.uns['napariGaterProvenance']['manually_adjusted']:\n            adata.uns['napariGaterProvenance']['manually_adjusted'][current_image] = {}\n        if current_image not in adata.uns['napariGaterProvenance']['timestamp']:\n            adata.uns['napariGaterProvenance']['timestamp'][current_image] = {}\n        if current_image not in adata.uns['napariGaterProvenance']['original_values']:\n            adata.uns['napariGaterProvenance']['original_values'][current_image] = {}\n        adata.uns['napariGaterProvenance']['manually_adjusted'][current_image][marker] = float(gate)\n        adata.uns['napariGaterProvenance']['timestamp'][current_image][marker] = timestamp\n        if marker not in adata.uns['napariGaterProvenance']['original_values'][current_image]:\n            original_value = float(adata.uns['gates'].loc[marker, current_image])\n            adata.uns['napariGaterProvenance']['original_values'][current_image][marker] = original_value\n        short_timestamp = (datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\")\n                           .strftime(\"%y-%m-%d %H:%M\"))\n        gate_controls.marker_status.value = f\"\u2713 ADJUSTED ({short_timestamp})\"\n        print(f\"Gate confirmed for {marker} at {gate:.2f}\")\n\n    @gate_controls.finish.clicked.connect\n    def _on_finish():\n        viewer.close()\n\n    points_layer.data = np.zeros((0, 2))\n    viewer.window.add_dock_widget(gate_controls, name='Gate Controls')\n    viewer.window.add_dock_widget(hist_widget, name='Marker Histogram')\n    napari.run()\n\n    print(f\"Napari viewer initialized in {time.time() - start_time:.2f} seconds\")\n</code></pre>"},{"location":"Functions/pl/pie/","title":"pie","text":"<p>Short Description</p> <p><code>sm.pl.pie</code>: This function facilitates the creation of pie charts to visually  represent the proportions of categories within any selected categorical column in  an AnnData object. It provides an intuitive and straightforward way to assess  the distribution of cell types, clusters, or any other categorical annotations,  offering insights into the composition of the dataset.</p>"},{"location":"Functions/pl/pie/#scimap.plotting.pie--function","title":"Function","text":""},{"location":"Functions/pl/pie/#scimap.plotting.pie.pie","title":"<code>pie(adata, phenotype='phenotype', group_by='imageid', ncols=None, subset_phenotype=None, subset_groupby=None, label='auto', title='auto', colors=None, autopct='%1.1f%%', legend=False, legend_loc='upper right', wedgeprops={'linewidth': 0}, fileName='pie.pdf', saveDir=None, return_data=False, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The annotated data matrix.</p> required <code>phenotype</code> <code>str</code> <p>Column in <code>adata.obs</code> containing the categorical data for pie chart visualization.</p> <code>'phenotype'</code> <code>group_by</code> <code>str</code> <p>Column in <code>adata.obs</code> for defining groups. Each group will have its own pie chart. Default is 'imageid'. Pass None to treat all data as a single group.</p> <code>'imageid'</code> <code>ncols</code> <code>int</code> <p>Number of columns in the grid layout when displaying multiple pie charts. Only applicable if <code>group_by</code> is used.</p> <code>None</code> <code>subset_phenotype</code> <code>list</code> <p>List of categories within <code>phenotype</code> to include in the visualization.</p> <code>None</code> <code>subset_groupby</code> <code>list</code> <p>List of groups within <code>group_by</code> to include in the visualization.</p> <code>None</code> <code>label</code> <code>list</code> <p>Labels for each wedge in the pie charts. If 'auto', labels are automatically derived from <code>phenotype</code> categories.</p> <code>'auto'</code> <code>title</code> <code>str</code> <p>Title for the pie chart(s). If 'auto', titles are derived from <code>group_by</code> categories.</p> <code>'auto'</code> <code>colors</code> <code>list</code> <p>Custom color sequence for the pie chart wedges.</p> <code>None</code> <code>autopct</code> <code>str or callable</code> <p>String or function used to label wedges with their numeric value. Default is '%1.1f%%'.</p> <code>'%1.1f%%'</code> <code>legend</code> <code>bool</code> <p>Whether to display a legend for the pie chart. Default is False.</p> <code>False</code> <code>legend_loc</code> <code>str</code> <p>Location of the legend. Default is 'upper right'.</p> <code>'upper right'</code> <code>wedgeprops</code> <code>dict</code> <p>Properties passed to the wedge objects, such as <code>{'linewidth': 3}</code>.</p> <code>{'linewidth': 0}</code> <code>return_data</code> <code>bool</code> <p>If True, returns the data used for plotting instead of the pie chart(s).</p> <code>False</code> <code>fileName</code> <code>str</code> <p>Name of the file to save the plot. Relevant only if <code>saveDir</code> is not None.</p> <code>'pie.pdf'</code> <code>saveDir</code> <code>str</code> <p>Directory to save the generated plot. If None, the plot is not saved.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to <code>matplotlib.pyplot.pie</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <p>plot and dataFrame (matplotlib, pandas DF): If <code>return_data</code> is True, returns a pandas DataFrame used for plotting.</p> Example <pre><code># Basic pie chart visualization of cell phenotypes\nsm.pl.pie(adata, phenotype='cell_type', group_by='sample_id', ncols=3)\n\n# Advanced visualization with custom colors and pie chart properties\nsm.pl.pie(adata, phenotype='cell_type', group_by='condition', ncols=4, colors=['#ff9999','#66b3ff','#99ff99'],\n          wedgeprops={'edgecolor': 'black', 'linewidth': 2}, autopct='%1.1f%%', legend=True, legend_loc='best')\n\n# Subsetted visualization focusing on specific phenotypes and groups\nsm.pl.pie(adata, phenotype='cell_type', group_by='treatment', subset_phenotype=['T cells', 'B cells'],\n          subset_groupby=['Control', 'Treated'], ncols=2, legend=True, legend_loc='lower left')\n</code></pre> Source code in <code>scimap/plotting/pie.py</code> <pre><code>def pie(\n    adata,\n    phenotype='phenotype',\n    group_by='imageid',\n    ncols=None,\n    subset_phenotype=None,\n    subset_groupby=None,\n    label='auto',\n    title='auto',\n    colors=None,\n    autopct='%1.1f%%',\n    legend=False,\n    legend_loc='upper right',\n    wedgeprops={'linewidth': 0},\n    fileName='pie.pdf',\n    saveDir=None,\n    return_data=False,\n    **kwargs,\n):\n    \"\"\"\n    Parameters:\n            adata (anndata.AnnData):\n                The annotated data matrix.\n\n            phenotype (str, optional):\n                Column in `adata.obs` containing the categorical data for pie chart visualization.\n\n            group_by (str, optional):\n                Column in `adata.obs` for defining groups. Each group will have its own pie chart.\n                Default is 'imageid'. Pass None to treat all data as a single group.\n\n            ncols (int, optional):\n                Number of columns in the grid layout when displaying multiple pie charts.\n                Only applicable if `group_by` is used.\n\n            subset_phenotype (list, optional):\n                List of categories within `phenotype` to include in the visualization.\n\n            subset_groupby (list, optional):\n                List of groups within `group_by` to include in the visualization.\n\n            label (list, optional):\n                Labels for each wedge in the pie charts. If 'auto', labels are automatically\n                derived from `phenotype` categories.\n\n            title (str, optional):\n                Title for the pie chart(s). If 'auto', titles are derived from `group_by` categories.\n\n            colors (list, optional):\n                Custom color sequence for the pie chart wedges.\n\n            autopct (str or callable, optional):\n                String or function used to label wedges with their numeric value. Default is '%1.1f%%'.\n\n            legend (bool, optional):\n                Whether to display a legend for the pie chart. Default is False.\n\n            legend_loc (str, optional):\n                Location of the legend. Default is 'upper right'.\n\n            wedgeprops (dict, optional):\n                Properties passed to the wedge objects, such as `{'linewidth': 3}`.\n\n            return_data (bool, optional):\n                If True, returns the data used for plotting instead of the pie chart(s).\n\n            fileName (str, optional):\n                Name of the file to save the plot. Relevant only if `saveDir` is not None.\n\n            saveDir (str, optional):\n                Directory to save the generated plot. If None, the plot is not saved.\n\n            **kwargs:\n                Additional keyword arguments passed to `matplotlib.pyplot.pie`.\n\n    Returns:\n        plot and dataFrame (matplotlib, pandas DF):\n            If `return_data` is True, returns a pandas DataFrame used for plotting.\n\n    Example:\n        ```python\n\n        # Basic pie chart visualization of cell phenotypes\n        sm.pl.pie(adata, phenotype='cell_type', group_by='sample_id', ncols=3)\n\n        # Advanced visualization with custom colors and pie chart properties\n        sm.pl.pie(adata, phenotype='cell_type', group_by='condition', ncols=4, colors=['#ff9999','#66b3ff','#99ff99'],\n                  wedgeprops={'edgecolor': 'black', 'linewidth': 2}, autopct='%1.1f%%', legend=True, legend_loc='best')\n\n        # Subsetted visualization focusing on specific phenotypes and groups\n        sm.pl.pie(adata, phenotype='cell_type', group_by='treatment', subset_phenotype=['T cells', 'B cells'],\n                  subset_groupby=['Control', 'Treated'], ncols=2, legend=True, legend_loc='lower left')\n\n        ```\n    \"\"\"\n\n    # convert subset into list\n    if subset_phenotype is not None:\n        if isinstance(subset_phenotype, str):\n            subset_phenotype = [subset_phenotype]\n    if subset_groupby is not None:\n        if isinstance(subset_groupby, str):\n            subset_groupby = [subset_groupby]\n\n    # create copy of the required data\n    if group_by is not None:\n        data = adata.obs[[phenotype, group_by]]\n    else:\n        data = adata.obs[[phenotype]]\n\n    # subset data if needed\n    if subset_groupby is not None:\n        data = data[data[group_by].isin(subset_groupby)]\n        data[group_by] = data[group_by].astype('str').astype('category')\n        data[group_by] = data[group_by].cat.reorder_categories(subset_groupby)\n        data = data.sort_values(group_by)\n    if subset_phenotype is not None:\n        data = data[data[phenotype].isin(subset_phenotype)]\n        data[phenotype] = data[phenotype].astype('str').astype('category')\n        data[phenotype] = data[phenotype].cat.reorder_categories(subset_phenotype)\n        data = data.sort_values(phenotype)\n    if group_by and phenotype is not None:\n        data = data.sort_values([phenotype, group_by])\n\n    # calculate the proportion\n    if group_by is None:\n        prop = data[phenotype].value_counts().reset_index(inplace=False)\n        prop.columns = [phenotype, 'value']\n        prop['group_by'] = phenotype\n        labels = np.unique(prop[phenotype])\n\n    else:\n        # if group_by is provided\n        prop = pd.DataFrame(\n            data.groupby([group_by, phenotype], observed=False).size()\n        ).reset_index(inplace=False)\n        prop.columns = ['group_by', phenotype, 'value']\n        labels = np.unique(prop[phenotype])\n        #\n        if ncols is not None:\n            g = prop.groupby('group_by', observed=False)\n            rows = int(np.ceil(len(g) / ncols))\n        else:\n            g = prop.groupby('group_by', observed=False)\n            rows = 1\n            ncols = len(g)\n\n    # remove label if requested\n    if label == 'auto':\n        label = labels\n    elif label is None:\n        label = None\n    else:\n        label = label\n\n    # plot\n    if group_by is None:\n        fig, ax = plt.subplots()\n        ax.pie(prop.value, labels=label, colors=colors, wedgeprops=wedgeprops)\n        # ax.pie(prop.value, labels=label,colors=colors, wedgeprops = wedgeprops, **kwargs)\n        if title is None:\n            pass\n        else:\n            ax.set_title(phenotype)\n    else:\n        # plot the figure\n        # Ground work for removing unwanted axes\n        total_axes = list(range(ncols * rows))\n        required_axes = list(range(len(np.unique(prop['group_by']))))\n        final_axes = list(set(total_axes) ^ set(required_axes))\n        # Plot\n        fig, axes = plt.subplots(ncols=ncols, nrows=rows)\n        axes = np.atleast_1d(\n            axes\n        )  # This ensures axes is always an array, even if it's a single subplot\n        for (c, grp), ax in zip(g, axes.flat):\n            ax.pie(grp.value, labels=label, colors=colors, wedgeprops=wedgeprops)\n            # ax.pie(grp.value, labels=label, colors=colors, wedgeprops = wedgeprops, **kwargs)\n            if title is None:\n                pass\n            else:\n                ax.set_title(c)\n        # removing unwanted axis\n        for i in final_axes:\n            fig.delaxes(axes.flatten()[i])\n\n        if legend is True:\n            plt.legend(labels, loc=legend_loc, framealpha=1)\n\n    # Saving the figure if saveDir and fileName are provided\n    if saveDir:\n        if not os.path.exists(saveDir):\n            os.makedirs(saveDir)\n        full_path = os.path.join(saveDir, fileName)\n        plt.savefig(full_path, dpi=300)\n        plt.close()\n        print(f\"Saved plot to {full_path}\")\n    else:\n        plt.show()\n\n    # return data\n    if return_data is True:\n        return prop\n</code></pre>"},{"location":"Functions/pl/spatialInteractionNetwork/","title":"spatialInteractionNetwork","text":"<p>Short Description</p> <p>The <code>sm.pl.spatialInteractionNetwork</code> function visualizes spatial interactions as a network graph, highlighting significant interactions between cell types.</p>"},{"location":"Functions/pl/spatialInteractionNetwork/#scimap.plotting.spatialInteractionNetwork--function","title":"Function","text":""},{"location":"Functions/pl/spatialInteractionNetwork/#scimap.plotting.spatialInteractionNetwork.spatialInteractionNetwork","title":"<code>spatialInteractionNetwork(adata, spatial_interaction='spatial_interaction', p_val=0.05, cmap='vlag', nodeColor='#22333b', nodeSize=None, alpha=0.9, figsize=None, fontSize=12, fontColor='white', subsetPhenotype=None, fileName='spatialInteractionNetwork.pdf', saveDir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData or str</code> <p>An AnnData object or a path to an .h5ad file containing the dataset.</p> required <code>spatial_interaction</code> <code>str</code> <p>Key in <code>adata.uns</code> for spatial interaction data.</p> <code>'spatial_interaction'</code> <code>p_val</code> <code>float</code> <p>Threshold for significance of interactions to display.</p> <code>0.05</code> <code>cmap</code> <code>str</code> <p>Colormap for the edges based on their z-scores.</p> <code>'vlag'</code> <code>nodeColor</code> <code>str</code> <p>Color of the nodes.</p> <code>'#22333b'</code> <code>nodeSize</code> <code>int or None</code> <p>Size of the nodes. If None, size is dynamically adjusted.</p> <code>None</code> <code>alpha</code> <code>float</code> <p>Opacity of the nodes.</p> <code>0.9</code> <code>figsize</code> <code>tuple or None</code> <p>Figure size as (width, height). If None, size is dynamically calculated.</p> <code>None</code> <code>fontSize</code> <code>int</code> <p>Font size for node labels.</p> <code>12</code> <code>fontColor</code> <code>str</code> <p>Color of the node labels.</p> <code>'white'</code> <code>subsetPhenotype</code> <code>list of str or None</code> <p>List of phenotypes to include. If None, all are included.</p> <code>None</code> <code>fileName</code> <code>str</code> <p>Filename for saving the network plot.</p> <code>'spatialInteractionNetwork.pdf'</code> <code>saveDir</code> <code>str or None</code> <p>Directory to save the plot file. If None, plot is shown and not saved.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>plot</code> <code>matplotlib</code> <p>Displays or saves a network plot visualizing the interactions between cell types.</p> Example <pre><code># Visualizes the network using the 'coolwarm' colormap.\nsm.pl.spatialInteractionNetwork(adata, cmap='coolwarm')\n\n# Filters for 'T cells' and 'B cells' interactions, saves the visualization as 'T_B_interaction.pdf' in './plots'.\nsm.pl.spatialInteractionNetwork(adata, subsetPhenotype=['T cells', 'B cells'], fileName='T_B_interaction.pdf', saveDir='./plots')\n</code></pre> Source code in <code>scimap/plotting/spatialInteractionNetwork.py</code> <pre><code>def spatialInteractionNetwork(\n    adata,\n    spatial_interaction='spatial_interaction',\n    p_val=0.05,\n    cmap='vlag',\n    nodeColor='#22333b',\n    nodeSize=None,\n    alpha=0.9,\n    figsize=None,\n    fontSize=12,\n    fontColor='white',\n    subsetPhenotype=None,\n    fileName='spatialInteractionNetwork.pdf',\n    saveDir=None,\n):\n    \"\"\"\n    Parameters:\n        adata (AnnData or str):\n            An AnnData object or a path to an .h5ad file containing the dataset.\n\n        spatial_interaction (str):\n            Key in `adata.uns` for spatial interaction data.\n\n        p_val (float):\n            Threshold for significance of interactions to display.\n\n        cmap (str):\n            Colormap for the edges based on their z-scores.\n\n        nodeColor (str):\n            Color of the nodes.\n\n        nodeSize (int or None):\n            Size of the nodes. If None, size is dynamically adjusted.\n\n        alpha (float):\n            Opacity of the nodes.\n\n        figsize (tuple or None):\n            Figure size as (width, height). If None, size is dynamically calculated.\n\n        fontSize (int):\n            Font size for node labels.\n\n        fontColor (str):\n            Color of the node labels.\n\n        subsetPhenotype (list of str or None):\n            List of phenotypes to include. If None, all are included.\n\n        fileName (str):\n            Filename for saving the network plot.\n\n        saveDir (str or None):\n            Directory to save the plot file. If None, plot is shown and not saved.\n\n    Returns:\n            plot (matplotlib):\n                Displays or saves a network plot visualizing the interactions between cell types.\n\n    Example:\n        ```python\n\n        # Visualizes the network using the 'coolwarm' colormap.\n        sm.pl.spatialInteractionNetwork(adata, cmap='coolwarm')\n\n        # Filters for 'T cells' and 'B cells' interactions, saves the visualization as 'T_B_interaction.pdf' in './plots'.\n        sm.pl.spatialInteractionNetwork(adata, subsetPhenotype=['T cells', 'B cells'], fileName='T_B_interaction.pdf', saveDir='./plots')\n        ```\n    \"\"\"\n\n    # Load adata if a path is provided\n    if isinstance(adata, str):\n        adata = ad.read_h5ad(adata)\n\n    # create a copy of the distance measurement\n    if spatial_interaction not in adata.uns:\n        raise KeyError(\n            f\"{spatial_interaction} does not exist in adata.uns. Please check if the '{spatial_interaction}' column exists or run `sm.tl.spatial_interaction(adata)` to compute it.\"\n        )\n\n    # copy the data to plot\n    df = adata.uns[spatial_interaction].copy()\n\n    # subset\n    if subsetPhenotype:\n        if isinstance(subsetPhenotype, str):\n            subsetPhenotype = [subsetPhenotype]\n        df = df[\n            df['phenotype'].isin(subsetPhenotype)\n            &amp; df['neighbour_phenotype'].isin(subsetPhenotype)\n        ]\n        # Convert to categorical if not already\n        df['phenotype'] = df['phenotype'].astype('str').astype('category')\n        df['neighbour_phenotype'] = (\n            df['neighbour_phenotype'].astype('str').astype('category')\n        )\n\n    # now calculate a meta score across images\n    # Automatically identify z-score and p-value columns\n    z_score_columns = [\n        col\n        for col in df.columns\n        if 'pvalue_' not in col and col not in ['phenotype', 'neighbour_phenotype']\n    ]\n    p_value_columns = [col for col in df.columns if 'pvalue_' in col]\n\n    # Ensure there is a matching p-value column for each z-score column\n    assert len(z_score_columns) == len(\n        p_value_columns\n    ), \"The number of z-score columns does not match the number of p-value columns.\"\n\n    def stouffers_method(z_scores):\n        \"\"\"Combines z-scores using Stouffer's method.\"\"\"\n        combined_z = np.sum(z_scores) / np.sqrt(len(z_scores))\n        return combined_z\n\n    def combine_z_scores(row):\n        \"\"\"Extracts and combines z-scores from the row.\"\"\"\n        z_scores = row[z_score_columns].values\n        combined_z = stouffers_method(z_scores)\n        return combined_z\n\n    def combine_p_values(row, p_value_columns):\n        \"\"\"Extracts p-values from the row and combines them using Fisher's method.\"\"\"\n        p_values = [\n            row[col] for col in p_value_columns\n        ]  # Extract p-values for the specified columns\n\n        # Convert to a NumPy array and ensure type float for NaN handling\n        p_values_array = np.array(p_values, dtype=float)\n\n        # Filter out NaN values before combining\n        p_values_filtered = p_values_array[~np.isnan(p_values_array)]\n\n        # Check if filtered array is empty\n        if p_values_filtered.size == 0:\n            return np.nan  # Return NaN if there are no valid p-values to combine\n\n        # Combine p-values using Fisher's method\n        _, combined_p = combine_pvalues(p_values_filtered)\n        return combined_p\n\n    # Combine z-scores and p-values for each interaction\n    df['combined_z'] = df.apply(combine_z_scores, axis=1)\n    df['combined_p'] = df.apply(\n        lambda row: combine_p_values(row, p_value_columns), axis=1\n    )\n\n    # Create a consolidated DataFrame with the relevant columns\n    df = df[['phenotype', 'neighbour_phenotype', 'combined_z', 'combined_p']]\n    df.columns = ['phenotype', 'neighbour_phenotype', 'z score', 'p-value']\n\n    # Filter out edges with p-value &gt;= 0.05\n    df_filtered = df[df['p-value'] &lt; p_val]\n\n    # Create a directed graph from the filtered DataFrame\n    G = nx.from_pandas_edgelist(\n        df_filtered,\n        'phenotype',\n        'neighbour_phenotype',\n        ['z score', 'p-value'],\n        create_using=nx.DiGraph(),\n    )\n\n    # Normalize z-scores for edge color\n    z_scores = nx.get_edge_attributes(G, 'z score')\n    min_z = min(z_scores.values())\n    max_z = max(z_scores.values())\n    # Apply normalization for coloring\n    colors = [\n        plt.cm.coolwarm((z_scores[edge] - min_z) / (max_z - min_z))\n        for edge in G.edges()\n    ]\n\n    # Normalize p-values for edge thickness\n    p_values = nx.get_edge_attributes(G, 'p-value')\n    # Invert and normalize p-values to range for thickness: Higher values for lower p-values\n    min_p = min(p_values.values())\n    max_p = max(p_values.values())\n    thicknesses = [\n        10 * (1 - (p_values[edge] - min_p) / (max_p - min_p)) + 1 for edge in G.edges()\n    ]\n\n    # Use spring_layout considering the 'weight' for layout\n    pos = nx.spring_layout(G, weight='weight')\n\n    if figsize is None:\n        # Adjust these scaling factors to suit your specific needs\n        figsize_width_scale = 0.5\n        figsize_height_scale = 0.5\n        # Calculate width and height based on the DataFrame dimensions\n        figsize_width = max(10, len(df.columns) * figsize_width_scale)\n        figsize_height = max(8, len(df) * figsize_height_scale)\n        figsize = (figsize_width, figsize_height)\n\n    # Base node size that works well for a small number of nodes\n    if nodeSize is None:\n        node_count = G.number_of_nodes()\n        nodeSize = 2000 / (\n            node_count / 10\n        )  # Example scaling, adjust the divisor as needed\n\n    # Drawing the network graph\n    fig, ax = plt.subplots(figsize=figsize, constrained_layout=True)\n\n    # Draw the network components\n    nx.draw_networkx_nodes(\n        G, pos, ax=ax, node_size=nodeSize, node_color=nodeColor, alpha=alpha\n    )\n    nx.draw_networkx_edges(\n        G, pos, ax=ax, width=thicknesses, edge_color=colors, arrowstyle='-&gt;'\n    )\n    nx.draw_networkx_labels(\n        G,\n        pos,\n        ax=ax,\n        font_size=fontSize,\n        font_family=\"sans-serif\",\n        font_color=fontColor,\n    )\n\n    # Setup the ScalarMappable for the colorbar reflecting z-scores\n    sm = plt.cm.ScalarMappable(\n        cmap=plt.get_cmap(cmap), norm=plt.Normalize(vmin=min_z, vmax=max_z)\n    )\n    # sm = plt.cm.ScalarMappable(cmap=plt.cm.coolwarm, norm=plt.Normalize(vmin=min_z, vmax=max_z))\n    sm.set_array([])\n    cbar = fig.colorbar(\n        sm, ax=ax, orientation='vertical', fraction=0.046, pad=0.04, aspect=10\n    )\n    cbar.set_label('Z-score')\n\n    # Since matplotlib's colorbar does not directly support displaying edge thickness, you might add a text or legend\n    # describing the mapping of p-values to thickness if necessary.\n    ax.axis('off')\n\n    # Save or show the figure\n    if saveDir and fileName:\n        if not os.path.exists(saveDir):\n            os.makedirs(saveDir)\n        full_path = os.path.join(saveDir, fileName)\n        plt.savefig(full_path, dpi=300)\n        if not os.path.exists(saveDir):\n            os.makedirs(saveDir)\n        print(f\"Saved network plot to {full_path}\")\n    else:\n        plt.show()\n</code></pre>"},{"location":"Functions/pl/spatial_distance/","title":"spatial_distance","text":"<p>Short Description</p> <p><code>sm.pl.spatial_distance</code>: This function enables the visualization of the average  shortest distances between selected phenotypes or cell types, offering insights  into spatial relationships within biological samples. To accurately generate  these visual representations, it's essential to first compute spatial distances  using <code>sm.tl.spatial_distance</code>. This preparatory step ensures the data necessary  for creating comprehensive heatmaps, numeric comparisons, and distribution plots is  available, facilitating a deeper understanding of spatial patterning and interactions  among cell populations.</p>"},{"location":"Functions/pl/spatial_distance/#scimap.plotting.spatial_distance--function","title":"Function","text":""},{"location":"Functions/pl/spatial_distance/#scimap.plotting.spatial_distance.spatial_distance","title":"<code>spatial_distance(adata, spatial_distance='spatial_distance', phenotype='phenotype', imageid='imageid', log=False, method='heatmap', heatmap_summarize=True, heatmap_na_color='grey', heatmap_cmap='vlag_r', heatmap_row_cluster=False, heatmap_col_cluster=False, heatmap_standard_scale=0, distance_from=None, distance_to=None, x_axis=None, y_axis=None, facet_by=None, plot_type=None, return_data=False, subset_col=None, subset_value=None, fileName='spatial_distance.pdf', saveDir=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The annotated data matrix with spatial distance calculations.</p> required <code>spatial_distance</code> <code>str</code> <p>Key in <code>adata.uns</code> where spatial distance data is stored, typically the output of <code>sm.tl.spatial_distance</code>.</p> <code>'spatial_distance'</code> <code>phenotype</code> <code>str</code> <p>Column in <code>adata.obs</code> containing phenotype or cell type annotations.</p> <code>'phenotype'</code> <code>imageid</code> <code>str</code> <p>Column in <code>adata.obs</code> identifying different images or samples.</p> <code>'imageid'</code> <code>log</code> <code>bool</code> <p>If True, applies log transformation to the distance data.</p> <code>False</code> <code>method</code> <code>str</code> <p>Visualization method: 'heatmap', 'numeric', or 'distribution'.</p> <code>'heatmap'</code> <code>heatmap_summarize</code> <code>bool</code> <p>If True, summarizes distances across all images or samples for the heatmap.</p> <code>True</code> <code>heatmap_na_color</code> <code>str</code> <p>Color for NA values in the heatmap.</p> <code>'grey'</code> <code>heatmap_cmap</code> <code>str</code> <p>Colormap for the heatmap.</p> <code>'vlag_r'</code> <code>heatmap_row_cluster,</code> <code>heatmap_col_cluster (bool</code> <p>If True, clusters rows or columns in the heatmap.</p> required <code>heatmap_standard_scale</code> <code>int</code> <p>Standardizes rows (0) or columns (1) in the heatmap.</p> <code>0</code> <code>distance_from,</code> <code>distance_to (str</code> <p>Phenotypes of interest for distance calculation in 'numeric' or 'distribution' plots.</p> required <code>x_axis,</code> <code>y_axis (str</code> <p>Axes labels for 'numeric' or 'distribution' plots.</p> required <code>facet_by</code> <code>str</code> <p>Categorizes plots into subplots based on this column.</p> <code>None</code> <code>plot_type</code> <code>str</code> <p>For 'numeric' plots: options include 'box', 'violin', etc. For 'distribution' plots: 'hist', 'kde', etc.</p> <code>None</code> <code>subset_col</code> <code>str</code> <p>Column name for subsetting data before plotting.</p> <code>None</code> <code>subset_value</code> <code>list</code> <p>Values in <code>subset_col</code> to include in the plot.</p> <code>None</code> <code>fileName</code> <code>str</code> <p>Name of the file to save the plot. Relevant only if <code>saveDir</code> is not None.</p> <code>'spatial_distance.pdf'</code> <code>saveDir</code> <code>str</code> <p>Directory to save the generated plot. If None, the plot is not saved.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments for plotting functions.</p> <code>{}</code> <p>Returns:</p> Type Description <p>Plot and dataFrame (matplotlib, pandasDF): If <code>return_data</code> is True, returns the data frame used for plotting; otherwise, displays the plot.</p> Example <pre><code># Generate a heatmap of spatial distances\nsm.pl.spatial_distance(adata, method='heatmap', phenotype='cell_type', imageid='sample_id')\n\n# Numeric plot showing distance from one phenotype to all others\nsm.pl.spatial_distance(adata, method='numeric', distance_from='Tumor', phenotype='cell_type', plot_type='boxen')\n\n# Distribution plot comparing distances between two specific phenotypes\nsm.pl.spatial_distance(adata, method='distribution', distance_from='Tumor', distance_to='Stroma',\n                 plot_type='kde', x_axis='distance', y_axis='group')\n</code></pre> Source code in <code>scimap/plotting/spatial_distance.py</code> <pre><code>def spatial_distance(\n    adata,\n    spatial_distance='spatial_distance',\n    phenotype='phenotype',\n    imageid='imageid',\n    log=False,\n    method='heatmap',\n    heatmap_summarize=True,\n    heatmap_na_color='grey',\n    heatmap_cmap='vlag_r',\n    heatmap_row_cluster=False,\n    heatmap_col_cluster=False,\n    heatmap_standard_scale=0,\n    distance_from=None,\n    distance_to=None,\n    x_axis=None,\n    y_axis=None,\n    facet_by=None,\n    plot_type=None,\n    return_data=False,\n    subset_col=None,\n    subset_value=None,\n    fileName='spatial_distance.pdf',\n    saveDir=None,\n    **kwargs,\n):\n    \"\"\"\n    Parameters:\n            adata (anndata.AnnData):\n                The annotated data matrix with spatial distance calculations.\n\n            spatial_distance (str, optional):\n                Key in `adata.uns` where spatial distance data is stored, typically the output of `sm.tl.spatial_distance`.\n\n            phenotype (str):\n                Column in `adata.obs` containing phenotype or cell type annotations.\n\n            imageid (str, optional):\n                Column in `adata.obs` identifying different images or samples.\n\n            log (bool, optional):\n                If True, applies log transformation to the distance data.\n\n            method (str, optional):\n                Visualization method: 'heatmap', 'numeric', or 'distribution'.\n\n            heatmap_summarize (bool, optional):\n                If True, summarizes distances across all images or samples for the heatmap.\n\n            heatmap_na_color (str, optional):\n                Color for NA values in the heatmap.\n\n            heatmap_cmap (str, optional):\n                Colormap for the heatmap.\n\n            heatmap_row_cluster, heatmap_col_cluster (bool, optional):\n                If True, clusters rows or columns in the heatmap.\n\n            heatmap_standard_scale (int, optional):\n                Standardizes rows (0) or columns (1) in the heatmap.\n\n            distance_from, distance_to (str, optional):\n                Phenotypes of interest for distance calculation in 'numeric' or 'distribution' plots.\n\n            x_axis, y_axis (str, optional):\n                Axes labels for 'numeric' or 'distribution' plots.\n\n            facet_by (str, optional):\n                Categorizes plots into subplots based on this column.\n\n            plot_type (str, optional):\n                For 'numeric' plots: options include 'box', 'violin', etc. For 'distribution' plots: 'hist', 'kde', etc.\n\n            subset_col (str, optional):\n                Column name for subsetting data before plotting.\n\n            subset_value (list, optional):\n                Values in `subset_col` to include in the plot.\n\n            fileName (str, optional):\n                Name of the file to save the plot. Relevant only if `saveDir` is not None.\n\n            saveDir (str, optional):\n                Directory to save the generated plot. If None, the plot is not saved.\n\n            **kwargs:\n                Additional keyword arguments for plotting functions.\n\n    Returns:\n        Plot and dataFrame (matplotlib, pandasDF):\n            If `return_data` is True, returns the data frame used for plotting; otherwise, displays the plot.\n\n    Example:\n        ```python\n\n        # Generate a heatmap of spatial distances\n        sm.pl.spatial_distance(adata, method='heatmap', phenotype='cell_type', imageid='sample_id')\n\n        # Numeric plot showing distance from one phenotype to all others\n        sm.pl.spatial_distance(adata, method='numeric', distance_from='Tumor', phenotype='cell_type', plot_type='boxen')\n\n        # Distribution plot comparing distances between two specific phenotypes\n        sm.pl.spatial_distance(adata, method='distribution', distance_from='Tumor', distance_to='Stroma',\n                         plot_type='kde', x_axis='distance', y_axis='group')\n\n        ```\n    \"\"\"\n\n    # set color for heatmap\n    # cmap_updated = matplotlib.cm.get_cmap(heatmap_cmap)\n    cmap_updated = matplotlib.colormaps[heatmap_cmap]\n    cmap_updated.set_bad(color=heatmap_na_color)\n\n    # Copy the spatial_distance results from anndata object\n    try:\n        diatance_map = adata.uns[spatial_distance].copy()\n    except KeyError:\n        raise ValueError(\n            'spatial_distance not found- Please run sm.tl.spatial_distance first'\n        )\n\n    # subset the data if user requests\n    if subset_col is not None:\n        if isinstance(subset_value, str):\n            subset_value = [subset_value]\n        # find the cell names to be subsetted out\n        obs = adata.obs[[subset_col]]\n        cells_to_subset = obs[obs[subset_col].isin(subset_value)].index\n\n        # subset the diatance_map\n        diatance_map = diatance_map.loc[\n            diatance_map.index.intersection(cells_to_subset)\n        ]\n        # diatance_map = diatance_map.loc[cells_to_subset]\n\n    # Convert distance to log scale if user requests\n    if log is True:\n        diatance_map = np.log1p(diatance_map)\n\n    # Method\n    if method == 'heatmap':\n        if heatmap_summarize is True:\n            # create the necessary data\n            data = pd.DataFrame({'phenotype': adata.obs[phenotype]})\n            data = pd.merge(\n                data, diatance_map, how='outer', left_index=True, right_index=True\n            )  # merge with the distance map\n            k = data.groupby(\n                ['phenotype'], observed=False\n            ).mean()  # collapse the whole dataset into mean expression\n            d = k[k.index]\n        else:\n            # create new naming scheme for the phenotypes\n            non_summary = pd.DataFrame(\n                {'imageid': adata.obs[imageid], 'phenotype': adata.obs[phenotype]}\n            )\n            non_summary['imageid'] = non_summary['imageid'].astype(\n                str\n            )  # convert the column to string\n            non_summary['phenotype'] = non_summary['phenotype'].astype(\n                str\n            )  # convert the column to string\n            non_summary['image_phenotype'] = non_summary['imageid'].str.cat(\n                non_summary['phenotype'], sep=\"_\"\n            )\n            # Merge distance map with phenotype\n            data = pd.DataFrame(non_summary[['image_phenotype']])\n            data = pd.merge(\n                data, diatance_map, how='outer', left_index=True, right_index=True\n            )\n            k = data.groupby(['image_phenotype'], observed=False).mean()\n            d = k.sort_index(axis=1)\n        # Generate the heatmap\n        mask = d.isnull()  # identify the NAN's for masking\n        d = d.fillna(0)  # replace nan's with 0 so that clustering will work\n        # Heatmap\n        plot = sns.clustermap(\n            d,\n            cmap=heatmap_cmap,\n            row_cluster=heatmap_row_cluster,\n            col_cluster=heatmap_col_cluster,\n            mask=mask,\n            standard_scale=heatmap_standard_scale,\n            **kwargs,\n        )\n    else:\n\n        # condition-1\n        if distance_from is None and distance_to is None:\n            raise ValueError(\n                'Please include distance_from and/or distance_to parameters to use this method'\n            )\n\n        # condition-2\n        if distance_from is None and distance_to is not None:\n            raise ValueError('Please `distance_from` parameters to use this method')\n\n        # condition-3\n        if distance_to is not None:\n            # convert input to list if needed\n            if isinstance(distance_to, str):\n                distance_to = [distance_to]\n\n        # Start\n        pheno_df = pd.DataFrame(\n            {'imageid': adata.obs[imageid], 'phenotype': adata.obs[phenotype]}\n        )  # image id and phenotype\n        data = pd.merge(\n            pheno_df, diatance_map, how='outer', left_index=True, right_index=True\n        )  # merge with the distance map\n        data = data[data['phenotype'] == distance_from]  # subset the pheno of interest\n\n        if distance_to is not None:\n            data = data[\n                distance_to\n            ]  # drop columns that are not requested in distance_to\n        else:\n            data = data.drop(\n                ['phenotype', 'imageid'], axis=1\n            )  # drop the phenotype column before stacking\n\n        d = data.stack().reset_index()  # collapse everything to one column\n        d.columns = ['cellid', 'group', 'distance']\n        d = pd.merge(\n            d, pheno_df, left_on='cellid', right_index=True\n        )  # bring back the imageid and phenotype\n\n        # Convert columns to str\n        for col in ['imageid', 'group', 'phenotype']:\n            d[col] = d[col].astype(str)\n\n        # Convert columns to categorical so that it drops unused categories\n        for col in ['imageid', 'group', 'phenotype']:\n            d[col] = d[col].astype('category')\n\n        # re arrange the order based on from and to list provided\n        if distance_to is not None:\n            d['group'] = d['group'].cat.reorder_categories(distance_to)\n            d = d.sort_values('group')\n\n        # Plotting\n        if method == 'numeric':\n            if (\n                x_axis is None\n                and y_axis is None\n                and facet_by is None\n                and plot_type is None\n            ):\n                plot = sns.catplot(\n                    data=d,\n                    x=\"distance\",\n                    y=\"group\",\n                    col=\"imageid\",\n                    kind=\"boxen\",\n                    **kwargs,\n                )\n            else:\n                plot = sns.catplot(\n                    data=d, x=x_axis, y=y_axis, col=facet_by, kind=plot_type, **kwargs\n                )\n\n        if method == 'distribution':\n            if (\n                x_axis is None\n                and y_axis is None\n                and facet_by is None\n                and plot_type is None\n            ):\n                plot = sns.displot(\n                    data=d,\n                    x=\"distance\",\n                    hue=\"imageid\",\n                    col=\"group\",\n                    kind=\"kde\",\n                    **kwargs,\n                )\n            else:\n                plot = sns.displot(\n                    data=d, x=x_axis, hue=y_axis, col=facet_by, kind=plot_type, **kwargs\n                )\n\n    # Saving the figure if saveDir and fileName are provided\n    if saveDir:\n        if not os.path.exists(saveDir):\n            os.makedirs(saveDir)\n        full_path = os.path.join(saveDir, fileName)\n        plot.savefig(full_path, dpi=300)\n        plt.close()\n        print(f\"Saved plot to {full_path}\")\n    else:\n        plt.show()\n\n    # return\n    if return_data is True:\n        return d\n</code></pre>"},{"location":"Functions/pl/spatial_interaction/","title":"spatial_interaction","text":"<p>Short Description</p> <p><code>sm.pl.spatial_interaction</code>: This function provides a sophisticated approach to  visualizing spatial interactions between cell types or phenotypes through heatmaps.  It adeptly highlights the frequency and significance of co-occurrence patterns,  where the intensity of colors reflects the scaled abundance of interactions.  Non-significant results are clearly marked with blank regions, offering a clear  demarcation of areas where interactions do not meet the specified threshold of significance.  This visualization tool is invaluable for uncovering intricate spatial relationships  and potential signaling networks within complex tissue environments.</p>"},{"location":"Functions/pl/spatial_interaction/#scimap.plotting.spatial_interaction--function","title":"Function","text":""},{"location":"Functions/pl/spatial_interaction/#scimap.plotting.spatial_interaction.spatial_interaction","title":"<code>spatial_interaction(adata, spatial_interaction='spatial_interaction', summarize_plot=True, p_val=0.05, row_cluster=False, col_cluster=False, cmap='vlag', nonsig_color='grey', subset_phenotype=None, subset_neighbour_phenotype=None, binary_view=False, return_data=False, fileName='spatial_interaction.pdf', saveDir=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The annotated data matrix with spatial interaction calculations.</p> required <code>spatial_interaction</code> <code>str</code> <p>Key in <code>adata.uns</code> where spatial interaction data is stored, typically the output of <code>sm.tl.spatial_interaction</code>.</p> <code>'spatial_interaction'</code> <code>summarize_plot</code> <code>bool</code> <p>If True, summarizes cell-cell interactions across all images or samples to provide an aggregated view.</p> <code>True</code> <code>p_val</code> <code>float</code> <p>Threshold for significance of interactions. Interactions with a P-value above this threshold are considered non-significant.</p> <code>0.05</code> <code>row_cluster,</code> <code>col_cluster (bool</code> <p>If True, performs hierarchical clustering on rows or columns in the heatmap to group similar patterns of interaction.</p> required <code>cmap</code> <code>str</code> <p>Colormap for the heatmap visualization. Default is 'vlag'.</p> <code>'vlag'</code> <code>nonsig_color</code> <code>str</code> <p>Color used to represent non-significant interactions in the heatmap.</p> <code>'grey'</code> <code>subset_phenotype,</code> <code>subset_neighbour_phenotype (list</code> <p>Subsets of phenotypes or neighboring phenotypes to include in the analysis and visualization.</p> required <code>binary_view</code> <code>bool</code> <p>If True, visualizes interactions in a binary manner, highlighting presence or absence of significant interactions without intensity gradation.</p> <code>False</code> <code>return_data</code> <code>bool</code> <p>If True, returns the DataFrame used for plotting instead of the plot itself.</p> <code>False</code> <code>fileName</code> <code>str</code> <p>Name of the file to save the plot. Relevant only if <code>saveDir</code> is not None.</p> <code>'spatial_interaction.pdf'</code> <code>saveDir</code> <code>str</code> <p>Directory to save the generated plot. If None, the plot is not saved.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments for seaborn's clustermap function, such as <code>linecolor</code> and <code>linewidths</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <p>pandas.DataFrame (dataframe): Only if <code>return_data</code> is True. The DataFrame containing the data used for plotting.</p> Example <pre><code># Basic visualization of spatial interactions with default settings\nsm.pl.spatial_interaction(adata)\n\n# Detailed heatmap of spatial interactions, excluding non-significant interactions\nsm.pl.spatial_interaction(adata, summarize_plot=False, p_val=0.01, cmap='coolwarm', nonsig_color='lightgrey',\n                    binary_view=True, row_cluster=True, col_cluster=True)\n\n# Visualizing specific phenotypes interactions, with custom colormap and binary view\nsm.pl.spatial_interaction(adata, subset_phenotype=['T cells', 'B cells'], subset_neighbour_phenotype=['Macrophages'],\n                    cmap='seismic', binary_view=True, row_cluster=True, col_cluster=False,\n                    figsize=(10, 8), dendrogram_ratio=(.1, .2), cbar_pos=(0, .2, .03, .4))\n</code></pre> Source code in <code>scimap/plotting/spatial_interaction.py</code> <pre><code>def spatial_interaction(\n    adata,\n    spatial_interaction='spatial_interaction',\n    summarize_plot=True,\n    p_val=0.05,\n    row_cluster=False,\n    col_cluster=False,\n    cmap='vlag',\n    nonsig_color='grey',\n    subset_phenotype=None,\n    subset_neighbour_phenotype=None,\n    binary_view=False,\n    return_data=False,\n    fileName='spatial_interaction.pdf',\n    saveDir=None,\n    **kwargs,\n):\n    \"\"\"\n    Parameters:\n            adata (anndata.AnnData):\n                The annotated data matrix with spatial interaction calculations.\n\n            spatial_interaction (str, optional):\n                Key in `adata.uns` where spatial interaction data is stored, typically the output of `sm.tl.spatial_interaction`.\n\n            summarize_plot (bool, optional):\n                If True, summarizes cell-cell interactions across all images or samples to provide an aggregated view.\n\n            p_val (float, optional):\n                Threshold for significance of interactions. Interactions with a P-value above this threshold are considered non-significant.\n\n            row_cluster, col_cluster (bool, optional):\n                If True, performs hierarchical clustering on rows or columns in the heatmap to group similar patterns of interaction.\n\n            cmap (str, optional):\n                Colormap for the heatmap visualization. Default is 'vlag'.\n\n            nonsig_color (str, optional):\n                Color used to represent non-significant interactions in the heatmap.\n\n            subset_phenotype, subset_neighbour_phenotype (list, optional):\n                Subsets of phenotypes or neighboring phenotypes to include in the analysis and visualization.\n\n            binary_view (bool, optional):\n                If True, visualizes interactions in a binary manner, highlighting presence or absence of significant interactions without intensity gradation.\n\n            return_data (bool, optional):\n                If True, returns the DataFrame used for plotting instead of the plot itself.\n\n            fileName (str, optional):\n                Name of the file to save the plot. Relevant only if `saveDir` is not None.\n\n            saveDir (str, optional):\n                Directory to save the generated plot. If None, the plot is not saved.\n\n            **kwargs:\n                Additional keyword arguments for seaborn's clustermap function, such as `linecolor` and `linewidths`.\n\n    Returns:\n            pandas.DataFrame (dataframe):\n                Only if `return_data` is True. The DataFrame containing the data used for plotting.\n\n    Example:\n        ```python\n\n        # Basic visualization of spatial interactions with default settings\n        sm.pl.spatial_interaction(adata)\n\n        # Detailed heatmap of spatial interactions, excluding non-significant interactions\n        sm.pl.spatial_interaction(adata, summarize_plot=False, p_val=0.01, cmap='coolwarm', nonsig_color='lightgrey',\n                            binary_view=True, row_cluster=True, col_cluster=True)\n\n        # Visualizing specific phenotypes interactions, with custom colormap and binary view\n        sm.pl.spatial_interaction(adata, subset_phenotype=['T cells', 'B cells'], subset_neighbour_phenotype=['Macrophages'],\n                            cmap='seismic', binary_view=True, row_cluster=True, col_cluster=False,\n                            figsize=(10, 8), dendrogram_ratio=(.1, .2), cbar_pos=(0, .2, .03, .4))\n        ```\n    \"\"\"\n\n    # set color for heatmap\n    # cmap_updated = copy.copy(matplotlib.cm.get_cmap(cmap))\n    # cmap_updated = matplotlib.cm.get_cmap(cmap)\n    cmap_updated = matplotlib.colormaps[cmap]\n    cmap_updated.set_bad(color=nonsig_color)\n\n    # Copy the interaction results from anndata object\n    try:\n        interaction_map = adata.uns[spatial_interaction].copy()\n    except KeyError:\n        raise ValueError(\n            'spatial_interaction not found- Please run sm.tl.spatial_interaction first'\n        )\n\n    # subset the data if user requests\n    if subset_phenotype is not None:\n        if isinstance(subset_phenotype, str):\n            subset_phenotype = [subset_phenotype]\n        # subset the phenotype\n        interaction_map = interaction_map[\n            interaction_map['phenotype'].isin(subset_phenotype)\n        ]\n\n    if subset_neighbour_phenotype is not None:\n        if isinstance(subset_neighbour_phenotype, str):\n            subset_neighbour_phenotype = [subset_neighbour_phenotype]\n        # subset the phenotype\n        interaction_map = interaction_map[\n            interaction_map['neighbour_phenotype'].isin(subset_neighbour_phenotype)\n        ]\n\n    # Seperate Interaction intensity from P-value\n    p_value = interaction_map.filter(regex='pvalue_')\n    p_val_df = pd.concat(\n        [interaction_map[['phenotype', 'neighbour_phenotype']], p_value],\n        axis=1,\n        join='outer',\n    )\n    p_val_df = p_val_df.set_index(['phenotype', 'neighbour_phenotype'])\n    interaction_map = interaction_map[\n        interaction_map.columns.difference(p_value.columns)\n    ]\n    interaction_map = interaction_map.set_index(['phenotype', 'neighbour_phenotype'])\n\n    # Binarize the values if user requests\n    if binary_view == True:\n        interaction_map[interaction_map &gt; 0] = 1\n        interaction_map[interaction_map &lt;= 0] = -1\n\n    if summarize_plot == True:\n        # convert first two columns to multi-index column\n        # interaction_map = interaction_map.set_index(['phenotype','neighbour_phenotype'])\n        # p_val_df = p_val_df.set_index(['phenotype','neighbour_phenotype'])\n\n        # If multiple images are present, take the average of interactions\n        interaction_map['mean'] = interaction_map.mean(axis=1).values\n        interaction_map = interaction_map[['mean']]  # keep only the mean column\n        interaction_map = interaction_map['mean'].unstack()\n        # Do the same for P-values\n        p_val_df['mean'] = p_val_df.mean(axis=1).values\n        p_val_df = p_val_df[['mean']]  # keep only the mean column\n        # set the P-value threshold\n        p_val_df.loc[p_val_df[p_val_df['mean'] &gt; p_val].index, 'mean'] = np.NaN\n        p_val_df = p_val_df['mean'].unstack()\n\n        # change to the order passed in subset\n        if subset_phenotype is not None:\n            interaction_map = interaction_map.reindex(subset_phenotype)\n            p_val_df = p_val_df.reindex(subset_phenotype)\n        if subset_neighbour_phenotype is not None:\n            interaction_map = interaction_map.reindex(\n                columns=subset_neighbour_phenotype\n            )\n            p_val_df = p_val_df.reindex(columns=subset_neighbour_phenotype)\n\n        # Plotting heatmap\n        mask = p_val_df.isnull()  # identify the NAN's for masking\n        im = interaction_map.fillna(\n            0\n        )  # replace nan's with 0 so that clustering will work\n        # heatmap\n        plot = sns.clustermap(\n            im,\n            cmap=cmap_updated,\n            row_cluster=row_cluster,\n            col_cluster=col_cluster,\n            mask=mask,\n            **kwargs,\n        )\n\n    else:\n        if len(interaction_map.columns) &lt; 2:\n            raise ValueError(\n                'Data for only a single image is available please set summarize_plot=True and try again'\n            )\n        # convert first two columns to multi-index column\n        # interaction_map = interaction_map.set_index(['phenotype','neighbour_phenotype'])\n        # p_val_df = p_val_df.set_index(['phenotype','neighbour_phenotype'])\n\n        # P value threshold\n        p_val_df = p_val_df.apply(lambda x: np.where(x &gt; p_val, np.nan, x))\n\n        # Remove rows that are all nan\n        idx = p_val_df.index[p_val_df.isnull().all(1)]  # Find all nan rows\n        interaction_map = interaction_map.loc[\n            interaction_map.index.difference(idx)\n        ]  # clean intensity data\n        p_val_df = p_val_df.loc[p_val_df.index.difference(idx)]  # clean p-value data\n\n        # order the plot as needed\n        if subset_phenotype or subset_neighbour_phenotype is not None:\n            interaction_map.reset_index(inplace=True)\n            p_val_df.reset_index(inplace=True)\n            if subset_phenotype is not None:\n                interaction_map['phenotype'] = (\n                    interaction_map['phenotype'].astype('str').astype('category')\n                )\n                interaction_map['phenotype'] = interaction_map[\n                    'phenotype'\n                ].cat.reorder_categories(subset_phenotype)\n                interaction_map = interaction_map.sort_values('phenotype')\n                # Do same for Pval\n                p_val_df['phenotype'] = (\n                    p_val_df['phenotype'].astype('str').astype('category')\n                )\n                p_val_df['phenotype'] = p_val_df['phenotype'].cat.reorder_categories(\n                    subset_phenotype\n                )\n                p_val_df = p_val_df.sort_values('phenotype')\n            if subset_neighbour_phenotype is not None:\n                interaction_map['neighbour_phenotype'] = (\n                    interaction_map['neighbour_phenotype']\n                    .astype('str')\n                    .astype('category')\n                )\n                interaction_map['neighbour_phenotype'] = interaction_map[\n                    'neighbour_phenotype'\n                ].cat.reorder_categories(subset_neighbour_phenotype)\n                interaction_map = interaction_map.sort_values('neighbour_phenotype')\n                # Do same for Pval\n                p_val_df['neighbour_phenotype'] = (\n                    p_val_df['neighbour_phenotype'].astype('str').astype('category')\n                )\n                p_val_df['neighbour_phenotype'] = p_val_df[\n                    'neighbour_phenotype'\n                ].cat.reorder_categories(subset_neighbour_phenotype)\n                p_val_df = p_val_df.sort_values('neighbour_phenotype')\n            if subset_phenotype and subset_neighbour_phenotype is not None:\n                interaction_map = interaction_map.sort_values(\n                    ['phenotype', 'neighbour_phenotype']\n                )\n                p_val_df = p_val_df.sort_values(['phenotype', 'neighbour_phenotype'])\n\n            # convert the data back into multi-index\n            interaction_map = interaction_map.set_index(\n                ['phenotype', 'neighbour_phenotype']\n            )\n            p_val_df = p_val_df.set_index(['phenotype', 'neighbour_phenotype'])\n\n        # Plotting heatmap\n        mask = p_val_df.isnull()  # identify the NAN's for masking\n        im = interaction_map.fillna(\n            0\n        )  # replace nan's with 0 so that clustering will work\n        mask.columns = im.columns\n\n        # covert the first two columns into index\n        # Plot\n        plot = sns.clustermap(\n            im,\n            cmap=cmap_updated,\n            row_cluster=row_cluster,\n            col_cluster=col_cluster,\n            mask=mask,\n            **kwargs,\n        )\n\n    # Saving the figure if saveDir and fileName are provided\n    if saveDir:\n        if not os.path.exists(saveDir):\n            os.makedirs(saveDir)\n        full_path = os.path.join(saveDir, fileName)\n        plot.savefig(full_path, dpi=300)\n        plt.close()\n        print(f\"Saved plot to {full_path}\")\n    else:\n        plt.show()\n\n    if return_data is True:\n        # perpare data for export\n        map_data = interaction_map.copy()\n        p_val_data = mask.copy()\n        map_data.reset_index(inplace=True)\n        p_val_data.reset_index(inplace=True)\n        # remove the first two colums\n        map_data = map_data.drop(['phenotype', 'neighbour_phenotype'], axis=1)\n        p_val_data = p_val_data.drop(['phenotype', 'neighbour_phenotype'], axis=1)\n        p_val_data.columns = map_data.columns\n        # remove the mased values\n        final_Data = map_data.where(~p_val_data, other=np.nan)\n        final_Data.index = interaction_map.index\n        return final_Data\n</code></pre>"},{"location":"Functions/pl/spatial_pscore/","title":"spatial_pscore","text":"<p>Short Description</p> <p><code>sm.pl.spatial_pscore</code>: This function offers a visual representation of  proximity volume and density scores, essential for understanding the spatial  relationships and interactions among cell types or phenotypes within tissue samples.  To ensure accurate and meaningful visualizations, it is crucial to compute  these scores beforehand using <code>sm.tl.spatial_pscore</code>. Through customizable bar  plots, users can delve into the intricacies of spatial co-occurrence patterns,  facilitating deeper insights into the cellular microenvironment.</p>"},{"location":"Functions/pl/spatial_pscore/#scimap.plotting.spatial_pscore--function","title":"Function","text":""},{"location":"Functions/pl/spatial_pscore/#scimap.plotting.spatial_pscore.spatial_pscore","title":"<code>spatial_pscore(adata, label='spatial_pscore', plot_score='both', order_xaxis=None, color='grey', figsize=None, fileName='spatial_pscore.pdf', saveDir=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The annotated data matrix with spatial proximity scores.</p> required <code>label</code> <code>str</code> <p>The label/key used to access the spatial proximity scores stored in <code>adata.uns</code>. This should match the label used during the <code>sm.tl.spatial_pscore</code> computation. Default is 'spatial_pscore'.</p> <code>'spatial_pscore'</code> <code>plot_score</code> <code>str</code> <p>Determines which score(s) to plot. Options are: - 'Proximity Density' for plotting only the Proximity Density scores, - 'Proximity Volume' for plotting only the Proximity Volume scores, - 'both' for plotting both scores side by side. Default is 'both'.</p> <code>'both'</code> <code>order_xaxis</code> <code>list</code> <p>Custom order for the x-axis categories. Pass a list of category names in the desired order. This can be useful for comparing specific regions or samples in a specific sequence.</p> <code>None</code> <code>color</code> <code>str</code> <p>Color to use for the bar plots. This can enhance plot readability or align with publication themes.</p> <code>'grey'</code> <code>fileName</code> <code>str</code> <p>Name of the file to save the plot. Relevant only if <code>saveDir</code> is not None.</p> <code>'spatial_pscore.pdf'</code> <code>saveDir</code> <code>str</code> <p>Directory to save the generated plot. If None, the plot is not saved.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed directly to seaborn's barplot function, allowing for further customization of the plots.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Plot</code> <code>matplotlib</code> <p>Displays the generated bar plots.</p> Example <pre><code># Basic visualization of both Proximity Density and Proximity Volume\nsm.pl.spatial_pscore(adata, label='spatial_pscore', plot_score='both', color='skyblue')\n\n# Customized plot for Proximity Density with ordered x-axis and specific color\nsm.pl.spatial_pscore(adata, plot_score='Proximity Density', order_xaxis=['Sample1', 'Sample2', 'Sample3'], color='salmon', edgecolor: 'black'})\n\n# Focused plot on Proximity Volume with seaborn customization through kwargs\nsm.pl.spatial_pscore(adata, plot_score='Proximity Volume', color='lightgreen', saturation: 0.8, alpha: 0.7})\n</code></pre> Source code in <code>scimap/plotting/spatial_pscore.py</code> <pre><code>def spatial_pscore(\n    adata,\n    label='spatial_pscore',\n    plot_score='both',\n    order_xaxis=None,\n    color='grey',\n    figsize=None,\n    fileName='spatial_pscore.pdf',\n    saveDir=None,\n    **kwargs,\n):\n    \"\"\"\n    Parameters:\n            adata (anndata.AnnData):\n                The annotated data matrix with spatial proximity scores.\n\n            label (str, optional):\n                The label/key used to access the spatial proximity scores stored in `adata.uns`.\n                This should match the label used during the `sm.tl.spatial_pscore` computation. Default is 'spatial_pscore'.\n\n            plot_score (str, optional):\n                Determines which score(s) to plot. Options are:\n                - 'Proximity Density' for plotting only the Proximity Density scores,\n                - 'Proximity Volume' for plotting only the Proximity Volume scores,\n                - 'both' for plotting both scores side by side. Default is 'both'.\n\n            order_xaxis (list, optional):\n                Custom order for the x-axis categories. Pass a list of category names in the desired order.\n                This can be useful for comparing specific regions or samples in a specific sequence.\n\n            color (str, optional):\n                Color to use for the bar plots. This can enhance plot readability or align with publication themes.\n\n            fileName (str, optional):\n                Name of the file to save the plot. Relevant only if `saveDir` is not None.\n\n            saveDir (str, optional):\n                Directory to save the generated plot. If None, the plot is not saved.\n\n            **kwargs:\n                Additional keyword arguments passed directly to seaborn's barplot function, allowing for further customization of the plots.\n\n    Returns:\n            Plot (matplotlib):\n                Displays the generated bar plots.\n\n    Example:\n        ```python\n\n        # Basic visualization of both Proximity Density and Proximity Volume\n        sm.pl.spatial_pscore(adata, label='spatial_pscore', plot_score='both', color='skyblue')\n\n        # Customized plot for Proximity Density with ordered x-axis and specific color\n        sm.pl.spatial_pscore(adata, plot_score='Proximity Density', order_xaxis=['Sample1', 'Sample2', 'Sample3'], color='salmon', edgecolor: 'black'})\n\n        # Focused plot on Proximity Volume with seaborn customization through kwargs\n        sm.pl.spatial_pscore(adata, plot_score='Proximity Volume', color='lightgreen', saturation: 0.8, alpha: 0.7})\n\n        ```\n    \"\"\"\n\n    # Isolate the data from anndata object\n    data = adata.uns[label]\n\n    # Order the x-axis if needed\n    if order_xaxis is not None:\n        data = data.reindex(order_xaxis)\n\n    # Generate the x and y axis\n    x = data.index\n    y_pd = data['Proximity Density'].values\n    y_pv = data['Proximity Volume'].values\n\n    if figsize is None:\n        # Dynamically calculate figsize based on the data size\n        figsize_width_scale = (\n            1.0  # Adjust based on your preference and the expected data length\n        )\n        figsize_height_scale = 0.5  # Adjust this to change how tall the plots are\n        # For 'both', we might want a wider figure\n        figsize_width = max(12, len(x) * figsize_width_scale)\n        figsize_height = max(8, len(x) * figsize_height_scale)\n        figsize = (figsize_width, figsize_height)\n\n    # Plot what user requests\n    if plot_score == 'Proximity Density':\n        fig, ax = plt.subplots(figsize=figsize)\n        sns.barplot(x=x, y=y_pd, color=color, **kwargs).set_title('Proximity Density')\n        plt.xticks(rotation=90)\n        plt.tight_layout()\n    elif plot_score == 'Proximity Volume':\n        fig, ax = plt.subplots(figsize=figsize)\n        sns.barplot(x=x, y=y_pv, color=color, **kwargs).set_title('Proximity Volume')\n        plt.xticks(rotation=90)\n        plt.tight_layout()\n    elif plot_score == 'both':\n        fig, axs = plt.subplots(1, 2, figsize=figsize)\n        sns.barplot(x=x, y=y_pd, color=color, ax=axs[0], **kwargs).set_title(\n            'Proximity Density'\n        )\n        axs[0].tick_params(axis='x', rotation=90)\n        sns.barplot(x=x, y=y_pv, color=color, ax=axs[1], **kwargs).set_title(\n            'Proximity Volume'\n        )\n        axs[1].tick_params(axis='x', rotation=90)\n        plt.tight_layout()\n\n    # Saving the figure if saveDir and fileName are provided\n    if saveDir:\n        if not os.path.exists(saveDir):\n            os.makedirs(saveDir)\n        full_path = os.path.join(saveDir, fileName)\n        fig.savefig(full_path, dpi=300)\n        plt.close(fig)\n        print(f\"Saved plot to {full_path}\")\n    else:\n        plt.show()\n</code></pre>"},{"location":"Functions/pl/spatial_scatterPlot/","title":"spatial_scatterPlot","text":"<p>Short Description</p> <p>The scatterPlot function offers a convenient way to generate scatter plots  for visualizing single-cell spatial data. By utilizing this function,  users can effectively visualize the spatial distribution of cells while  overlaying expression levels or categorical columns onto the plot.  This functionality allows for a comprehensive understanding of the  relationship between cell location and specific features of interest  within the dataset.</p>"},{"location":"Functions/pl/spatial_scatterPlot/#scimap.plotting.spatial_scatterPlot--function","title":"Function","text":""},{"location":"Functions/pl/spatial_scatterPlot/#scimap.plotting.spatial_scatterPlot.spatial_scatterPlot","title":"<code>spatial_scatterPlot(adata, colorBy, topLayer=None, x_coordinate='X_centroid', y_coordinate='Y_centroid', imageid='imageid', layer=None, subset=None, s=None, ncols=None, alpha=1, dpi=200, fontsize=None, plotLegend=True, cmap='RdBu_r', catCmap='tab20', vmin=None, vmax=None, customColors=None, figsize=(5, 5), invert_yaxis=True, saveDir=None, fileName='scimapScatterPlot.png', **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Pass the <code>adata</code> loaded into memory or a path to the <code>adata</code> file (.h5ad).</p> required <code>colorBy</code> <code>str</code> <pre><code>The column name that will be used for color-coding the points. This can be\neither markers (data stored in `adata.var`) or observations (data stored in `adata.obs`).\n</code></pre> required <code>topLayer</code> <code>list</code> <pre><code>A list of categories that should be plotted on the top layer. These categories\nmust be present in the `colorBy` data. Helps to highlight cell types or cluster that is of interest.\n</code></pre> <code>None</code> <code>x_coordinate</code> <code>str</code> <p>The column name in <code>spatial feature table</code> that records the X coordinates for each cell.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <code>str</code> <p>The column name in <code>single-cell spatial table</code> that records the Y coordinates for each cell.</p> <code>'Y_centroid'</code> <code>imageid</code> <code>str</code> <p>The column name in <code>spatial feature table</code> that contains the image ID for each cell.</p> <code>'imageid'</code> <code>layer</code> <code>str or None</code> <p>The layer in <code>adata.layers</code> that contains the expression data to use. If <code>None</code>, <code>adata.X</code> is used. use <code>raw</code> to use the data stored in <code>adata.raw.X</code>.</p> <code>None</code> <code>subset</code> <code>list or None</code> <p><code>imageid</code> of a single or multiple images to be subsetted for plotting purposes.</p> <code>None</code> <code>s</code> <code>float</code> <p>The size of the markers.</p> <code>None</code> <code>ncols</code> <code>int</code> <p>The number of columns in the final plot when multiple variables are plotted.</p> <code>None</code> <code>alpha</code> <code>float</code> <p>The alpha value of the points (controls opacity).</p> <code>1</code> <code>dpi</code> <code>int</code> <p>The DPI of the figure.</p> <code>200</code> <code>fontsize</code> <code>int</code> <p>The size of the fonts in plot.</p> <code>None</code> <code>plotLegend</code> <code>bool</code> <p>Whether to include a legend.</p> <code>True</code> <code>cmap</code> <code>str</code> <p>The colormap to use for continuous data.</p> <code>'RdBu_r'</code> <code>catCmap</code> <code>str</code> <p>The colormap to use for categorical data.</p> <code>'tab20'</code> <code>vmin</code> <code>float or None</code> <p>The minimum value of the color scale.</p> <code>None</code> <code>vmax</code> <code>float or None</code> <p>The maximum value of the color scale.</p> <code>None</code> <code>customColors</code> <code>dict or None</code> <p>A dictionary mapping color categories to colors.</p> <code>None</code> <code>figsize</code> <code>tuple</code> <p>The size of the figure. Default is (5, 5).</p> <code>(5, 5)</code> <code>invert_yaxis</code> <code>bool</code> <p>Invert the Y-axis of the plot.</p> <code>True</code> <code>saveDir</code> <code>str or None</code> <p>The directory to save the output plot. If None, the plot will not be saved.</p> <code>None</code> <code>fileName</code> <code>str</code> <p>The name of the output file. Use desired file format as suffix (e.g. <code>.png</code> or <code>.pdf</code>). Default is 'scimapScatterPlot.png'.</p> <code>'scimapScatterPlot.png'</code> <code>**kwargs</code> <p>Additional keyword arguments to be passed to the matplotlib scatter function.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Plot</code> <code>image</code> <p>If <code>saveDir</code> is provided the plot will saved within the provided saveDir.</p> Example <pre><code>customColors = { 'Unknown' : '#e5e5e5',\n                'CD8+ T' : '#ffd166',\n                'Non T CD4+ cells' : '#06d6a0',\n                'CD4+ T' : '#118ab2',\n                'ECAD+' : '#ef476f',\n                'Immune' : '#073b4c',\n                'KI67+ ECAD+' : '#000000'\n    }\n\nsm.pl.spatial_scatterPlot (adata=core6,\n                 colorBy = ['ECAD', 'phenotype_gator'],\n                 subset = 'unmicst-6_cellMask',\n                 figsize=(4,4),\n                 s=0.5,\n                 plotLegend=True,\n                 fontsize=3,\n                 dpi=300,\n                 vmin=0,\n                 vmax=1,\n                 customColors=customColors,\n                 fileName='scimapScatterPlot.svg',\n                 saveDir='/Users/aj/Downloads')\n</code></pre> Source code in <code>scimap/plotting/spatial_scatterPlot.py</code> <pre><code>def spatial_scatterPlot(\n    adata,\n    colorBy,\n    topLayer=None,\n    x_coordinate='X_centroid',\n    y_coordinate='Y_centroid',\n    imageid='imageid',\n    layer=None,\n    subset=None,\n    s=None,\n    ncols=None,\n    alpha=1,\n    dpi=200,\n    fontsize=None,\n    plotLegend=True,\n    cmap='RdBu_r',\n    catCmap='tab20',\n    vmin=None,\n    vmax=None,\n    customColors=None,\n    figsize=(5, 5),\n    invert_yaxis=True,\n    saveDir=None,\n    fileName='scimapScatterPlot.png',\n    **kwargs,\n):\n    \"\"\"\n    Parameters:\n        adata (anndata.AnnData):  \n            Pass the `adata` loaded into memory or a path to the `adata`\n            file (.h5ad).\n\n        colorBy (str):  \n                The column name that will be used for color-coding the points. This can be\n                either markers (data stored in `adata.var`) or observations (data stored in `adata.obs`).\n\n        topLayer (list, optional):  \n                A list of categories that should be plotted on the top layer. These categories\n                must be present in the `colorBy` data. Helps to highlight cell types or cluster that is of interest.\n\n        x_coordinate (str, optional):\n            The column name in `spatial feature table` that records the\n            X coordinates for each cell.\n\n        y_coordinate (str, optional):\n            The column name in `single-cell spatial table` that records the\n            Y coordinates for each cell.\n\n        imageid (str, optional):\n            The column name in `spatial feature table` that contains the image ID\n            for each cell.\n\n        layer (str or None, optional):\n            The layer in `adata.layers` that contains the expression data to use.\n            If `None`, `adata.X` is used. use `raw` to use the data stored in `adata.raw.X`.\n\n        subset (list or None, optional):\n            `imageid` of a single or multiple images to be subsetted for plotting purposes.\n\n        s (float, optional):\n            The size of the markers.\n\n        ncols (int, optional):\n            The number of columns in the final plot when multiple variables are plotted.\n\n        alpha (float, optional):\n            The alpha value of the points (controls opacity).\n\n        dpi (int, optional):\n            The DPI of the figure.\n\n        fontsize (int, optional):\n            The size of the fonts in plot.\n\n        plotLegend (bool, optional):\n            Whether to include a legend.\n\n        cmap (str, optional):\n            The colormap to use for continuous data.\n\n        catCmap (str, optional):\n            The colormap to use for categorical data.\n\n        vmin (float or None, optional):\n            The minimum value of the color scale.\n\n        vmax (float or None, optional):\n            The maximum value of the color scale.\n\n        customColors (dict or None, optional):\n            A dictionary mapping color categories to colors.\n\n        figsize (tuple, optional):\n            The size of the figure. Default is (5, 5).\n\n        invert_yaxis (bool, optional):\n            Invert the Y-axis of the plot.\n\n        saveDir (str or None, optional):\n            The directory to save the output plot. If None, the plot will not be saved.\n\n        fileName (str, optional):\n            The name of the output file. Use desired file format as\n            suffix (e.g. `.png` or `.pdf`). Default is 'scimapScatterPlot.png'.\n\n        **kwargs:\n            Additional keyword arguments to be passed to the matplotlib scatter function.\n\n\n    Returns:\n        Plot (image):\n            If `saveDir` is provided the plot will saved within the\n            provided saveDir.\n\n    Example:\n            ```python\n\n            customColors = { 'Unknown' : '#e5e5e5',\n                            'CD8+ T' : '#ffd166',\n                            'Non T CD4+ cells' : '#06d6a0',\n                            'CD4+ T' : '#118ab2',\n                            'ECAD+' : '#ef476f',\n                            'Immune' : '#073b4c',\n                            'KI67+ ECAD+' : '#000000'\n                }\n\n            sm.pl.spatial_scatterPlot (adata=core6,\n                             colorBy = ['ECAD', 'phenotype_gator'],\n                             subset = 'unmicst-6_cellMask',\n                             figsize=(4,4),\n                             s=0.5,\n                             plotLegend=True,\n                             fontsize=3,\n                             dpi=300,\n                             vmin=0,\n                             vmax=1,\n                             customColors=customColors,\n                             fileName='scimapScatterPlot.svg',\n                             saveDir='/Users/aj/Downloads')\n\n\n            ```\n\n    \"\"\"\n\n    # Load the andata object\n    if isinstance(adata, str):\n        adata = ad.read_h5ad(adata)\n    else:\n        adata = adata.copy()\n\n    # subset data if neede\n    if subset is not None:\n        if isinstance(subset, str):\n            subset = [subset]\n        if layer == 'raw':\n            bdata = adata.copy()\n            bdata.X = adata.raw.X\n            bdata = bdata[bdata.obs[imageid].isin(subset)]\n        else:\n            bdata = adata.copy()\n            bdata = bdata[bdata.obs[imageid].isin(subset)]\n    else:\n        bdata = adata.copy()\n\n    # isolate the data\n    if layer is None:\n        data = pd.DataFrame(bdata.X, index=bdata.obs.index, columns=bdata.var.index)\n    elif layer == 'raw':\n        data = pd.DataFrame(bdata.raw.X, index=bdata.obs.index, columns=bdata.var.index)\n    else:\n        data = pd.DataFrame(\n            bdata.layers[layer], index=bdata.obs.index, columns=bdata.var.index\n        )\n\n    # isolate the meta data\n    meta = bdata.obs\n\n    # toplayer logic\n    if isinstance(topLayer, str):\n        topLayer = [topLayer]\n\n    # identify the things to color\n    if isinstance(colorBy, str):\n        colorBy = [colorBy]\n    # extract columns from data and meta\n    data_cols = [col for col in data.columns if col in colorBy]\n    meta_cols = [col for col in meta.columns if col in colorBy]\n    # combine extracted columns from data and meta\n    colorColumns = pd.concat([data[data_cols], meta[meta_cols]], axis=1)\n\n    # identify the x and y coordinates\n    x = meta[x_coordinate]\n    y = meta[y_coordinate]\n\n    # auto identify rows and columns in the grid plot\n    def calculate_grid_dimensions(num_items, num_columns=None):\n        \"\"\"\n        Calculates the number of rows and columns for a square grid\n        based on the number of items.\n        \"\"\"\n        if num_columns is None:\n            num_rows_columns = int(math.ceil(math.sqrt(num_items)))\n            return num_rows_columns, num_rows_columns\n        else:\n            num_rows = int(math.ceil(num_items / num_columns))\n            return num_rows, num_columns\n\n    # calculate the number of rows and columns\n    nrows, ncols = calculate_grid_dimensions(\n        len(colorColumns.columns), num_columns=ncols\n    )\n\n    # resolve figsize\n    # figsize = (figsize[0]*ncols, figsize[1]*nrows)\n\n    # Estimate point size\n    if s is None:\n        s = (10000 / bdata.shape[0]) / len(colorColumns.columns)\n\n    # Define the categorical colormap (optional)\n    cmap_cat = plt.get_cmap(catCmap)\n\n    # FIIGURE\n    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, dpi=dpi)\n\n    # Flatten the axs array for easier indexing\n    if nrows == 1 and ncols == 1:\n        axs = [axs]  # wrap single subplot in a list\n    else:\n        axs = axs.flatten()\n\n    # Loop over the columns of the DataFrame\n    for i, col in enumerate(colorColumns):\n        # Select the current axis\n        ax = axs[i]\n\n        # invert y-axis\n        if invert_yaxis is True:\n            ax.invert_yaxis()\n\n        # Scatter plot for continuous data\n        if colorColumns[col].dtype.kind in 'iufc':\n            scatter = ax.scatter(\n                x=x,\n                y=y,\n                c=colorColumns[col],\n                cmap=cmap,\n                s=s,\n                vmin=vmin,\n                vmax=vmax,\n                linewidths=0,\n                alpha=alpha,\n                **kwargs,\n            )\n            if plotLegend is True:\n                cbar = plt.colorbar(scatter, ax=ax, pad=0)\n                cbar.ax.tick_params(labelsize=fontsize)\n\n        # Scatter plot for categorical data\n        else:\n            # Get the unique categories in the column\n            categories = colorColumns[col].unique()\n\n            # Map the categories to colors using either the custom colors or the categorical colormap\n            if customColors:\n                colors = {\n                    cat: customColors[cat] for cat in categories if cat in customColors\n                }\n            else:\n                colors = {cat: cmap_cat(i) for i, cat in enumerate(categories)}\n\n            # Ensure topLayer categories are plotted last\n            categories_to_plot_last = (\n                [cat for cat in topLayer if cat in categories] if topLayer else []\n            )\n            categories_to_plot_first = [\n                cat for cat in categories if cat not in categories_to_plot_last\n            ]\n\n            # Plot non-topLayer categories first\n            for cat in categories_to_plot_first:\n                cat_mask = colorColumns[col] == cat\n                ax.scatter(\n                    x=x[cat_mask],\n                    y=y[cat_mask],\n                    c=[colors.get(cat, cmap_cat(np.where(categories == cat)[0][0]))],\n                    s=s,\n                    linewidths=0,\n                    alpha=alpha,\n                    **kwargs,\n                )\n\n            # Then plot topLayer categories\n            for cat in categories_to_plot_last:\n                cat_mask = colorColumns[col] == cat\n                ax.scatter(\n                    x=x[cat_mask],\n                    y=y[cat_mask],\n                    c=[colors.get(cat, cmap_cat(np.where(categories == cat)[0][0]))],\n                    s=s,\n                    linewidths=0,\n                    alpha=alpha,\n                    **kwargs,\n                )\n\n            if plotLegend is True:\n                # Adjust legend to include all categories\n                handles = [\n                    mpatches.Patch(\n                        color=colors.get(\n                            cat, cmap_cat(np.where(categories == cat)[0][0])\n                        ),\n                        label=cat,\n                    )\n                    for cat in categories\n                ]\n                ax.legend(\n                    handles=handles,\n                    bbox_to_anchor=(1.0, 1.0),\n                    loc='upper left',\n                    bbox_transform=ax.transAxes,\n                    fontsize=fontsize,\n                )\n\n        ax.set_title(col)  # fontsize=fontsize\n        ax.set_yticklabels([])\n        ax.set_xticklabels([])\n        ax.set_xticks([])\n        ax.set_yticks([])\n\n    # Remove any empty subplots\n    num_plots = len(colorColumns.columns)\n    for i in range(num_plots, nrows * ncols):\n        ax = axs[i]\n        fig.delaxes(ax)\n\n    # Adjust the layout of the subplots grid\n    plt.tick_params(axis='both', labelsize=fontsize)\n    plt.tight_layout()\n\n    # save figure\n    if saveDir:\n        if not os.path.exists(saveDir):\n            os.makedirs(saveDir)\n        full_path = os.path.join(saveDir, fileName)\n        plt.savefig(full_path, dpi=dpi)\n        plt.close()\n        print(f\"Saved plot to {full_path}\")\n    else:\n        plt.show()\n</code></pre>"},{"location":"Functions/pl/stacked_barplot/","title":"stacked_barplot","text":"<p>Short Description</p> <p><code>sm.pl.stacked_barplot</code>: This function creates stacked bar plots to visualize the  distribution and proportions of categories within a specified categorical column  across different groups or samples in an AnnData object. It supports both <code>matplotlib</code>  for generating static plots and <code>Plotly</code> for interactive, browser-based visualizations.  The flexibility to choose between plotting libraries caters to diverse analysis needs,  from detailed publication-ready figures to dynamic exploration of complex datasets,  enhancing the interpretability of spatial and phenotypic compositions.</p>"},{"location":"Functions/pl/stacked_barplot/#scimap.plotting.stacked_barplot--function","title":"Function","text":""},{"location":"Functions/pl/stacked_barplot/#scimap.plotting.stacked_barplot.stacked_barplot","title":"<code>stacked_barplot(adata, x_axis='imageid', y_axis='phenotype', subset_xaxis=None, subset_yaxis=None, order_xaxis=None, order_yaxis=None, method='percent', plot_tool='matplotlib', matplotlib_cmap=None, matplotlib_bbox_to_anchor=(1, 1.02), matplotlib_legend_loc=2, fileName='stacked_barplot.pdf', saveDir=None, return_data=False, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The annotated data matrix.</p> required <code>x_axis</code> <code>str</code> <p>Column in <code>adata.obs</code> to be used as x-axis categories.</p> <code>'imageid'</code> <code>y_axis</code> <code>str</code> <p>Column in <code>adata.obs</code> representing categories to stack.</p> <code>'phenotype'</code> <code>subset_xaxis</code> <code>list</code> <p>Subsets categories in x_axis before plotting.</p> <code>None</code> <code>subset_yaxis</code> <code>list</code> <p>Subsets categories in y_axis before plotting.</p> <code>None</code> <code>order_xaxis</code> <code>list</code> <p>Specifies custom ordering for x-axis categories.</p> <code>None</code> <code>order_yaxis</code> <code>list</code> <p>Specifies custom ordering for y-axis categories.</p> <code>None</code> <code>method</code> <code>str</code> <p>Plotting method; 'percent' for percentage proportions, 'absolute' for actual counts.</p> <code>'percent'</code> <code>plot_tool</code> <code>str</code> <p>Choice of plotting library; 'matplotlib' for static plots, 'plotly' for interactive plots.</p> <code>'matplotlib'</code> <code>matplotlib_cmap</code> <code>str</code> <p>Matplotlib colormap for coloring the bars.</p> <code>None</code> <code>matplotlib_bbox_to_anchor</code> <code>tuple</code> <p>Adjusts the legend's bounding box location in matplotlib plots.</p> <code>(1, 1.02)</code> <code>matplotlib_legend_loc</code> <code>int</code> <p>Sets the legend location in matplotlib plots.</p> <code>2</code> <code>return_data</code> <code>bool</code> <p>If True, returns a DataFrame used for plotting instead of displaying the plot.</p> <code>False</code> <code>fileName</code> <code>str</code> <p>Name of the file to save the plot. Relevant only if <code>saveDir</code> is not None.</p> <code>'stacked_barplot.pdf'</code> <code>saveDir</code> <code>str</code> <p>Directory to save the generated plot. If None, the plot is not saved.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to the plotting function (matplotlib or plotly).</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Plot</code> <code>matplotlib</code> <p>If <code>return_data</code> is True, returns a DataFrame containing the data used for plotting. Otherwise, displays the stacked bar plot.</p> Example <pre><code># Default stacked bar plot showing percentage composition\nsm.pl.stacked_barplot(adata, x_axis='sample_id', y_axis='cell_type', method='percent')\n\n# Stacked bar plot using absolute counts with matplotlib customization\nsm.pl.stacked_barplot(adata, x_axis='region', y_axis='phenotype', method='absolute', plot_tool='matplotlib',\n                matplotlib_cmap='tab20', figsize=(12, 6), edgecolor='white')\n\n# Interactive stacked bar plot using Plotly with subset and custom order\nsm.pl.stacked_barplot(adata, x_axis='condition', y_axis='cell_state', subset_xaxis=['Control', 'Treated'],\n                order_yaxis=['State1', 'State2', 'State3'], method='percent', plot_tool='plotly',\n                color_discrete_map={'State1': '#1f77b4', 'State2': '#ff7f0e', 'State3': '#2ca02c'})\n\n# Retrieve data used for plotting\ndata_df = sm.pl.stacked_barplot(adata, x_axis='batch', y_axis='cell_type', return_data=True)\n</code></pre> Source code in <code>scimap/plotting/stacked_barplot.py</code> <pre><code>def stacked_barplot(\n    adata,\n    x_axis='imageid',\n    y_axis='phenotype',\n    subset_xaxis=None,\n    subset_yaxis=None,\n    order_xaxis=None,\n    order_yaxis=None,\n    method='percent',\n    plot_tool='matplotlib',\n    matplotlib_cmap=None,\n    matplotlib_bbox_to_anchor=(1, 1.02),\n    matplotlib_legend_loc=2,\n    fileName='stacked_barplot.pdf',\n    saveDir=None,\n    return_data=False,\n    **kwargs,\n):\n    \"\"\"\n    Parameters:\n            adata (anndata.AnnData):\n                The annotated data matrix.\n\n            x_axis (str):\n                Column in `adata.obs` to be used as x-axis categories.\n\n            y_axis (str):\n                Column in `adata.obs` representing categories to stack.\n\n            subset_xaxis (list, optional):\n                Subsets categories in x_axis before plotting.\n\n            subset_yaxis (list, optional):\n                Subsets categories in y_axis before plotting.\n\n            order_xaxis (list, optional):\n                Specifies custom ordering for x-axis categories.\n\n            order_yaxis (list, optional):\n                Specifies custom ordering for y-axis categories.\n\n            method (str, optional):\n                Plotting method; 'percent' for percentage proportions, 'absolute' for actual counts.\n\n            plot_tool (str, optional):\n                Choice of plotting library; 'matplotlib' for static plots, 'plotly' for interactive plots.\n\n            matplotlib_cmap (str, optional):\n                Matplotlib colormap for coloring the bars.\n\n            matplotlib_bbox_to_anchor (tuple, optional):\n                Adjusts the legend's bounding box location in matplotlib plots.\n\n            matplotlib_legend_loc (int, optional):\n                Sets the legend location in matplotlib plots.\n\n            return_data (bool, optional):\n                If True, returns a DataFrame used for plotting instead of displaying the plot.\n\n            fileName (str, optional):\n                Name of the file to save the plot. Relevant only if `saveDir` is not None.\n\n            saveDir (str, optional):\n                Directory to save the generated plot. If None, the plot is not saved.\n\n            **kwargs:\n                Additional arguments passed to the plotting function (matplotlib or plotly).\n\n    Returns:\n        Plot (matplotlib):\n            If `return_data` is True, returns a DataFrame containing the data used for plotting.\n            Otherwise, displays the stacked bar plot.\n\n    Example:\n        ```python\n\n        # Default stacked bar plot showing percentage composition\n        sm.pl.stacked_barplot(adata, x_axis='sample_id', y_axis='cell_type', method='percent')\n\n        # Stacked bar plot using absolute counts with matplotlib customization\n        sm.pl.stacked_barplot(adata, x_axis='region', y_axis='phenotype', method='absolute', plot_tool='matplotlib',\n                        matplotlib_cmap='tab20', figsize=(12, 6), edgecolor='white')\n\n        # Interactive stacked bar plot using Plotly with subset and custom order\n        sm.pl.stacked_barplot(adata, x_axis='condition', y_axis='cell_state', subset_xaxis=['Control', 'Treated'],\n                        order_yaxis=['State1', 'State2', 'State3'], method='percent', plot_tool='plotly',\n                        color_discrete_map={'State1': '#1f77b4', 'State2': '#ff7f0e', 'State3': '#2ca02c'})\n\n        # Retrieve data used for plotting\n        data_df = sm.pl.stacked_barplot(adata, x_axis='batch', y_axis='cell_type', return_data=True)\n\n        ```\n    \"\"\"\n\n    # create the dataframe with details\n    data = pd.DataFrame(adata.obs)[[x_axis, y_axis]].astype(str)\n\n    # subset the data if needed\n    # if subset_data is not None:data = data[data[list(subset_data.keys())[0]].isin(list(subset_data.values())[0])]\n\n    if subset_xaxis is not None:\n        if isinstance(subset_xaxis, str):\n            subset_xaxis = [subset_xaxis]\n        data = data[data[x_axis].isin(subset_xaxis)]\n    if subset_yaxis is not None:\n        if isinstance(subset_yaxis, str):\n            subset_yaxis = [subset_yaxis]\n        data = data[data[y_axis].isin(subset_yaxis)]\n\n    # Method: Absolute or Percentile\n    if method == 'percent':\n        total = data.groupby([x_axis, y_axis]).size().unstack().fillna(0).sum(axis=1)\n        rg = pd.DataFrame(\n            data.groupby([x_axis, y_axis])\n            .size()\n            .unstack()\n            .fillna(0)\n            .div(total, axis=0)\n            .stack()\n        )\n    elif method == 'absolute':\n        rg = pd.DataFrame(\n            data.groupby([x_axis, y_axis]).size().unstack().fillna(0).stack()\n        )\n    else:\n        raise ValueError('method should be either percent or absolute')\n\n    # change column name\n    rg.columns = ['count']\n\n    # Add the index as columns in the data frame\n    rg.reset_index(inplace=True)\n\n    # re-order the x oy y axis if requested by user\n    if order_xaxis is not None:\n        rg[x_axis] = rg[x_axis].astype('category')\n        rg[x_axis] = rg[x_axis].cat.reorder_categories(order_xaxis)\n        rg = rg.sort_values(x_axis)\n    if order_yaxis is not None:\n        rg[y_axis] = rg[y_axis].astype('category')\n        rg[y_axis] = rg[y_axis].cat.reorder_categories(order_yaxis)\n        rg = rg.sort_values(y_axis)\n    if order_xaxis and order_yaxis is not None:\n        rg = rg.sort_values([x_axis, y_axis])\n\n    pivot_df = rg.pivot(index=x_axis, columns=y_axis, values='count')\n\n    # Plotting tool\n    if plot_tool == 'matplotlib':\n\n        if matplotlib_cmap is None:\n            if len(rg[y_axis].unique()) &lt;= 9:\n                matplotlib_cmap = \"Set1\"\n            elif len(rg[y_axis].unique()) &gt; 9 and len(rg[y_axis].unique()) &lt;= 20:\n                matplotlib_cmap = plt.cm.tab20  # tab20\n            else:\n                matplotlib_cmap = plt.cm.gist_ncar\n\n        # Plotting\n        # add width if not passed via parameters\n        try:\n            width\n        except NameError:\n            width = 0.9\n        # actual plotting\n        # p = pivot_df.plot.bar(stacked=True, cmap=matplotlib_cmap, width=width,  **kwargs)\n        # handles, labels = p.get_legend_handles_labels() # for reversing the order of the legend\n        # p.legend(reversed(handles), reversed(labels), bbox_to_anchor=matplotlib_bbox_to_anchor, loc=matplotlib_legend_loc)\n\n        # Actual plotting\n        ax = pivot_df.plot.bar(\n            stacked=True, cmap=matplotlib_cmap, width=width, **kwargs\n        )\n        fig = ax.get_figure()  # Get the Figure object to save\n        handles, labels = (\n            ax.get_legend_handles_labels()\n        )  # for reversing the order of the legend\n        ax.legend(\n            list(reversed(handles)),\n            list(reversed(labels)),\n            bbox_to_anchor=matplotlib_bbox_to_anchor,\n            loc=matplotlib_legend_loc,\n        )\n\n        # Saving the figure if saveDir and fileName are provided\n        if saveDir:\n            if not os.path.exists(saveDir):\n                os.makedirs(saveDir)\n            full_path = os.path.join(saveDir, fileName)\n            fig.savefig(full_path, dpi=300)  # Use fig.savefig instead of p.savefig\n            plt.close(fig)  # Close the figure properly\n            print(f\"Saved plot to {full_path}\")\n        else:\n            plt.show()\n\n    elif plot_tool == 'plotly':\n\n        fig = px.bar(rg, x=x_axis, y=\"count\", color=y_axis, **kwargs)\n        fig.update_layout(\n            {'plot_bgcolor': 'rgba(0, 0, 0, 0)', 'paper_bgcolor': 'rgba(0, 0, 0, 0)'},\n            xaxis=dict(tickmode='linear'),  # type = 'category'\n        )\n        fig.show()\n\n    else:\n\n        raise ValueError('plot_tool should be either matplotlib or plotly')\n\n    # Return data\n    if return_data is True:\n        return pivot_df\n</code></pre>"},{"location":"Functions/pl/umap/","title":"umap","text":"<p>Short Description</p> <p><code>sm.pl.umap</code>: This function facilitates the creation of scatter plots based  on UMAP (Uniform Manifold Approximation and Projection) embeddings stored  in an AnnData object. It offers extensive customization options for visualizing  high-dimensional data reduced to two dimensions, including the ability to color  points by gene expression levels, metadata annotations, or other categorical or  continuous variables. Users can leverage this function to explore and interpret  complex datasets visually, enhancing the understanding of underlying biological  variations and relationships.</p>"},{"location":"Functions/pl/umap/#scimap.plotting.umap--function","title":"Function","text":""},{"location":"Functions/pl/umap/#scimap.plotting.umap.umap","title":"<code>umap(adata, color=None, layer=None, use_raw=False, log=False, label='umap', cmap='vlag', palette=None, alpha=0.8, figsize=(5, 5), s=None, ncols=None, tight_layout=False, return_data=False, saveDir=None, fileName='umap.pdf', **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The annotated data matrix.</p> required <code>color</code> <code>list</code> <p>List of keys from <code>adata.obs.columns</code> or <code>adata.var.index</code> to color the plot. Allows multiple keys for facetted plotting.</p> <code>None</code> <code>layer</code> <code>str</code> <p>Specifies the AnnData layer to use for UMAP calculations. Defaults to using <code>adata.X</code>.</p> <code>None</code> <code>use_raw</code> <code>bool</code> <p>If True, uses <code>adata.raw.X</code> for coloring the plot, useful for visualizing gene expression on UMAP.</p> <code>False</code> <code>log</code> <code>bool</code> <p>Applies log transformation (<code>np.log1p</code>) to the data before plotting. Useful for gene expression data.</p> <code>False</code> <code>label</code> <code>str</code> <p>Key in <code>adata.obsm</code> where UMAP coordinates are stored.</p> <code>'umap'</code> <code>cmap</code> <code>str</code> <p>Colormap for continuous variables. Supports matplotlib colormap names and objects.</p> <code>'vlag'</code> <code>palette</code> <code>dict</code> <p>Specific colors for different categories as a dictionary mapping from categories to colors.</p> <code>None</code> <code>alpha</code> <code>float</code> <p>Transparency level of the points. Ranges from 0 (transparent) to 1 (opaque).</p> <code>0.8</code> <code>figsize</code> <code>tuple</code> <p>Figure size specified as (width, height) in inches.</p> <code>(5, 5)</code> <code>s</code> <code>int</code> <p>Size of the points in the plot.</p> <code>None</code> <code>ncols</code> <code>int</code> <p>Number of columns for facetted plotting.</p> <code>None</code> <code>tight_layout</code> <code>bool</code> <p>Adjusts subplot params for a tight layout.</p> <code>False</code> <code>return_data</code> <code>bool</code> <p>If True, returns the DataFrame containing data used for plotting instead of displaying the plot.</p> <code>False</code> <code>saveDir</code> <code>str</code> <p>Path and filename to save the figure. File extension determines the format (e.g., <code>.pdf</code>, <code>.png</code>).</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to matplotlib plot function.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Plot</code> <code>matplotlib</code> <p>Optionally returns the data used for plotting if <code>return_data=True</code>.</p> Example <pre><code># Basic UMAP visualization with default settings\nsm.pl.umap(adata, color='cell_type')\n\n# UMAP visualization with log transformation and custom colormap\nsm.pl.umap(adata, color='gene_expression', log=True, cmap='coolwarm')\n\n# Facetted UMAP plotting with custom point size and saved figure\nsm.pl.umap(adata, color=['cell_type', 'condition'], s=100, figsize=(10, 5), save_figure='/path/to/umap_plot.png')\n</code></pre> Source code in <code>scimap/plotting/umap.py</code> <pre><code>def umap(\n    adata,\n    color=None,\n    layer=None,\n    use_raw=False,\n    log=False,\n    label='umap',\n    cmap='vlag',\n    palette=None,\n    alpha=0.8,\n    figsize=(5, 5),\n    s=None,\n    ncols=None,\n    tight_layout=False,\n    return_data=False,\n    saveDir=None,\n    fileName='umap.pdf',\n    **kwargs,\n):\n    \"\"\"\n    Parameters:\n            adata (anndata.AnnData):\n                The annotated data matrix.\n\n            color (list, optional):\n                List of keys from `adata.obs.columns` or `adata.var.index` to color the plot.\n                Allows multiple keys for facetted plotting.\n\n            layer (str, optional):\n                Specifies the AnnData layer to use for UMAP calculations. Defaults to using `adata.X`.\n\n            use_raw (bool, optional):\n                If True, uses `adata.raw.X` for coloring the plot, useful for visualizing gene expression on UMAP.\n\n            log (bool, optional):\n                Applies log transformation (`np.log1p`) to the data before plotting. Useful for gene expression data.\n\n            label (str, optional):\n                Key in `adata.obsm` where UMAP coordinates are stored.\n\n            cmap (str, optional):\n                Colormap for continuous variables. Supports matplotlib colormap names and objects.\n\n            palette (dict, optional):\n                Specific colors for different categories as a dictionary mapping from categories to colors.\n\n            alpha (float, optional):\n                Transparency level of the points. Ranges from 0 (transparent) to 1 (opaque).\n\n            figsize (tuple, optional):\n                Figure size specified as (width, height) in inches.\n\n            s (int, optional):\n                Size of the points in the plot.\n\n            ncols (int, optional):\n                Number of columns for facetted plotting.\n\n            tight_layout (bool, optional):\n                Adjusts subplot params for a tight layout.\n\n            return_data (bool, optional):\n                If True, returns the DataFrame containing data used for plotting instead of displaying the plot.\n\n            saveDir (str, optional):\n                Path and filename to save the figure. File extension determines the format (e.g., `.pdf`, `.png`).\n\n            **kwargs:\n                Additional keyword arguments passed to matplotlib plot function.\n\n    Returns:\n            Plot (matplotlib):\n                    Optionally returns the data used for plotting if `return_data=True`.\n\n    Example:\n        ```python\n\n        # Basic UMAP visualization with default settings\n        sm.pl.umap(adata, color='cell_type')\n\n        # UMAP visualization with log transformation and custom colormap\n        sm.pl.umap(adata, color='gene_expression', log=True, cmap='coolwarm')\n\n        # Facetted UMAP plotting with custom point size and saved figure\n        sm.pl.umap(adata, color=['cell_type', 'condition'], s=100, figsize=(10, 5), save_figure='/path/to/umap_plot.png')\n\n        ```\n    \"\"\"\n\n    # check if umap tool has been run\n    try:\n        adata.obsm[label]\n    except KeyError:\n        raise KeyError(\"Please run `sm.tl.umap(adata)` first\")\n\n    # identify the coordinates\n    umap_coordinates = pd.DataFrame(\n        adata.obsm[label], index=adata.obs.index, columns=['umap-1', 'umap-2']\n    )\n\n    # other data that the user requests\n    if color is not None:\n        if isinstance(color, str):\n            color = [color]\n        # identify if all elemets of color are available\n        if (\n            set(color).issubset(list(adata.var.index) + list(adata.obs.columns))\n            is False\n        ):\n            raise ValueError(\n                \"Element passed to `color` is not found in adata, please check!\"\n            )\n\n        # organise the data\n        if any(item in color for item in list(adata.obs.columns)):\n            adataobs = adata.obs.loc[:, adata.obs.columns.isin(color)]\n            adataobs = adataobs.apply(lambda x: x.astype('category'))\n\n        else:\n            adataobs = None\n\n        if any(item in color for item in list(adata.var.index)):\n            # find the index of the marker\n            marker_index = np.where(np.isin(list(adata.var.index), color))[0]\n            if layer is not None:\n                adatavar = adata.layers[layer][:, np.r_[marker_index]]\n            elif use_raw is True:\n                adatavar = adata.raw.X[:, np.r_[marker_index]]\n            else:\n                adatavar = adata.X[:, np.r_[marker_index]]\n            adatavar = pd.DataFrame(\n                adatavar,\n                index=adata.obs.index,\n                columns=list(adata.var.index[marker_index]),\n            )\n        else:\n            adatavar = None\n\n        # combine all color data\n        if adataobs is not None and adatavar is not None:\n            color_data = pd.concat([adataobs, adatavar], axis=1)\n        elif adataobs is not None and adatavar is None:\n            color_data = adataobs\n        elif adataobs is None and adatavar is not None:\n            color_data = adatavar\n    else:\n        color_data = None\n\n    # combine color data with umap coordinates\n    if color_data is not None:\n        final_data = pd.concat([umap_coordinates, color_data], axis=1)\n    else:\n        final_data = umap_coordinates\n\n    # create some reasonable defaults\n    # estimate number of columns in subpolt\n    nplots = len(final_data.columns) - 2  # total number of plots\n    if ncols is None:\n        if nplots &gt;= 4:\n            subplot = [math.ceil(nplots / 4), 4]\n        elif nplots == 0:\n            subplot = [1, 1]\n        else:\n            subplot = [math.ceil(nplots / nplots), nplots]\n    else:\n        subplot = [math.ceil(nplots / ncols), ncols]\n\n    if nplots == 0:\n        n_plots_to_remove = 0\n    else:\n        n_plots_to_remove = (\n            np.prod(subplot) - nplots\n        )  # figure if we have to remove any subplots\n\n    # size of points\n    if s is None:\n        if nplots == 0:\n            s = 100000 / adata.shape[0]\n        else:\n            s = (100000 / adata.shape[0]) / nplots\n\n    # if there are categorical data then assign colors to them\n    if final_data.select_dtypes(exclude=[\"number\", \"bool_\", \"object_\"]).shape[1] &gt; 0:\n        # find all categories in the dataframe\n        cat_data = final_data.select_dtypes(exclude=[\"number\", \"bool_\", \"object_\"])\n        # find all categories\n        all_cat = []\n        for i in cat_data.columns:\n            all_cat.append(list(cat_data[i].cat.categories))\n\n        # generate colormapping for all categories\n        less_9 = [colors.rgb2hex(x) for x in sns.color_palette('Set1')]\n        nineto20 = [colors.rgb2hex(x) for x in sns.color_palette('tab20')]\n        greater20 = [\n            colors.rgb2hex(x)\n            for x in sns.color_palette('gist_ncar', max([len(i) for i in all_cat]))\n        ]\n\n        all_cat_colormap = dict()\n        for i in range(len(all_cat)):\n            if len(all_cat[i]) &lt;= 9:\n                dict1 = dict(zip(all_cat[i], less_9[: len(all_cat[i])]))\n            elif len(all_cat[i]) &gt; 9 and len(all_cat[i]) &lt;= 20:\n                dict1 = dict(zip(all_cat[i], nineto20[: len(all_cat[i])]))\n            else:\n                dict1 = dict(zip(all_cat[i], greater20[: len(all_cat[i])]))\n            all_cat_colormap.update(dict1)\n\n        # if user has passed in custom colours update the colors\n        if palette is not None:\n            all_cat_colormap.update(palette)\n    else:\n        all_cat_colormap = None\n\n    # plot\n    fig, ax = plt.subplots(subplot[0], subplot[1], figsize=figsize)\n    plt.rcdefaults()\n    # plt.rcParams['axes.facecolor'] = 'white'\n\n    # remove unwanted axes\n    # fig.delaxes(ax[-1])\n    if n_plots_to_remove &gt; 0:\n        for i in range(n_plots_to_remove):\n            fig.delaxes(ax[-1][(len(ax[-1]) - 1) - i : (len(ax[-1])) - i][0])\n\n    # to make sure the ax is always 2x2\n    if any(i &gt; 1 for i in subplot):\n        if any(i == 1 for i in subplot):\n            ax = ax.reshape(subplot[0], subplot[1])\n\n    if nplots == 0:\n        ax.scatter(\n            x=final_data['umap-1'],\n            y=final_data['umap-2'],\n            s=s,\n            cmap=cmap,\n            alpha=alpha,\n            **kwargs,\n        )\n        plt.xlabel(\"UMAP-1\")\n        plt.ylabel(\"UMAP-2\")\n        plt.tick_params(right=False, top=False, left=False, bottom=False)\n        ax.get_xaxis().set_ticks([])\n        ax.get_yaxis().set_ticks([])\n        if tight_layout is True:\n            plt.tight_layout()\n\n    elif all(i == 1 for i in subplot):\n        column_to_plot = [\n            e for e in list(final_data.columns) if e not in ('umap-1', 'umap-2')\n        ][0]\n        if all_cat_colormap is None:\n            im = ax.scatter(\n                x=final_data['umap-1'],\n                y=final_data['umap-2'],\n                s=s,\n                c=final_data[column_to_plot],\n                cmap=cmap,\n                alpha=alpha,\n                **kwargs,\n            )\n            plt.colorbar(im, ax=ax)\n        else:\n            ax.scatter(\n                x=final_data['umap-1'],\n                y=final_data['umap-2'],\n                s=s,\n                c=final_data[column_to_plot].map(all_cat_colormap),\n                cmap=cmap,\n                alpha=alpha,\n                **kwargs,\n            )\n            # create legend\n            patchList = []\n            for key in list(final_data[column_to_plot].unique()):\n                data_key = mpatches.Patch(color=all_cat_colormap[key], label=key)\n                patchList.append(data_key)\n                ax.legend(\n                    handles=patchList,\n                    bbox_to_anchor=(1.05, 1),\n                    loc=2,\n                    borderaxespad=0.0,\n                )\n\n        plt.xlabel(\"UMAP-1\")\n        plt.ylabel(\"UMAP-2\")\n        plt.title(column_to_plot)\n        plt.tick_params(right=False, top=False, left=False, bottom=False)\n        ax.set(xticklabels=([]))\n        ax.set(yticklabels=([]))\n        if tight_layout is True:\n            plt.tight_layout()\n\n    else:\n        column_to_plot = [\n            e for e in list(final_data.columns) if e not in ('umap-1', 'umap-2')\n        ]\n        k = 0\n        for i, j in itertools.product(range(subplot[0]), range(subplot[1])):\n\n            if final_data[column_to_plot[k]].dtype == 'category':\n                ax[i, j].scatter(\n                    x=final_data['umap-1'],\n                    y=final_data['umap-2'],\n                    s=s,\n                    c=final_data[column_to_plot[k]].map(all_cat_colormap),\n                    cmap=cmap,\n                    alpha=alpha,\n                    **kwargs,\n                )\n                # create legend\n                patchList = []\n                for key in list(final_data[column_to_plot[k]].unique()):\n                    data_key = mpatches.Patch(color=all_cat_colormap[key], label=key)\n                    patchList.append(data_key)\n                    ax[i, j].legend(\n                        handles=patchList,\n                        bbox_to_anchor=(1.05, 1),\n                        loc=2,\n                        borderaxespad=0.0,\n                    )\n            else:\n                im = ax[i, j].scatter(\n                    x=final_data['umap-1'],\n                    y=final_data['umap-2'],\n                    s=s,\n                    c=final_data[column_to_plot[k]],\n                    cmap=cmap,\n                    alpha=alpha,\n                    **kwargs,\n                )\n                plt.colorbar(im, ax=ax[i, j])\n\n            ax[i, j].tick_params(right=False, top=False, left=False, bottom=False)\n            ax[i, j].set_xticklabels([])\n            ax[i, j].set_yticklabels([])\n            ax[i, j].set_xlabel(\"UMAP-1\")\n            ax[i, j].set_ylabel(\"UMAP-2\")\n            ax[i, j].set_title(column_to_plot[k])\n            if tight_layout is True:\n                plt.tight_layout()\n            k = k + 1  # iterator\n\n    # if save figure is requested\n    if saveDir:\n        if not os.path.exists(saveDir):\n            os.makedirs(saveDir)\n        full_path = os.path.join(saveDir, fileName)\n        plt.savefig(full_path, dpi=300)\n        plt.close(fig)\n        print(f\"Saved heatmap to {full_path}\")\n    else:\n        plt.show()\n\n    # return data if needed\n    if return_data is True:\n        return final_data\n</code></pre>"},{"location":"Functions/pl/voronoi/","title":"voronoi","text":"<p>Short Description</p> <p><code>sm.pl.voronoi</code>: This function enables the visualization of spatial data through the creation of Voronoi diagrams,  offering a distinctive method to explore the spatial distribution of cells or features within a defined area.  Users can color these diagrams according to values from any categorical column in their dataset,  such as cell type or tissue compartment, particularly good looking for manuscripts.</p> <p>Key considerations for optimal use of this function include:</p> <ul> <li> <p>Application Scope: Voronoi diagrams are particularly effective for analyzing small to moderately sized spatial regions,  supporting regions with up to 5,000 cells. This constraint ensures both interpretability and performance are maintained,  as larger regions can result in complex visualizations that are difficult to interpret and may require extended processing times.</p> </li> <li> <p>Performance and Interpretability: While Voronoi diagrams offer insightful visualizations for spatial data, their  utility diminishes with increasing dataset size. For regions containing more than 5,000 cells, the generated plots may become  cluttered and challenging to interpret, alongside experiencing significant delays in generation time. Users are encouraged to segment larger datasets into smaller, manageable regions or utilize alternative visualization methods  suitable for high-density spatial data.</p> </li> </ul>"},{"location":"Functions/pl/voronoi/#scimap.plotting.voronoi--function","title":"Function","text":""},{"location":"Functions/pl/voronoi/#scimap.plotting.voronoi.voronoi","title":"<code>voronoi(adata, color_by=None, colors=None, x_coordinate='X_centroid', y_coordinate='Y_centroid', imageid='imageid', subset=None, x_lim=None, y_lim=None, flip_y=True, voronoi_edge_color='black', voronoi_line_width=0.1, voronoi_alpha=0.5, size_max=np.inf, overlay_points=None, overlay_points_categories=None, overlay_drop_categories=None, overlay_points_colors=None, overlay_point_size=5, overlay_point_alpha=1, overlay_point_shape='.', plot_legend=True, fileName='voronoi.pdf', saveDir=None, legend_size=6, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>An AnnData object containing the spatial data to be visualized.</p> required <code>color_by</code> <code>str</code> <p>The name of the column used to color the Voronoi diagram. Typically, this column represents categorical variables such as cell types or tissue compartments.</p> <code>None</code> <code>colors</code> <code>str or Dict</code> <p>Custom color mapping for the Voronoi diagram. Can be specified as a seaborn color palette name or a dictionary mapping categories to colors.</p> <code>None</code> <code>x_coordinate</code> <code>str</code> <p>The column name containing the x-coordinates.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <code>str</code> <p>The column name containing the y-coordinates.</p> <code>'Y_centroid'</code> <code>imageid</code> <code>str</code> <p>The column name containing identifiers for different images or spatial contexts.</p> <code>'imageid'</code> <code>subset</code> <code>str</code> <p>Specifies the identifier of a single image to focus the visualization on.</p> <code>None</code> <code>x_lim</code> <code>list</code> <p>The x-axis limits for the plot as a list of two elements: [xmin, xmax].</p> <code>None</code> <code>y_lim</code> <code>list</code> <p>The y-axis limits for the plot as a list of two elements: [ymin, ymax].</p> <code>None</code> <code>flip_y</code> <code>bool</code> <p>If set to True, the y-axis will be flipped. This may be necessary for some datasets where y-coordinates are inverted.</p> <code>True</code> <code>voronoi_edge_color</code> <code>str</code> <p>The color of the edges of the Voronoi cells.</p> <code>'black'</code> <code>voronoi_line_width</code> <code>float</code> <p>The line width of the Voronoi cell edges.</p> <code>0.1</code> <code>voronoi_alpha</code> <code>float</code> <p>The opacity of the Voronoi cells, ranging from 0 (completely transparent) to 1 (completely opaque).</p> <code>0.5</code> <code>size_max</code> <code>float</code> <p>The maximum size for the Voronoi cells. Can be used to limit the cell size in the visualization.</p> <code>inf</code> <code>overlay_points</code> <code>str</code> <p>The name of the column to use for overlaying points on the Voronoi diagram.</p> <code>None</code> <code>overlay_points_categories</code> <code>list</code> <p>Specific categories within the <code>overlay_points</code> column to include in the overlay.</p> <code>None</code> <code>overlay_drop_categories</code> <code>list</code> <p>Specific categories within the <code>overlay_points</code> column to exclude from the overlay.</p> <code>None</code> <code>overlay_points_colors</code> <code>str or Dict</code> <p>Custom color mapping for the overlay points. Can be specified as a seaborn color palette name or a dictionary mapping categories to colors.</p> <code>None</code> <code>overlay_point_size</code> <code>float</code> <p>The size of the overlay points.</p> <code>5</code> <code>overlay_point_alpha</code> <code>float</code> <p>The opacity of the overlay points, ranging from 0 (completely transparent) to 1 (completely opaque).</p> <code>1</code> <code>overlay_point_shape</code> <code>str</code> <p>The shape of the overlay points.</p> <code>'.'</code> <code>plot_legend</code> <code>bool</code> <p>Whether to display a legend for the plot.</p> <code>True</code> <code>fileName</code> <code>str</code> <p>Name of the file to save the plot. Relevant only if <code>saveDir</code> is not None.</p> <code>'voronoi.pdf'</code> <code>saveDir</code> <code>str</code> <p>Directory to save the generated plot. If None, the plot is not saved.</p> <code>None</code> <code>legend_size</code> <code>float</code> <p>The font size of the legend text.</p> <code>6</code> <p>Returns:</p> Name Type Description <code>Plot</code> <code>matplotlib</code> <p>Returns a plot.</p> Example <pre><code>#E xample 1: Basic Voronoi plot with default settings\n\nsm.pl.voronoi(adata)\n\n\n# Example 2: Voronoi plot colored by cell type, with customized colors and overlay points for a specific phenotype\n\nsm.pl.voronoi(adata, color_by='cell_type', colors='Set2', overlay_points='phenotype', overlay_points_colors={'phenotype1': 'red', 'phenotype2': 'blue'}, plot_legend=True)\n\n\n# Example 3: Voronoi plot for a specific image subset, with adjusted alpha and line width, and without flipping the y-axis\n\nsm.pl.voronoi(adata, subset='image_01', voronoi_alpha=0.7, voronoi_line_width=0.5)\n</code></pre> Source code in <code>scimap/plotting/voronoi.py</code> <pre><code>def voronoi(\n    adata,\n    color_by=None,\n    colors=None,\n    x_coordinate='X_centroid',\n    y_coordinate='Y_centroid',\n    imageid='imageid',\n    subset=None,\n    x_lim=None,\n    y_lim=None,\n    flip_y=True,\n    voronoi_edge_color='black',\n    voronoi_line_width=0.1,\n    voronoi_alpha=0.5,\n    size_max=np.inf,\n    overlay_points=None,\n    overlay_points_categories=None,\n    overlay_drop_categories=None,\n    overlay_points_colors=None,\n    overlay_point_size=5,\n    overlay_point_alpha=1,\n    overlay_point_shape=\".\",\n    plot_legend=True,\n    fileName='voronoi.pdf',\n    saveDir=None,\n    legend_size=6,\n    **kwargs,\n):\n    \"\"\"\n    Parameters:\n            adata (anndata.AnnData):\n                An AnnData object containing the spatial data to be visualized.\n\n            color_by (str, optional):\n                The name of the column used to color the Voronoi diagram. Typically, this column represents categorical\n                variables such as cell types or tissue compartments.\n\n            colors (str or Dict, optional):\n                Custom color mapping for the Voronoi diagram. Can be specified as a seaborn color palette name or a dictionary\n                mapping categories to colors.\n\n            x_coordinate (str, optional):\n                The column name containing the x-coordinates.\n\n            y_coordinate (str, optional):\n                The column name containing the y-coordinates.\n\n            imageid (str, optional):\n                The column name containing identifiers for different images or spatial contexts.\n\n            subset (str, optional):\n                Specifies the identifier of a single image to focus the visualization on.\n\n            x_lim (list, optional):\n                The x-axis limits for the plot as a list of two elements: [xmin, xmax].\n\n            y_lim (list, optional):\n                The y-axis limits for the plot as a list of two elements: [ymin, ymax].\n\n            flip_y (bool, optional):\n                If set to True, the y-axis will be flipped. This may be necessary for some datasets where y-coordinates are\n                inverted.\n\n            voronoi_edge_color (str, optional):\n                The color of the edges of the Voronoi cells.\n\n            voronoi_line_width (float, optional):\n                The line width of the Voronoi cell edges.\n\n            voronoi_alpha (float, optional):\n                The opacity of the Voronoi cells, ranging from 0 (completely transparent) to 1 (completely opaque).\n\n            size_max (float, optional):\n                The maximum size for the Voronoi cells. Can be used to limit the cell size in the visualization.\n\n            overlay_points (str, optional):\n                The name of the column to use for overlaying points on the Voronoi diagram.\n\n            overlay_points_categories (list, optional):\n                Specific categories within the `overlay_points` column to include in the overlay.\n\n            overlay_drop_categories (list, optional):\n                Specific categories within the `overlay_points` column to exclude from the overlay.\n\n            overlay_points_colors (str or Dict, optional):\n                Custom color mapping for the overlay points. Can be specified as a seaborn color palette name or a dictionary\n                mapping categories to colors.\n\n            overlay_point_size (float, optional):\n                The size of the overlay points.\n\n            overlay_point_alpha (float, optional):\n                The opacity of the overlay points, ranging from 0 (completely transparent) to 1 (completely opaque).\n\n            overlay_point_shape (str, optional):\n                The shape of the overlay points.\n\n            plot_legend (bool, optional):\n                Whether to display a legend for the plot.\n\n            fileName (str, optional):\n                Name of the file to save the plot. Relevant only if `saveDir` is not None.\n\n            saveDir (str, optional):\n                Directory to save the generated plot. If None, the plot is not saved.\n\n            legend_size (float, optional):\n                The font size of the legend text.\n\n    Returns:\n            Plot (matplotlib):\n                    Returns a plot.\n\n    Example:\n            ```python\n\n\n            #E xample 1: Basic Voronoi plot with default settings\n\n            sm.pl.voronoi(adata)\n\n\n            # Example 2: Voronoi plot colored by cell type, with customized colors and overlay points for a specific phenotype\n\n            sm.pl.voronoi(adata, color_by='cell_type', colors='Set2', overlay_points='phenotype', overlay_points_colors={'phenotype1': 'red', 'phenotype2': 'blue'}, plot_legend=True)\n\n\n            # Example 3: Voronoi plot for a specific image subset, with adjusted alpha and line width, and without flipping the y-axis\n\n            sm.pl.voronoi(adata, subset='image_01', voronoi_alpha=0.7, voronoi_line_width=0.5)\n\n            ```\n\n    \"\"\"\n\n    # create the data frame needed\n    data = adata.obs.copy()\n\n    # Subset the image of interest\n    if subset is not None:\n        data = data[data[imageid] == subset]\n\n    # subset coordinates if needed\n    if x_lim is not None:\n        x1 = x_lim[0]\n        if len(x_lim) &lt; 2:\n            x2 = max(data[x_coordinate])\n        else:\n            x2 = x_lim[1]\n    if y_lim is not None:\n        y1 = y_lim[0]\n        if len(y_lim) &lt; 2:\n            y2 = min(data[y_coordinate])\n        else:\n            y2 = y_lim[1]\n\n    # do the actuall subsetting\n    # if x_lim is not None:\n    #    data = data[data[x_coordinate] &gt;= x1]\n    #    data = data[data[x_coordinate] &lt;= x2]\n    # if y_lim is not None:\n    #    data = data[data[y_coordinate] &lt;= y1]\n    #    data = data[data[y_coordinate] &gt;= y2]\n\n    # do the actuall subsetting\n    if x_lim is not None:\n        data = data[(data[x_coordinate] &gt;= x1) &amp; (data[x_coordinate] &lt;= x2)]\n    if y_lim is not None:\n        data = data[(data[y_coordinate] &gt;= y1) &amp; (data[y_coordinate] &lt;= y2)]\n\n    # create an extra column with index information\n    data['index_info'] = np.arange(data.shape[0])\n\n    # generate the x and y coordinates\n    points = data[[x_coordinate, y_coordinate]].values\n\n    # invert the Y-axis\n    if flip_y is True:\n        points[:, 1] = max(points[:, 1]) - points[:, 1]\n\n    # Generate colors\n    if color_by is None:\n        colors = np.repeat('#e5e5e5', len(data))\n    #    elif color_by is None and colors is not None:\n    #        if isinstance(colors,str):\n    #            colors = np.repeat(colors, len(data))\n    elif color_by is not None and colors is None:\n        # auto color the samples\n        if len(np.unique(data[color_by])) &lt;= 9:\n            c = sns.color_palette('Set1')[0 : len(np.unique(data[color_by]))]\n        if len(np.unique(data[color_by])) &gt; 9 and len(np.unique(data[color_by])) &lt;= 20:\n            c = sns.color_palette('tab20')[0 : len(np.unique(data[color_by]))]\n        if len(np.unique(data[color_by])) &gt; 20:\n            # For large categories generate random colors\n            np.random.seed(0)\n            c = np.random.rand(len(np.unique(data[color_by])), 3).tolist()\n        # merge colors with phenotypes/ categories of interest\n        p = np.unique(data[color_by])\n        c_p = dict(zip(p, c))\n        # map to colors\n        colors = list(map(c_p.get, list(data[color_by].values)))\n    elif color_by is not None and colors is not None:\n        # check if colors is a dictionary or a sns color scale\n        if isinstance(colors, str):\n            if len(sns.color_palette(colors)) &lt; len(np.unique(data[color_by])):\n                raise ValueError(\n                    str(colors)\n                    + ' includes a maximun of '\n                    + str(len(sns.color_palette(colors)))\n                    + ' colors, while your data need '\n                    + str(len(np.unique(data[color_by])))\n                    + ' colors'\n                )\n            else:\n                c = sns.color_palette(colors)[0 : len(np.unique(data[color_by]))]\n                # merge colors with phenotypes/ categories of interest\n                p = np.unique(data[color_by])\n                c_p = dict(zip(p, c))\n        if isinstance(colors, dict):\n            if len(colors) &lt; len(np.unique(data[color_by])):\n                raise ValueError(\n                    'Color mapping is not provided for all categories. Please check'\n                )\n            else:\n                c_p = colors\n        # map to colors\n        colors = list(map(c_p.get, list(data[color_by].values)))\n\n    # create the voronoi object\n    vor = Voronoi(points)\n\n    # trim the object\n    regions, vertices = voronoi_finite_polygons_2d(vor)\n\n    # plotting\n    pts = MultiPoint([Point(i) for i in points])\n    mask = pts.convex_hull\n    new_vertices = []\n    if type(voronoi_alpha) != list:\n        voronoi_alpha = [voronoi_alpha] * len(points)\n    areas = []\n    for i, (region, alph) in enumerate(zip(regions, voronoi_alpha)):\n        polygon = vertices[region]\n        shape = list(polygon.shape)\n        shape[0] += 1\n        p = Polygon(np.append(polygon, polygon[0]).reshape(*shape)).intersection(mask)\n        areas += [p.area]\n        if p.area &lt; size_max:\n            poly = np.array(\n                list(zip(p.boundary.coords.xy[0][:-1], p.boundary.coords.xy[1][:-1]))\n            )\n            new_vertices.append(poly)\n            if voronoi_edge_color == 'facecolor':\n                plt.fill(\n                    *zip(*poly),\n                    alpha=alph,\n                    edgecolor=colors[i],\n                    linewidth=voronoi_line_width,\n                    facecolor=colors[i],\n                )\n                plt.xticks([])\n                plt.yticks([])\n            else:\n                plt.fill(\n                    *zip(*poly),\n                    alpha=alph,\n                    edgecolor=voronoi_edge_color,\n                    linewidth=voronoi_line_width,\n                    facecolor=colors[i],\n                )\n                plt.xticks([])\n                plt.yticks([])\n                # plt.xlim([1097.5,1414.5])\n                # plt.ylim([167.3,464.1])\n\n    # Add scatter on top of the voronoi if user requests\n    if overlay_points is not None:\n        if overlay_points_categories is None:\n            d = data\n        if overlay_points_categories is not None:\n            # convert to list if needed (cells to keep)\n            if isinstance(overlay_points_categories, str):\n                overlay_points_categories = [overlay_points_categories]\n            # subset cells needed\n            d = data[data[overlay_points].isin(overlay_points_categories)]\n        if overlay_drop_categories is not None:\n            # conver to list if needed (cells to drop)\n            if isinstance(overlay_drop_categories, str):\n                overlay_drop_categories = [overlay_drop_categories]\n            # subset cells needed\n            d = d[-d[overlay_points].isin(overlay_drop_categories)]\n\n        # Find the x and y coordinates for the overlay category\n        # points_scatter = d[[x_coordinate,y_coordinate]].values\n        points_scatter = points[d.index_info.values]\n\n        # invert the Y-axis\n        # points_scatter[:,1] = max(points_scatter[:,1])-points_scatter[:,1]\n\n        # Generate colors for the scatter plot\n        if overlay_points_colors is None and color_by == overlay_points:\n            # Borrow color from vornoi\n            wanted_keys = np.unique(d[overlay_points])  # The keys to extract\n            c_p_scatter = dict((k, c_p[k]) for k in wanted_keys if k in c_p)\n        elif overlay_points_colors is None and color_by != overlay_points:\n            # Randomly generate colors for all the categories in scatter plot\n            # auto color the samples\n            if len(np.unique(d[overlay_points])) &lt;= 9:\n                c_scatter = sns.color_palette('Set1')[\n                    0 : len(np.unique(d[overlay_points]))\n                ]\n            if (\n                len(np.unique(d[overlay_points])) &gt; 9\n                and len(np.unique(d[overlay_points])) &lt;= 20\n            ):\n                c_scatter = sns.color_palette('tab20')[\n                    0 : len(np.unique(d[overlay_points]))\n                ]\n            if len(np.unique(d[overlay_points])) &gt; 20:\n                # For large categories generate random colors\n                np.random.seed(1)\n                c_scatter = np.random.rand(\n                    len(np.unique(d[overlay_points])), 3\n                ).tolist()\n            # merge colors with phenotypes/ categories of interest\n            p_scatter = np.unique(d[overlay_points])\n            c_p_scatter = dict(zip(p_scatter, c_scatter))\n        elif overlay_points_colors is not None:\n            # check if the overlay_points_colors is a pallete\n            if isinstance(overlay_points_colors, str):\n                try:\n                    c_scatter = sns.color_palette(overlay_points_colors)[\n                        0 : len(np.unique(d[overlay_points]))\n                    ]\n                    if len(sns.color_palette(overlay_points_colors)) &lt; len(\n                        np.unique(d[overlay_points])\n                    ):\n                        raise ValueError(\n                            str(overlay_points_colors)\n                            + ' pallete includes a maximun of '\n                            + str(len(sns.color_palette(overlay_points_colors)))\n                            + ' colors, while your data (overlay_points_colors) need '\n                            + str(len(np.unique(d[overlay_points])))\n                            + ' colors'\n                        )\n                except:\n                    c_scatter = np.repeat(\n                        overlay_points_colors, len(np.unique(d[overlay_points]))\n                    )  # [overlay_points_colors]\n                # create a dict\n                p_scatter = np.unique(d[overlay_points])\n                c_p_scatter = dict(zip(p_scatter, c_scatter))\n            if isinstance(overlay_points_colors, dict):\n                if len(overlay_points_colors) &lt; len(np.unique(d[overlay_points])):\n                    raise ValueError(\n                        'Color mapping is not provided for all categories. Please check overlay_points_colors'\n                    )\n                else:\n                    c_p_scatter = overlay_points_colors\n        # map to colors\n        colors_scatter = list(map(c_p_scatter.get, list(d[overlay_points].values)))\n\n        # plt.scatter(x = points_scatter[:,0], y = points_scatter[:,1], s= overlay_point_size, alpha= overlay_point_alpha, c= colors_scatter, marker=overlay_point_shape)\n        plt.scatter(\n            x=points_scatter[:, 0],\n            y=points_scatter[:, 1],\n            s=overlay_point_size,\n            alpha=overlay_point_alpha,\n            c=colors_scatter,\n            marker=overlay_point_shape,\n            **kwargs,\n        )\n        plt.xticks([])\n        plt.yticks([])\n\n    if plot_legend is True:\n        # Add legend to voronoi\n        patchList = []\n        for key in c_p:\n            data_key = mpatches.Patch(color=c_p[key], label=key)\n            patchList.append(data_key)\n\n        first_legend = plt.legend(\n            handles=patchList,\n            bbox_to_anchor=(1.05, 1),\n            loc=2,\n            borderaxespad=0.0,\n            prop={'size': legend_size},\n        )\n\n        try:\n            plt.tight_layout()\n        except:\n            pass\n\n        # Add the legend manually to the current Axes.\n        ax = plt.gca().add_artist(first_legend)\n\n        if overlay_points is not None:\n            # Add legend to scatter\n            patchList_scatter = []\n            for key in c_p_scatter:\n                data_key_scatter = mpatches.Patch(color=c_p_scatter[key], label=key)\n                patchList_scatter.append(data_key_scatter)\n\n            plt.legend(\n                handles=patchList_scatter,\n                bbox_to_anchor=(-0.05, 1),\n                loc=1,\n                borderaxespad=0.0,\n                prop={'size': legend_size},\n            )\n            # plt.tight_layout()\n\n    # Saving the figure if saveDir and fileName are provided\n    if saveDir:\n        if not os.path.exists(saveDir):\n            os.makedirs(saveDir)\n        full_path = os.path.join(saveDir, fileName)\n        plt.savefig(full_path, dpi=300)\n        plt.close()\n        print(f\"Saved plot to {full_path}\")\n    else:\n        plt.show()\n</code></pre>"},{"location":"Functions/pp/combat/","title":"combat","text":"<p>Short Description</p> <p>ComBat is a well-established method for correcting batch effects in high-dimensional data, such as single-cell RNA-seq. This implementation uses the <code>combat</code> function to correct batch effects across multiple slides.  </p>"},{"location":"Functions/pp/combat/#scimap.preprocessing.combat--function","title":"Function","text":""},{"location":"Functions/pp/combat/#scimap.preprocessing.combat.combat","title":"<code>combat(adata, batch='imageid', layer=None, log=False, replaceOriginal=False, label='combat')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData object</code> <p>Annotated data matrix.</p> required <code>batch</code> <code>str</code> <p>The batch key or column in <code>adata.obs</code> that indicates the batches for each cell.</p> <code>'imageid'</code> <code>layer</code> <code>str or None</code> <p>The layer in <code>adata.layers</code> that contains the expression data to correct. If None,  <code>adata.X</code> is used. use <code>raw</code> to use the data stored in <code>adata.raw.X</code></p> <code>None</code> <code>log</code> <code>bool</code> <p>Whether to log transform the data before applying ComBat. Generally use it with <code>raw</code>.</p> <code>False</code> <code>replaceOriginal</code> <code>bool</code> <p>Whether to replace the original expression data in <code>adata</code> with the corrected data.</p> <code>False</code> <code>label</code> <code>str</code> <p>The prefix for the key in <code>adata</code> that will contain the corrected data. If <code>replaceOriginal</code> is <code>True</code>, this parameter has no effect.  </p> <code>'combat'</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>anndata</code> <p>The corrected expression data is stored in a new layer <code>adata.layers['combat']</code>.</p> Example <pre><code># applying batch correction using raw data\nadata = sm.pp.combat (adata,\n                batch='imageid',\n                layer='raw',\n                log=True,\n                replaceOriginal=False,\n                label='combat')\n\n# results will be available in adata.layers['combat']\n</code></pre> Source code in <code>scimap/preprocessing/combat.py</code> <pre><code>def combat(\n    adata,\n    batch='imageid',\n    layer=None,\n    log=False,\n    replaceOriginal=False,\n    label='combat'):\n\n    \"\"\"\nParameters:\n    adata (AnnData object):  \n        Annotated data matrix.\n\n    batch (str, optional):  \n        The batch key or column in `adata.obs` that indicates the batches for each cell.\n\n    layer (str or None, optional):\n        The layer in `adata.layers` that contains the expression data to correct. If None, \n        `adata.X` is used. use `raw` to use the data stored in `adata.raw.X`\n\n    log (bool, optional):  \n        Whether to log transform the data before applying ComBat. Generally use it with `raw`.\n\n    replaceOriginal (bool, optional):\n        Whether to replace the original expression data in `adata` with the corrected data.\n\n    label (str, optional):  \n        The prefix for the key in `adata` that will contain the corrected data. If `replaceOriginal` is `True`, this parameter has no effect.  \n\nReturns:\n    adata (anndata):  \n        The corrected expression data is stored in a new layer `adata.layers['combat']`.\n\nExample:\n    ```python\n\n    # applying batch correction using raw data\n    adata = sm.pp.combat (adata,\n                    batch='imageid',\n                    layer='raw',\n                    log=True,\n                    replaceOriginal=False,\n                    label='combat')\n\n    # results will be available in adata.layers['combat']\n\n    ```\n    \"\"\"\n\n    # isolate the data\n    if layer is None:\n        data = pd.DataFrame(adata.X, index=adata.obs.index, columns=adata.var.index)\n    elif layer == 'raw':\n        data = pd.DataFrame(adata.raw.X, index=adata.obs.index, columns=adata.var.index)\n    else:\n        data = pd.DataFrame(adata.layers[layer], index=adata.obs.index, columns=adata.var.index)\n\n    # log the data if requested\n    if log is True:\n        data = np.log1p(data)\n\n    # isolate batch\n    batchData = adata.obs[batch]\n\n    # convert to category\n    batchData = batchData.astype('category')\n\n    # make sure there are atleast two batches\n    if len(batchData.unique()) &lt; 2:\n        raise Exception(\n            \"Sorry a minimum of 2 batches is required. Please check the '\"\n            + str(batch)\n            + \"' column\"\n        )\n\n    # perform batch correction\n    batchCorrected = pycombat(data.T, batchData).T\n\n    # add as a specific layer\n    adata.layers[label] = batchCorrected\n\n    # replace original\n    if replaceOriginal is True:\n        if layer is None:\n            adata.X = batchCorrected\n        elif layer == 'raw':\n            del adata.raw\n            adata.raw = ad.AnnData(batchCorrected, obs=adata.obs)\n        else:\n            adata.layers[layer] = batchCorrected\n\n    # return adata\n    return adata\n</code></pre>"},{"location":"Functions/pp/log1p/","title":"log1p","text":"<p>Short Description</p> <p><code>sm.pp.log1p</code> applies a log1p transformation to the raw data of an AnnData object and saves the transformed data in a specified layer.  If a string path to an AnnData file is provided, the file is loaded, transformed, and  overwritten with the  transformed data. The function ensures the raw data exists before applying the transformation and allows for verbose output.</p>"},{"location":"Functions/pp/log1p/#scimap.preprocessing.log1p--function","title":"Function","text":""},{"location":"Functions/pp/log1p/#scimap.preprocessing.log1p.log1p","title":"<code>log1p(adata, layer='log', verbose=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>str or AnnData</code> <p>The AnnData object or a string path to an AnnData file. If a path is provided, the function will load the AnnData object from the file. The transformation is applied to the raw data of this object.</p> required <code>layer</code> <code>str</code> <p>Name of the new layer where the log-transformed data will be stored. Default is 'log'. If the layer already exists, it will be overwritten with the new log-transformed data.</p> <code>'log'</code> <code>verbose</code> <code>bool</code> <p>If True, the function will print messages about its progress and actions, including warnings if the specified layer already exists and confirmation when the AnnData object is saved to a file. Default is True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>anndata</code> <p>The modified AnnData object, only if the input is an AnnData object and not a file path. If a file path is provided and successfully processed, the function returns None.</p> Example <pre><code># Using a path to an AnnData file:\n# will overwrite the original file with the transformed AnnData object.\n\nsm.pp.log1p(\"path/to/your/adata.h5ad\", layer=\"log\", verbose=True)\n\n# Using an AnnData object directly:\n# Assuming `adata` is your pre-loaded into memory\n# This will apply log1p transformation and the modified AnnData object\n\nadata = sm.pp.log1p(adata, layer=\"log\", verbose=True)\n</code></pre> Source code in <code>scimap/preprocessing/log1p.py</code> <pre><code>def log1p (adata,\n           layer='log',  \n           verbose=True):\n\n    \"\"\"\nParameters:\n    adata (str or anndata.AnnData): \n        The AnnData object or a string path to an AnnData file. If a path is provided, the function will load the AnnData object from the file. The transformation is applied to the raw data of this object.\n\n    layer (str): \n        Name of the new layer where the log-transformed data will be stored. Default is 'log'. If the layer already exists, it will be overwritten with the new log-transformed data.\n\n    verbose (bool): \n        If True, the function will print messages about its progress and actions, including warnings if the specified layer already exists and confirmation when the AnnData object is saved to a file. Default is True.\n\n\nReturns:\n    adata (anndata): \n        The modified AnnData object, only if the input is an AnnData object and not a file path. If a file path is provided and successfully processed, the function returns None.\n\nExample:\n    ```python\n\n    # Using a path to an AnnData file:\n    # will overwrite the original file with the transformed AnnData object.\n\n    sm.pp.log1p(\"path/to/your/adata.h5ad\", layer=\"log\", verbose=True)\n\n    # Using an AnnData object directly:\n    # Assuming `adata` is your pre-loaded into memory\n    # This will apply log1p transformation and the modified AnnData object\n\n    adata = sm.pp.log1p(adata, layer=\"log\", verbose=True)\n\n    ```\n\"\"\"\n\n    # load adata\n    if isinstance(adata, str):\n        adata_path = Path(adata)\n        if not adata_path.exists():\n            raise FileNotFoundError(f\"The file {adata} does not exist.\")\n        adata = ad.read_h5ad(adata_path)\n    else:\n        adata_path = None\n\n\n    if layer in adata.layers:\n        if verbose:\n            print(f\"Warning: Layer '{layer}' already exists. It will be overwritten with the new log-transformed data.\")\n\n    if adata.raw is None:\n        raise AttributeError(\"adata.raw does not exist. Please assign RAW data to adata.raw before proceeding (e.g., adata.raw = adata).\")\n\n    # perform the operation\n    adata.layers[layer] = np.log1p(adata.raw.X)\n\n    # return \n    # Overwrite the original file with the modified AnnData object if requested\n    if isinstance(adata_path, Path):\n        adata.write_h5ad(adata_path)\n        if verbose: \n            print(f\"Modified AnnData object has been saved to {adata_path}\")\n    else:\n        return adata\n</code></pre>"},{"location":"Functions/pp/mcmicro_to_scimap/","title":"mcmicro_to_scimap","text":"<p>Short Description</p> <p><code>sm.pp.mcmicro_to_scimap</code>: The function allows users to directly import the output from mcmicro  into <code>scimap</code>.</p>"},{"location":"Functions/pp/mcmicro_to_scimap/#scimap.preprocessing.mcmicro_to_scimap--function","title":"Function","text":""},{"location":"Functions/pp/mcmicro_to_scimap/#scimap.preprocessing.mcmicro_to_scimap.mcmicro_to_scimap","title":"<code>mcmicro_to_scimap(feature_table_path, remove_dna=True, remove_string_from_name=None, log=True, drop_markers=None, random_sample=None, unique_CellId=True, CellId='CellID', split='X_centroid', custom_imageid=None, min_cells=None, verbose=True, output_dir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>feature_table_path</code> <code>list of str</code> <p>A list containing file paths to single-cell spatial feature tables. Each path corresponds to a unique image's feature table.</p> required <code>remove_dna</code> <code>bool</code> <p>If set to <code>True</code>, channels identified by containing the substring 'dna' are excluded from the final dataset. This parameter is useful for omitting DNA-related features.</p> <code>True</code> <code>remove_string_from_name</code> <code>str</code> <p>Specifies a substring to be removed from all channel names, aiding in the normalization of marker names across datasets.</p> <code>None</code> <code>log</code> <code>bool</code> <p>If <code>True</code>, applies a log transformation (specifically log1p, which adds 1 before taking the logarithm) to the data. This is often used to normalize data distributions.</p> <code>True</code> <code>drop_markers</code> <code>list of str</code> <p>A list of marker names to exclude from the analysis. For example, to remove specific markers, you would list them here: [\"CD3D\", \"CD20\"].</p> <code>None</code> <code>random_sample</code> <code>int</code> <p>Specifies the number of cells to include in a subsampled dataset. This parameter is used for downsampling to a specified cell count.</p> <code>None</code> <code>CellId</code> <code>str</code> <p>The name of the column in the input data that contains cell identifiers. This is used to track individual cells across analyses.</p> <code>'CellID'</code> <code>unique_CellId</code> <code>bool</code> <p>Determines whether to automatically generate a unique identifier for each cell by combining the <code>CellId</code> with an <code>imageid</code>. Set to <code>False</code> to use the original <code>CellId</code> values directly. This is crucial for maintaining unique cell identifiers, especially when integrating multiple datasets.</p> <code>True</code> <code>split</code> <code>str</code> <p>The name of the column that demarcates the boundary between quantitative marker data and additional metadata in the input CSV. Specifying this column allows for the separation of data into counts and metadata components.</p> <code>'X_centroid'</code> <code>custom_imageid</code> <code>str</code> <p>Allows for the specification of a custom Image ID for each dataset. By default, the Image ID is derived from the name of the input CSV file.</p> <code>None</code> <code>min_cells</code> <code>int</code> <p>Sets a threshold for the minimum number of cells required for an image to be included in the analysis. Images with fewer cells than this number are excluded. This is useful for filtering out datasets with sparse cellular data.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If set to <code>True</code>, the function will print detailed messages about its progress and the steps being executed.</p> <code>True</code> <code>output_dir</code> <code>str</code> <p>The file path to the directory where output files will be saved. This parameter specifies the destination for any generated files.</p> <code>None</code> <p>Returns:</p> Type Description <p>AnnData Object (anndata): An annotated data object containing the processed single-cell spatial features, ready for downstream analysis.</p> Example <pre><code>feature_table_path = ['/Users/aj/scimapExampleData/quantification/exemplar-001--unmicst_cell.csv',\n                      '/Users/aj/scimapExampleData/quantification/exemplar-002--unmicst_cell.csv']\n\nadata = sm.pp.mcmicro_to_scimap(feature_table_path, drop_markers=['ELANE'], random_sample=5000)\n</code></pre> Source code in <code>scimap/preprocessing/mcmicro_to_scimap.py</code> <pre><code>def mcmicro_to_scimap(\n    feature_table_path,\n    remove_dna=True,\n    remove_string_from_name=None,\n    log=True,\n    drop_markers=None,\n    random_sample=None,\n    unique_CellId=True,\n    CellId='CellID',\n    split='X_centroid',\n    custom_imageid=None,\n    min_cells=None,\n    verbose=True,\n    output_dir=None,\n):\n    \"\"\"\n    Parameters:\n        feature_table_path (list of str):\n            A list containing file paths to single-cell spatial feature tables. Each path corresponds to a unique image's feature table.\n\n        remove_dna (bool):\n            If set to `True`, channels identified by containing the substring 'dna' are excluded from the final dataset. This parameter is useful for omitting DNA-related features.\n\n        remove_string_from_name (str):\n            Specifies a substring to be removed from all channel names, aiding in the normalization of marker names across datasets.\n\n        log (bool):\n            If `True`, applies a log transformation (specifically log1p, which adds 1 before taking the logarithm) to the data. This is often used to normalize data distributions.\n\n        drop_markers (list of str):\n            A list of marker names to exclude from the analysis. For example, to remove specific markers, you would list them here: [\"CD3D\", \"CD20\"].\n\n        random_sample (int):\n            Specifies the number of cells to include in a subsampled dataset. This parameter is used for downsampling to a specified cell count.\n\n        CellId (str):\n            The name of the column in the input data that contains cell identifiers. This is used to track individual cells across analyses.\n\n        unique_CellId (bool):\n            Determines whether to automatically generate a unique identifier for each cell by combining the `CellId` with an `imageid`. Set to `False` to use the original `CellId` values directly. This is crucial for maintaining unique cell identifiers, especially when integrating multiple datasets.\n\n        split (str):\n            The name of the column that demarcates the boundary between quantitative marker data and additional metadata in the input CSV. Specifying this column allows for the separation of data into counts and metadata components.\n\n        custom_imageid (str):\n            Allows for the specification of a custom Image ID for each dataset. By default, the Image ID is derived from the name of the input CSV file.\n\n        min_cells (int):\n            Sets a threshold for the minimum number of cells required for an image to be included in the analysis. Images with fewer cells than this number are excluded. This is useful for filtering out datasets with sparse cellular data.\n\n        verbose (bool):\n            If set to `True`, the function will print detailed messages about its progress and the steps being executed.\n\n        output_dir (str):\n            The file path to the directory where output files will be saved. This parameter specifies the destination for any generated files.\n\n\n    Returns:\n        AnnData Object (anndata):\n            An annotated data object containing the processed single-cell spatial features, ready for downstream analysis.\n\n\n    Example:\n            ```\n\n            feature_table_path = ['/Users/aj/scimapExampleData/quantification/exemplar-001--unmicst_cell.csv',\n                                  '/Users/aj/scimapExampleData/quantification/exemplar-002--unmicst_cell.csv']\n\n            adata = sm.pp.mcmicro_to_scimap(feature_table_path, drop_markers=['ELANE'], random_sample=5000)\n\n            ```\n\n    \"\"\"\n\n    # feature_table_path list or string\n    if isinstance(feature_table_path, str):\n        feature_table_path = [feature_table_path]\n    feature_table_path = [pathlib.Path(p) for p in feature_table_path]\n\n    # Import data based on the location provided\n    def load_process_data(image):\n        # Print the data that is being processed\n        if verbose:\n            print(f\"Loading {image.name}\")\n        d = pd.read_csv(image)\n        # If the data does not have a unique image ID column, add one.\n        if 'imageid' not in d.columns:\n            if custom_imageid is not None:\n                imid = custom_imageid\n            else:\n                # imid = random.randint(1000000,9999999)\n                imid = image.stem\n            d['imageid'] = imid\n        # Unique name for the data\n        if unique_CellId is True:\n            d.index = d['imageid'].astype(str) + '_' + d[CellId].astype(str)\n        else:\n            d.index = d[CellId]\n\n        # move image id and cellID column to end\n        cellid_col = [col for col in d.columns if col != CellId] + [CellId]\n        d = d[cellid_col]\n        imageid_col = [col for col in d.columns if col != 'imageid'] + ['imageid']\n        d = d[imageid_col]\n        # If there is INF replace with zero\n        d = d.replace([np.inf, -np.inf], 0)\n        # Return data\n        return d\n\n    # Apply function to all images and create a master dataframe\n    r_load_process_data = lambda x: load_process_data(image=x)  # Create lamda function\n    all_data = list(\n        map(r_load_process_data, list(feature_table_path))\n    )  # Apply function\n\n    # Merge all the data into a single large dataframe\n    for i in range(len(all_data)):\n        all_data[i].columns = all_data[0].columns\n    entire_data = pd.concat(all_data, axis=0, sort=False)\n\n    # Randomly sample the data\n    if random_sample is not None:\n        entire_data = entire_data.sample(n=random_sample, replace=False)\n\n    # Remove the images that contain less than a defined threshold of cells (min_cells)\n    if min_cells is not None:\n        to_drop = (\n            entire_data['imageid']\n            .value_counts()[entire_data['imageid'].value_counts() &lt; min_cells]\n            .index\n        )\n        entire_data = entire_data[~entire_data['imageid'].isin(to_drop)]\n        print(\n            'Removed Images that contained less than '\n            + str(min_cells)\n            + ' cells: '\n            + str(to_drop.values)\n        )\n\n    # Split the data into expression data and meta data\n    # Step-1 (Find the index of the column with name Area)\n    split_idx = entire_data.columns.get_loc(split)\n    meta = entire_data.iloc[:, split_idx:]\n    # Step-2 (select only the expression values)\n    entire_data = entire_data.iloc[:, :split_idx]\n\n    # Rename the columns of the data\n    if remove_string_from_name is not None:\n        entire_data.columns = entire_data.columns.str.replace(\n            remove_string_from_name, ''\n        )\n\n    # Save a copy of the column names in the uns space of ANNDATA\n    markers = list(entire_data.columns)\n\n    # Remove DNA channels\n    if remove_dna is True:\n        entire_data = entire_data.loc[\n            :, ~entire_data.columns.str.contains('dna', case=False)\n        ]\n\n    # Drop unnecessary markers\n    if drop_markers is not None:\n        if isinstance(drop_markers, str):\n            drop_markers = [drop_markers]\n        entire_data = entire_data.drop(columns=drop_markers)\n\n    # Create an anndata object\n    adata = ad.AnnData(entire_data)\n    adata.obs = meta\n    adata.uns['all_markers'] = markers\n\n    # Add log data\n    if log is True:\n        adata.raw = adata\n        adata.X = np.log1p(adata.X)\n        adata.layers['log'] = adata.X\n    else: \n        adata.layers['log'] = np.log1p(adata.X)\n\n\n\n    # Save data if requested\n    if output_dir is not None:\n        output_dir = pathlib.Path(output_dir)\n        output_dir.mkdir(exist_ok=True, parents=True)\n        imid = feature_table_path[0].stem\n        adata.write(output_dir / f'{imid}.h5ad')\n        # adata.write(str(output_dir) + '/' + imid + '.h5ad')\n    else:\n        # Return data\n        return adata\n</code></pre>"},{"location":"Functions/pp/rescale/","title":"rescale","text":"<p>Short Description</p> <p><code>sm.pp.rescale</code>: The function allows users to rescale the data. This step is often performed to standardize the  the expression of all markers to a common scale. The rescaling can be either performed automatically or manually.  User defined gates can be passed to rescale the data manually, else the algorithm fits a GMM (gaussian mixed model) to  identify the cutoff point. The resultant data is between 0-1 where values below 0.5 are considered non-expressing while  above 0.5 is considered positive. </p>"},{"location":"Functions/pp/rescale/#scimap.preprocessing.rescale--function","title":"Function","text":""},{"location":"Functions/pp/rescale/#scimap.preprocessing.rescale.rescale","title":"<code>rescale(adata, gate=None, log=True, imageid='imageid', failed_markers=None, method='all', verbose=True, random_state=0, gmm_components=3)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData Object, required</code> <p>An annotated data object that contains single-cell expression data.</p> required <code>gate</code> <code>DataFrame</code> <p>A pandas DataFrame where the first column lists markers, and subsequent columns contain gate values for each image in the dataset. Column names must correspond to unique <code>imageid</code> identifiers, and the marker column must be named \"markers\". If a single column of gate values is provided for a dataset with multiple images, the same gate will be uniformly applied to all images. In this case, ensure that the columns are named exactly \"markers\" and \"gates\". If no gates are provided for specific markers, the function attempts to automatically determine gates using a Gaussian Mixture Model (GMM).</p> <p>Note: If you have used <code>napariGater()</code>, the gates are stored within <code>adata.uns['gates']</code>. You can directly pass <code>adata.uns['gates']</code> to use these pre-defined gates.</p> <code>None</code> <code>log</code> <code>bool</code> <p>If <code>True</code>, the data in <code>adata.raw.X</code> will be log-transformed (using log1p) before gate application. This transformation is recommended when automatic gate identification through GMM is performed, as it helps in normalizing data distributions.</p> <code>True</code> <code>imageid</code> <code>str</code> <p>The name of the column in <code>adata</code> that contains Image IDs. This is necessary for matching manual gates specified in the <code>gate</code> DataFrame to their respective images.</p> <code>'imageid'</code> <code>failed_markers</code> <code>dict</code> <p>A dictionary mapping <code>imageid</code> to markers that failed quality control. This allows for the exclusion of specific markers from the analysis based on prior visual inspection or other criteria. The dictionary can use <code>all</code> as a key to specify markers that failed across all images.</p> <code>None</code> <code>method</code> <code>str</code> <p>Specifies the gating strategy: <code>all</code> to pool data from all images for GMM application, or <code>by_image</code> to apply GMM separately for each image. <code>all</code> may introduce batch effects, while <code>by_image</code> requires sufficient variation within each image to distinguish negative from positive populations effectively.</p> <code>'all'</code> <code>random_state</code> <code>int</code> <p>The seed used by the random number generator for GMM. Ensures reproducibility of results.</p> <code>0</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code>, detailed progress updates and diagnostic messages will be printed during the function's execution.</p> <code>True</code> <code>gmm_components</code> <code>int</code> <p>Number of components to use in the Gaussian Mixture Model for automatic gating. Must be at least 2. Gate will be placed between the highest two components. Default is 3.</p> <code>3</code> <p>Returns:</p> Type Description <p>Modified AnnData Object (AnnData): Returns the input <code>adata</code> object with updated expression data (<code>adata.X</code>) after rescaling. The gates applied, either provided manually or determined automatically, are stored within <code>adata.uns['gates']</code>.</p> Example <pre><code># Example with manual gates\nmanual_gate = pd.DataFrame({'marker': ['CD3D', 'KI67'], 'gate': [7, 8]})\nadata = sm.pp.rescale(adata, gate=manual_gate, failed_markers={'all': ['CD20', 'CD21']})\n\n# Importing gates from a CSV\nmanual_gate = pd.read_csv('manual_gates.csv')\nadata = sm.pp.rescale(adata, gate=manual_gate, failed_markers={'all': ['CD20', 'CD21']})\n\n# Running without manual gates to use GMM for automatic gate determination\nadata = sm.pp.rescale(adata, gate=None, failed_markers={'all': ['CD20', 'CD21']})\n</code></pre> Source code in <code>scimap/preprocessing/rescale.py</code> <pre><code>def rescale(\n    adata,\n    gate=None,\n    log=True,\n    imageid='imageid',\n    failed_markers=None,\n    method='all',\n    verbose=True,\n    random_state=0,\n    gmm_components=3,\n):\n    \"\"\"\n    Parameters:\n        adata (AnnData Object, required):\n            An annotated data object that contains single-cell expression data.\n\n        gate (DataFrame, optional):\n            A pandas DataFrame where the first column lists markers, and subsequent columns contain gate values\n            for each image in the dataset. Column names must correspond to unique `imageid` identifiers, and the marker column must be named \"markers\".\n            If a single column of gate values is provided for a dataset with multiple images, the same gate will be uniformly applied to all images.\n            In this case, ensure that the columns are named exactly \"markers\" and \"gates\".\n            If no gates are provided for specific markers, the function attempts to automatically determine gates using a Gaussian Mixture Model (GMM).\n\n            Note: If you have used `napariGater()`, the gates are stored within `adata.uns['gates']`.\n            You can directly pass `adata.uns['gates']` to use these pre-defined gates.\n\n        log (bool, optional):\n            If `True`, the data in `adata.raw.X` will be log-transformed (using log1p) before gate application. This transformation is recommended when automatic gate identification through GMM is performed, as it helps in normalizing data distributions.\n\n        imageid (str, optional):\n            The name of the column in `adata` that contains Image IDs. This is necessary for matching manual gates specified in the `gate` DataFrame to their respective images.\n\n        failed_markers (dict, optional):\n            A dictionary mapping `imageid` to markers that failed quality control. This allows for the exclusion of specific markers from the analysis based on prior visual inspection or other criteria. The dictionary can use `all` as a key to specify markers that failed across all images.\n\n        method (str, optional):\n            Specifies the gating strategy: `all` to pool data from all images for GMM application, or `by_image` to apply GMM separately for each image. `all` may introduce batch effects, while `by_image` requires sufficient variation within each image to distinguish negative from positive populations effectively.\n\n        random_state (int, optional):\n            The seed used by the random number generator for GMM. Ensures reproducibility of results.\n\n        verbose (bool, optional):\n            If `True`, detailed progress updates and diagnostic messages will be printed during the function's execution.\n\n        gmm_components (int, optional):\n            Number of components to use in the Gaussian Mixture Model for automatic gating.\n            Must be at least 2. Gate will be placed between the highest two components.\n            Default is 3.\n\n    Returns:\n        Modified AnnData Object (AnnData):\n            Returns the input `adata` object with updated expression data (`adata.X`) after rescaling. The gates applied, either provided manually or determined automatically, are stored within `adata.uns['gates']`.\n\n    Example:\n        ```python\n\n        # Example with manual gates\n        manual_gate = pd.DataFrame({'marker': ['CD3D', 'KI67'], 'gate': [7, 8]})\n        adata = sm.pp.rescale(adata, gate=manual_gate, failed_markers={'all': ['CD20', 'CD21']})\n\n        # Importing gates from a CSV\n        manual_gate = pd.read_csv('manual_gates.csv')\n        adata = sm.pp.rescale(adata, gate=manual_gate, failed_markers={'all': ['CD20', 'CD21']})\n\n        # Running without manual gates to use GMM for automatic gate determination\n        adata = sm.pp.rescale(adata, gate=None, failed_markers={'all': ['CD20', 'CD21']})\n\n        ```\n\n    \"\"\"\n\n    # log=True; imageid='imageid'; failed_markers=None; method='all'; random_state=0\n\n    # make a copy to raw data if raw is none\n    if adata.raw is None:\n        adata.raw = adata\n\n    # Mapping between markers and gates in the given dataset\n    dataset_markers = adata.var.index.tolist()\n    dataset_images = adata.obs[imageid].unique().tolist()\n    m = pd.DataFrame(index=dataset_markers, columns=dataset_images).reset_index()\n    m = pd.melt(m, id_vars=[m.columns[0]])\n    m.columns = ['markers', 'imageid', 'gate']\n\n    # Manipulate m with and without provided manual gates\n    if gate is None:\n        gate_mapping = m.copy()\n    else:\n        # Check overlap between gate columns and dataset images\n        matching_images = set(gate.columns) &amp; set(dataset_images)\n\n        # link to make sure index name is markers as we use reset_index later\n        if gate.index.name != 'markers' and 'markers' not in gate.columns:\n            gate.index.name = 'markers'\n\n        if len(matching_images) == 0 and len(gate.columns) &gt; 0:\n            # Case 1: No matching images and single value column - apply globally\n            gate = gate.reset_index()  # Convert index to column\n            gate_mapping = m.copy()\n            gate_mapping.gate = gate_mapping.gate.fillna(\n                gate_mapping.markers.map(\n                    dict(\n                        zip(gate['markers'], gate['gates'])\n                    )  # these columns are hardcoded in CSV\n                )\n            )\n        else:\n            # Case 2: handles both if all imageid matches with gate columns or if they partially match\n            gate = gate.reset_index()\n            manual_m = pd.melt(gate, id_vars=gate[['markers']])\n            manual_m.columns = ['markers', 'imageid', 'm_gate']\n            gate_mapping = pd.merge(\n                m,\n                manual_m,\n                how='left',\n                left_on=['markers', 'imageid'],\n                right_on=['markers', 'imageid'],\n            )\n            gate_mapping['gate'] = gate_mapping['gate'].fillna(gate_mapping['m_gate'])\n            gate_mapping = gate_mapping.drop(columns='m_gate')\n\n    # Addressing failed markers\n    def process_failed(adata_subset, foramted_failed_markers):\n        if verbose:\n            print(\n                'Processing Failed Marker in '\n                + str(adata_subset.obs[imageid].unique()[0])\n            )\n        # prepare data\n        data_subset = pd.DataFrame(\n            adata_subset.raw.X,\n            columns=adata_subset.var.index,\n            index=adata_subset.obs.index,\n        )\n        if log is True:\n            data_subset = np.log1p(data_subset)\n\n        # subset markers in the subset\n        fm_sub = foramted_failed_markers[adata_subset.obs[imageid].unique()].dropna()\n\n        def process_failed_internal(fail_mark, data_subset):\n            return data_subset[fail_mark].max()\n\n        r_process_failed_internal = lambda x: process_failed_internal(\n            fail_mark=x, data_subset=data_subset\n        )\n        f_g = list(map(r_process_failed_internal, [x[0] for x in fm_sub.values]))\n        subset_gate = pd.DataFrame(\n            {\n                'markers': [x[0] for x in fm_sub.values],\n                'imageid': adata_subset.obs[imageid].unique()[0],\n                'gate': f_g,\n            }\n        )\n        # return\n        return subset_gate\n\n    # Identify the failed markers\n    if failed_markers is not None:\n        # check if failed marker is a dict\n        if isinstance(failed_markers, dict) is False:\n            raise ValueError(\n                '`failed_markers` should be a python dictionary, please refer documentation'\n            )\n        # create a copy\n        fm = failed_markers.copy()\n        # seperate all from the rest\n        if 'all' in failed_markers:\n            all_failed = failed_markers['all']\n            if isinstance(all_failed, str):\n                all_failed = [all_failed]\n            failed_markers.pop('all', None)\n\n            df = pd.DataFrame(columns=adata.obs[imageid].unique())\n            for i in range(len(all_failed)):\n                df.loc[i] = np.repeat(all_failed[i], len(df.columns))\n            # for i in  range(len(df.columns)):\n            #    df.loc[i] = all_failed[i]\n        # rest of the failed markers\n        # fail = pd.DataFrame.from_dict(failed_markers)\n        fail = pd.DataFrame(\n            dict([(k, pd.Series(v)) for k, v in failed_markers.items()])\n        )\n        # merge\n        if 'all' in fm:\n            foramted_failed_markers = pd.concat([fail, df], axis=0)\n        else:\n            foramted_failed_markers = fail\n\n        # send the adata objects that need to be processed\n        # Check if any image needs to pass through the GMM protocol\n        adata_list = [\n            adata[adata.obs[imageid] == i] for i in foramted_failed_markers.columns\n        ]\n        # apply the process_failed function\n        r_process_failed = lambda x: process_failed(\n            adata_subset=x, foramted_failed_markers=foramted_failed_markers\n        )\n        failed_gates = list(map(r_process_failed, adata_list))\n        # combine the results and merge with gate_mapping\n        result = []\n        for i in range(len(failed_gates)):\n            result.append(failed_gates[i])\n        result = pd.concat(result, join='outer')\n        # use this to merge with gate_mapping\n        x1 = gate_mapping.set_index(['markers', 'imageid'])['gate']\n        x2 = result.set_index(['markers', 'imageid'])['gate']\n        x1.update(x2)\n        gate_mapping = x1.reset_index()\n\n    # trim the data before applying GMM\n    def clipping(x):\n        clip = x.clip(\n            lower=np.percentile(x, 0.01), upper=np.percentile(x, 99.99)\n        ).tolist()\n        return clip\n\n    # Find GMM based gates\n    def gmm_gating(marker, data, gmm_components):\n        \"\"\"Internal function to identify gates using GMM\n\n        Parameters:\n            marker: marker name\n            data: expression data\n            gmm_components: number of components for GMM (minimum 2)\n        \"\"\"\n        # Ensure minimum of 2 components\n        gmm_components = max(2, gmm_components)\n\n        # Prepare data for GMM\n        data_gm = data[marker].values.reshape(-1, 1)\n        data_gm = data_gm[~np.isnan(data_gm), None]\n\n        # Fit GMM with gmm_components\n        gmm = GaussianMixture(\n            n_components=gmm_components, random_state=random_state\n        ).fit(data_gm)\n\n        # Sort components by their means\n        means = gmm.means_.flatten()\n        sorted_idx = np.argsort(means)\n        sorted_means = means[sorted_idx]\n\n        # Calculate gate as midpoint between the second-to-last and last components\n        gate = np.mean([sorted_means[-2], sorted_means[-1]])\n\n        return gate\n\n    # Running gmm_gating on the dataset\n    def gmm_gating_internal(adata_subset, gate_mapping, method):\n        if verbose:\n            print(\n                'Running GMM for image: ' + str(adata_subset.obs[imageid].unique()[0])\n            )\n        data_subset = pd.DataFrame(\n            adata_subset.raw.X,\n            columns=adata_subset.var.index,\n            index=adata_subset.obs.index,\n        )\n        # find markers\n        if method == 'all':\n            image_specific = gate_mapping.copy()\n            marker_to_gate = list(\n                gate_mapping[gate_mapping.gate.isnull()].markers.unique()\n            )\n        else:\n            image_specific = gate_mapping[\n                gate_mapping['imageid'].isin(adata_subset.obs[imageid].unique())\n            ]\n            marker_to_gate = image_specific[image_specific.gate.isnull()].markers.values\n\n        if verbose and len(marker_to_gate) &gt; 0:\n            print('Applying GMM to markers: ' + ', '.join(marker_to_gate))\n\n        # Apply clipping\n        data_subset_clipped = data_subset.apply(clipping)\n        # log transform data\n        if log is True:\n            data_subset_clipped = np.log1p(data_subset_clipped)\n        # identify the gates for the markers\n        r_gmm_gating = lambda x: gmm_gating(\n            marker=x, data=data_subset_clipped, gmm_components=gmm_components\n        )\n        gates = list(map(r_gmm_gating, marker_to_gate))\n        # create a df with results\n        result = image_specific[image_specific.gate.isnull()]\n        mapping = dict(zip(marker_to_gate, gates))\n        for i in result.index:\n            result.loc[i, 'gate'] = mapping[result.loc[i, 'markers']]\n        # result['gate'] = result['gate'].fillna(result['markers'].map(dict(zip(marker_to_gate, gates))))\n        # return\n        return result\n\n    # Create a list of image IDs that need to go through the GMM\n    gmm_images = gate_mapping[gate_mapping.gate.isnull()].imageid.unique()\n\n    # Check if any image needs to pass through the GMM protocol\n    if len(gmm_images) &gt; 0:\n        # Create a list of adata that need to go through the GMM\n        if method == 'all':\n            adata_list = [adata]\n        else:\n            adata_list = [adata[adata.obs[imageid] == i] for i in gmm_images]\n        # run function\n        r_gmm_gating_internal = lambda x: gmm_gating_internal(\n            adata_subset=x, gate_mapping=gate_mapping, method=method\n        )\n        all_gates = list(map(r_gmm_gating_internal, adata_list))\n\n        # combine the results and merge with gate_mapping\n        result = []\n        for i in range(len(all_gates)):\n            result.append(all_gates[i])\n        result = pd.concat(result, join='outer')\n        # use this to merge with gate_mapping\n        gate_mapping.gate = gate_mapping.gate.fillna(\n            gate_mapping.markers.map(dict(zip(result.markers, result.gate)))\n        )\n\n    # Rescaling function\n    def data_scaler(adata_subset, gate_mapping):\n        if verbose:\n            print('\\nScaling Image: ' + str(adata_subset.obs[imageid].unique()[0]))\n        # Organise data\n        data_subset = pd.DataFrame(\n            adata_subset.raw.X,\n            columns=adata_subset.var.index,\n            index=adata_subset.obs.index,\n        )\n        if log is True:\n            data_subset = np.log1p(data_subset)\n        # subset markers in the subset\n        gate_mapping_sub = gate_mapping[\n            gate_mapping['imageid'] == adata_subset.obs[imageid].unique()[0]\n        ]\n\n        # organise gates\n        def data_scaler_internal(marker, gate_mapping_sub):\n            if verbose:\n                gate_value = gate_mapping_sub[gate_mapping_sub.markers == marker][\n                    'gate'\n                ].values[0]\n                print(f'Scaling {marker} (gate: {gate_value:.3f})')\n            # find the gate\n            moi = gate_mapping_sub[gate_mapping_sub.markers == marker]['gate'].values[0]\n\n            # Find the closest value to the gate\n            absolute_val_array = np.abs(data_subset[marker].values - float(moi))\n            # throw error if the array has nan values\n            if np.isnan(absolute_val_array).any():\n                raise ValueError(\n                    \"An exception occurred: \" + str(marker) + ' has nan values'\n                )\n            # smallest diff\n            smallest_difference_index = absolute_val_array.argmin()\n            closest_element = data_subset[marker].values[smallest_difference_index]\n\n            # rescale the data based on the identified gate\n            marker_study = data_subset[marker]\n            marker_study = marker_study.sort_values(axis=0)\n            # Find the index of the gate\n            # account for 0\n            if all(marker_study == 0):\n                gate_index = pd.DataFrame(marker_study).tail(2).index[0]\n            else:\n                gate_index = marker_study.index[marker_study == closest_element][0]\n            # Split into high and low groups\n            high = marker_study[gate_index:]\n            low = marker_study[:gate_index]\n            # Prepare for scaling the high and low dataframes\n            scaler_high = MinMaxScaler(feature_range=(0.5, 1))\n            scaler_low = MinMaxScaler(feature_range=(0, 0.5))\n            # Scale it\n            h = pd.DataFrame(\n                scaler_high.fit_transform(high.values.reshape(-1, 1)), index=high.index\n            )\n            l = pd.DataFrame(\n                scaler_low.fit_transform(low.values.reshape(-1, 1)), index=low.index\n            )\n            # Merge the high and low and resort it\n            scaled_data = pd.concat([l, h])\n            scaled_data = scaled_data.loc[~scaled_data.index.duplicated(keep='first')]\n            scaled_data = scaled_data.reindex(data_subset.index)\n            # scaled_data[scaled_data &gt; 0.5].count(axis=1).sum()\n            # return\n            return scaled_data\n\n        # run internal function\n        r_data_scaler_internal = lambda x: data_scaler_internal(\n            marker=x, gate_mapping_sub=gate_mapping_sub\n        )\n        scaled_subset = list(\n            map(r_data_scaler_internal, gate_mapping_sub.markers.values)\n        )\n\n        # combine the results and merge with gate_mapping\n        scaled_subset_result = []\n        for i in range(len(scaled_subset)):\n            scaled_subset_result.append(scaled_subset[i])\n        scaled_subset_result = pd.concat(scaled_subset_result, join='outer', axis=1)\n        scaled_subset_result.columns = gate_mapping_sub.markers.values\n        # scaled_subset_result[scaled_subset_result['CD3E'] &gt; 0.5]['CD3E'].count(axis=1).sum()\n\n        # return\n        return scaled_subset_result\n\n    # pass each dataset seperately\n    adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n\n    # Run the scaler function\n    r_data_scaler = lambda x: data_scaler(adata_subset=x, gate_mapping=gate_mapping)\n    scaled_subset = list(map(r_data_scaler, adata_list))\n\n    # combine the results and merge with gate_mapping\n    final_result = []\n    for i in range(len(scaled_subset)):\n        final_result.append(scaled_subset[i])\n    final_result = pd.concat(final_result, join='outer')\n\n    # reindex the final_results\n    final_result = final_result.reindex(adata.obs.index)\n\n    # save final gates\n    adata.uns['gates'] = gate_mapping.pivot_table(\n        index=['markers'], columns=['imageid']\n    ).droplevel(\n        0, axis=1\n    )  # .reset_index()\n\n    # add to the anndata\n    adata.X = final_result\n\n    # return adata\n    return adata\n</code></pre>"},{"location":"Functions/tl/cluster/","title":"cluster","text":"<p>Short Description</p> <p><code>sm.tl.cluster</code>: This function is designed for clustering cells within the dataset, facilitating the identification of distinct cell populations based on their expression profiles or other relevant features. It supports three popular clustering algorithms:</p> <ul> <li> <p>kmeans: A partitioning method that divides the dataset into <code>k</code> clusters, each represented by the centroid of the data points in the cluster. It is suitable for identifying spherical clusters in the feature space.</p> </li> <li> <p>phenograph: Based on community detection in graphs, Phenograph clusters cells by constructing a k-nearest neighbor graph and then detecting communities within this graph. This method is particularly effective for identifying clusters with varying densities and sizes.</p> </li> <li> <p>leiden: An algorithm that refines the cluster partitioning by optimizing a modularity score, leading to the detection of highly connected communities. It is known for its ability to uncover fine-grained and highly cohesive clusters.</p> </li> </ul> <p>Each algorithm has its own set of parameters and assumptions, making some more suitable than others for specific types of dataset characteristics. Users are encouraged to select the clustering algorithm that best matches their data's nature and their analytical goals.</p>"},{"location":"Functions/tl/cluster/#scimap.tools.cluster--function","title":"Function","text":""},{"location":"Functions/tl/cluster/#scimap.tools.cluster.cluster","title":"<code>cluster(adata, method='kmeans', layer='log', subset_genes=None, sub_cluster=False, sub_cluster_column='phenotype', sub_cluster_group=None, k=10, n_pcs=None, resolution=1, phenograph_clustering_metric='euclidean', nearest_neighbors=30, use_raw=True, log=True, random_state=0, collapse_labels=False, label=None, verbose=True, output_dir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The input AnnData object containing single-cell data for clustering.</p> required <code>method</code> <code>str</code> <p>Specifies the clustering algorithm to be used. Currently supported algorithms include 'kmeans', 'phenograph', and 'leiden'.</p> <code>'kmeans'</code> <code>subset_genes</code> <code>list of str</code> <p>A list of gene names to be used specifically for clustering. If not provided, all genes in the dataset are used.</p> <code>None</code> <code>sub_cluster</code> <code>bool</code> <p>Enables sub-clustering within an existing cluster or phenotype. Useful for further dissecting identified groups. </p> <code>False</code> <code>sub_cluster_column</code> <code>str</code> <p>The column in <code>adata.obs</code> that contains the cluster or phenotype labels for sub-clustering. Required if <code>sub_cluster</code> is <code>True</code>.</p> <code>'phenotype'</code> <code>sub_cluster_group</code> <code>list of str</code> <p>Specifies the clusters or phenotypes to be sub-clustered. If not provided, all groups in <code>sub_cluster_column</code> will be sub-clustered.</p> <code>None</code> <code>k</code> <code>int</code> <p>The number of clusters to generate when using the K-Means algorithm.</p> <code>10</code> <code>n_pcs</code> <code>int</code> <p>The number of principal components to use for Leiden clustering. Defaults to using all available PCs.</p> <code>None</code> <code>resolution</code> <code>float</code> <p>Adjusts the granularity of clustering, applicable for Leiden clustering. Higher values yield more clusters.</p> <code>1</code> <code>phenograph_clustering_metric</code> <code>str</code> <p>Defines the distance metric for nearest neighbor calculation in Phenograph. Choices include 'cityblock', 'cosine', 'euclidean', 'manhattan', and others. Note: 'correlation' and 'cosine' metrics may slow down the performance.</p> <code>'euclidean'</code> <code>nearest_neighbors</code> <code>int</code> <p>The number of nearest neighbors to consider during the initial graph construction phase in both Leiden and Phenograph clustering.</p> <code>30</code> <code>use_raw</code> <code>bool</code> <p>Determines whether raw data (<code>adata.raw</code>) or processed data (<code>adata.X</code>) should be used for clustering. Default is to use processed data.</p> <code>True</code> <code>log</code> <code>bool</code> <p>If True, applies logarithmic transformation to raw data before clustering. Requires <code>use_raw</code> to be True.</p> <code>True</code> <code>random_state</code> <code>int</code> <p>Seed for random number generation, ensuring reproducibility of clustering results.</p> <code>0</code> <code>collapse_labels</code> <code>bool</code> <p>When sub-clustering a subset of groups, this merges all other groups into a single category, aiding in visualization.</p> <code>False</code> <code>label</code> <code>str</code> <p>The key under which the clustering results are stored in <code>adata.obs</code>. Defaults to the name of the clustering method used.</p> <code>None</code> <code>verbose</code> <code>bool</code> <code>True</code> <code>output_dir</code> <code>str</code> <p>Specifies the directory where output files, if any, should be saved.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>AnnData</code> <code>modified AnnData</code> <p>The input <code>adata</code> object, updated to include a new column in <code>adata.obs</code> corresponding to the clustering results. The column name matches the <code>label</code> parameter or defaults to the clustering method used.</p> Example <pre><code># Example 1: Basic K-Means clustering without sub-clustering\nadata = sm.tl.cluster(adata, method='kmeans', k=10, use_raw=True, log=True, random_state=42)\n\n# Example 2: Phenograph clustering with a specific subset of genes and increased nearest neighbors\nsubset_genes = ['CD3D', 'CD19', 'CD4', 'CD8A']\nadata = sm.tl.cluster(adata, method='phenograph', subset_genes=subset_genes, nearest_neighbors=50, phenograph_clustering_metric='euclidean', use_raw=False)\n\n# Example 3: Leiden clustering using principal components with a higher resolution for finer clusters\nadata = sm.tl.cluster(adata, method='leiden', n_pcs=20, resolution=1, use_raw=False, log=False)\n\n# Example 4: Sub-clustering within a specific phenotype group using Leiden, with results labeled distinctly\nadata = sm.tl.cluster(adata, method='leiden', sub_cluster=True, sub_cluster_column='phenotype', sub_cluster_group=['B cells'], n_pcs=15, resolution=1, label='B_cell_subclusters', verbose=True)\n</code></pre> Source code in <code>scimap/tools/cluster.py</code> <pre><code>def cluster (adata, \n             method='kmeans', \n             layer='log',\n             subset_genes=None,\n             sub_cluster=False, \n             sub_cluster_column='phenotype', \n             sub_cluster_group = None,\n             k= 10, \n             n_pcs=None, \n             resolution=1, \n             phenograph_clustering_metric='euclidean', \n             nearest_neighbors= 30, \n             use_raw=True, \n             log=True, \n             random_state=0, \n             collapse_labels= False,\n             label=None, \n             verbose=True,\n             output_dir=None):\n    \"\"\"\n\nParameters:\n    adata (AnnData):  \n        The input AnnData object containing single-cell data for clustering.\n\n    method (str):  \n        Specifies the clustering algorithm to be used. Currently supported algorithms include 'kmeans', 'phenograph', and 'leiden'.\n\n    subset_genes (list of str, optional):  \n        A list of gene names to be used specifically for clustering. If not provided, all genes in the dataset are used.\n\n    sub_cluster (bool, optional):  \n        Enables sub-clustering within an existing cluster or phenotype. Useful for further dissecting identified groups. \n\n    sub_cluster_column (str, optional):  \n        The column in `adata.obs` that contains the cluster or phenotype labels for sub-clustering. Required if `sub_cluster` is `True`.\n\n    sub_cluster_group (list of str, optional):  \n        Specifies the clusters or phenotypes to be sub-clustered. If not provided, all groups in `sub_cluster_column` will be sub-clustered.\n\n    k (int, optional):  \n        The number of clusters to generate when using the K-Means algorithm.\n\n    n_pcs (int, optional):  \n        The number of principal components to use for Leiden clustering. Defaults to using all available PCs.\n\n    resolution (float, optional):  \n        Adjusts the granularity of clustering, applicable for Leiden clustering. Higher values yield more clusters.\n\n    phenograph_clustering_metric (str, optional):  \n        Defines the distance metric for nearest neighbor calculation in Phenograph. Choices include 'cityblock', 'cosine', 'euclidean', 'manhattan', and others. Note: 'correlation' and 'cosine' metrics may slow down the performance.\n\n    nearest_neighbors (int, optional):  \n        The number of nearest neighbors to consider during the initial graph construction phase in both Leiden and Phenograph clustering.\n\n    use_raw (bool, optional):  \n        Determines whether raw data (`adata.raw`) or processed data (`adata.X`) should be used for clustering. Default is to use processed data.\n\n    log (bool, optional):  \n        If True, applies logarithmic transformation to raw data before clustering. Requires `use_raw` to be True.\n\n    random_state (int, optional):  \n        Seed for random number generation, ensuring reproducibility of clustering results.\n\n    collapse_labels (bool, optional):  \n        When sub-clustering a subset of groups, this merges all other groups into a single category, aiding in visualization.\n\n    label (str, optional):  \n        The key under which the clustering results are stored in `adata.obs`. Defaults to the name of the clustering method used.\n\n    verbose (bool):  \n    If set to `True`, the function will print detailed messages about its progress and the steps being executed.\n\n    output_dir (str, optional):  \n        Specifies the directory where output files, if any, should be saved.\n\nReturns:\n    AnnData (modified AnnData):  \n        The input `adata` object, updated to include a new column in `adata.obs` corresponding to the clustering results. The column name matches the `label` parameter or defaults to the clustering method used.\n\nExample:\n    ```python\n\n    # Example 1: Basic K-Means clustering without sub-clustering\n    adata = sm.tl.cluster(adata, method='kmeans', k=10, use_raw=True, log=True, random_state=42)\n\n    # Example 2: Phenograph clustering with a specific subset of genes and increased nearest neighbors\n    subset_genes = ['CD3D', 'CD19', 'CD4', 'CD8A']\n    adata = sm.tl.cluster(adata, method='phenograph', subset_genes=subset_genes, nearest_neighbors=50, phenograph_clustering_metric='euclidean', use_raw=False)\n\n    # Example 3: Leiden clustering using principal components with a higher resolution for finer clusters\n    adata = sm.tl.cluster(adata, method='leiden', n_pcs=20, resolution=1, use_raw=False, log=False)\n\n    # Example 4: Sub-clustering within a specific phenotype group using Leiden, with results labeled distinctly\n    adata = sm.tl.cluster(adata, method='leiden', sub_cluster=True, sub_cluster_column='phenotype', sub_cluster_group=['B cells'], n_pcs=15, resolution=1, label='B_cell_subclusters', verbose=True)\n\n\n    ```\n    \"\"\"\n\n    # Load the andata object    \n    if isinstance(adata, str):\n        imid = str(adata.rsplit('/', 1)[-1])\n        adata = anndata.read_h5ad(adata)\n    else:\n        adata = adata\n\n    # dynamically adapt the number of neighbours\n    if nearest_neighbors &gt; adata.shape[0]:\n        nearest_neighbors = adata.shape[0] - 3\n\n\n    # Leiden clustering\n    def leiden_clustering (pheno, adata, nearest_neighbors, n_pcs, resolution):\n\n        # subset the data to be clustered\n        if pheno is not None:\n            cell_subset =  adata.obs[adata.obs[sub_cluster_column] == pheno].index\n        else:\n            cell_subset = adata.obs.index\n\n        if use_raw == True:\n            data_subset = adata[cell_subset]\n            if log is True:\n                data_subset.X = np.log1p(data_subset.raw.X)          \n            else:\n                data_subset.X = data_subset.raw.X\n        else:\n            data_subset = adata[cell_subset]\n\n        # clustering\n        if pheno is not None:\n            if verbose: \n                print('Leiden clustering ' + str(pheno))\n        else:\n            if verbose:\n                print('Leiden clustering')\n\n        sc.tl.pca(data_subset)\n        if n_pcs is None:\n            n_pcs = len(adata.var)\n        sc.pp.neighbors(data_subset, n_neighbors=nearest_neighbors, n_pcs=n_pcs)\n        sc.tl.leiden(data_subset,resolution=resolution, random_state=random_state)\n\n        # Rename the labels\n        cluster_labels = list(map(str,list(data_subset.obs['leiden'])))\n        if pheno is not None:\n            cluster_labels = list(map(lambda orig_string: pheno + '-' + orig_string, cluster_labels))\n\n        # Make it into a dataframe\n        cluster_labels = pd.DataFrame(cluster_labels, index = data_subset.obs.index)\n\n        # return labels\n        return cluster_labels\n\n    # Kmeans clustering\n    def k_clustering (pheno, adata, k, sub_cluster_column, use_raw, random_state):\n\n        # subset the data to be clustered\n        if pheno is not None:\n            cell_subset =  adata.obs[adata.obs[sub_cluster_column] == pheno].index\n        else:\n            cell_subset = adata.obs.index\n\n        # Usage of scaled or raw data\n        if use_raw == True:\n            if log is True:\n                data_subset = pd.DataFrame(np.log1p(adata.raw[cell_subset].X), columns =adata[cell_subset].var.index, index = adata[cell_subset].obs.index)\n            else:\n                data_subset = pd.DataFrame(adata.raw[cell_subset].X, columns =adata[cell_subset].var.index, index = adata[cell_subset].obs.index)\n        else:\n            data_subset = pd.DataFrame(adata[cell_subset].X, columns =adata[cell_subset].var.index, index = adata[cell_subset].obs.index)\n\n        # K-means clustering\n        if pheno is not None:\n            if verbose:\n                print('Kmeans clustering ' + str(pheno))\n        else:\n            if verbose:\n                print('Kmeans clustering')\n\n        kmeans = KMeans(n_clusters=k, random_state=random_state, n_init=10).fit(data_subset)\n\n        # Rename the labels\n        cluster_labels = list(map(str,kmeans.labels_))\n        if pheno is not None:\n            cluster_labels = list(map(lambda orig_string: pheno + '-' + orig_string, cluster_labels))\n\n        # Make it into a \n        cluster_labels = pd.DataFrame(cluster_labels, index = data_subset.index)\n\n        # return labels\n        return cluster_labels\n\n    # Phenograph clustering\n    def phenograph_clustering (pheno, adata, primary_metric, nearest_neighbors):\n\n        # subset the data to be clustered\n        if pheno is not None:\n            cell_subset =  adata.obs[adata.obs[sub_cluster_column] == pheno].index\n        else:\n            cell_subset = adata.obs.index\n\n        # Usage of scaled or raw data\n        if use_raw == True:\n            data_subset = adata[cell_subset]\n            if log is True:\n                data_subset.X = np.log1p(data_subset.raw.X)          \n            else:\n                data_subset.X = data_subset.raw.X\n        else:\n            data_subset = adata[cell_subset]\n\n        # Phenograph clustering\n        if pheno is not None:\n            if verbose:\n                print('Phenograph clustering ' + str(pheno))\n        else:\n            if verbose:\n                print('Phenograph clustering')\n\n        sc.tl.pca(data_subset)\n        result = sce.tl.phenograph(data_subset.obsm['X_pca'], k = nearest_neighbors, primary_metric=phenograph_clustering_metric)\n\n        # Rename the labels\n        cluster_labels = list(map(str,result[0]))\n        if pheno is not None:\n            cluster_labels = list(map(lambda orig_string: pheno + '-' + orig_string, cluster_labels))\n\n        # Make it into a dataframe\n        cluster_labels = pd.DataFrame(cluster_labels, index = data_subset.obs.index)\n\n        # return labels\n        return cluster_labels\n\n\n    # Use user defined genes for clustering\n    if subset_genes is not None:\n        bdata = adata[:,subset_genes]\n        bdata.raw = bdata[:,subset_genes]\n    else:\n        bdata = adata.copy()\n\n    # IF sub-cluster is True\n    # What cells to run the clustering on?\n    if sub_cluster is True:\n        if sub_cluster_group is not None:\n            if isinstance(sub_cluster_group, list):\n                pheno = sub_cluster_group\n            else:\n                pheno = [sub_cluster_group]         \n        else:\n            # Make sure number of clusters is not greater than number of cells available\n            if method == 'kmeans':\n                pheno = (bdata.obs[sub_cluster_column].value_counts() &gt; k+1).index[bdata.obs[sub_cluster_column].value_counts() &gt; k+1]\n            if method == 'phenograph':\n                pheno = (bdata.obs[sub_cluster_column].value_counts() &gt; nearest_neighbors+1).index[bdata.obs[sub_cluster_column].value_counts() &gt; nearest_neighbors+1]\n            if method == 'leiden':\n                pheno = (bdata.obs[sub_cluster_column].value_counts() &gt; 1).index[bdata.obs[sub_cluster_column].value_counts() &gt; 1]\n\n    # Run the specified method\n    if method == 'kmeans':\n        if sub_cluster == True:  \n            # Apply the Kmeans function\n            r_k_clustering = lambda x: k_clustering(pheno=x, adata=bdata, k=k, sub_cluster_column=sub_cluster_column, use_raw=use_raw, random_state=random_state) # Create lamda function \n            all_cluster_labels = list(map(r_k_clustering, pheno)) # Apply function \n        else:\n            all_cluster_labels = k_clustering(pheno=None, adata=bdata, k=k, sub_cluster_column=sub_cluster_column, use_raw=use_raw, random_state=random_state)\n\n    if method == 'phenograph':\n        if sub_cluster == True:\n            r_phenograph_clustering = lambda x: phenograph_clustering(pheno=x, adata=bdata, primary_metric=phenograph_clustering_metric, nearest_neighbors=nearest_neighbors) # Create lamda function \n            all_cluster_labels = list(map(r_phenograph_clustering, pheno)) # Apply function      \n        else:\n            all_cluster_labels = phenograph_clustering(pheno=None, adata=bdata, primary_metric=phenograph_clustering_metric, nearest_neighbors=nearest_neighbors)\n\n\n    if method == 'leiden':\n        if sub_cluster == True:\n            r_leiden_clustering = lambda x: leiden_clustering(pheno=x, adata=bdata, nearest_neighbors=nearest_neighbors, n_pcs=n_pcs, resolution=resolution) # Create lamda function \n            all_cluster_labels = list(map(r_leiden_clustering, pheno)) # Apply function \n        else:\n            all_cluster_labels = leiden_clustering(pheno=None, adata=bdata, nearest_neighbors=nearest_neighbors, n_pcs=n_pcs, resolution=resolution)\n\n\n\n    # Merge all the labels into one and add to adata\n    if sub_cluster == True:\n        sub_clusters = pd.concat(all_cluster_labels, axis=0, sort=False)\n    else:\n        sub_clusters = all_cluster_labels\n\n    # Merge with all cells\n    #sub_clusters = pd.DataFrame(bdata.obs[sub_cluster_column]).merge(sub_clusters, how='outer', left_index=True, right_index=True)\n    sub_clusters = pd.DataFrame(bdata.obs).merge(sub_clusters, how='outer', left_index=True, right_index=True)\n\n\n    # Transfer labels\n    if collapse_labels is False and sub_cluster is True:\n        sub_clusters = pd.DataFrame(sub_clusters[0].fillna(sub_clusters[sub_cluster_column]))\n\n\n    # Get only the required column\n    sub_clusters = sub_clusters[0]\n\n    # re index the rows\n    sub_clusters = sub_clusters.reindex(adata.obs.index)\n\n    # Append to adata\n    if label is None:\n        adata.obs[method] = sub_clusters\n    else:\n        adata.obs[label] = sub_clusters\n\n    # Save data if requested\n    if output_dir is not None:\n        output_dir = pathlib.Path(output_dir)\n        output_dir.mkdir(exist_ok=True, parents=True)\n        adata.write(output_dir / imid)\n    else:    \n        # Return data\n        return adata\n</code></pre>"},{"location":"Functions/tl/foldchange/","title":"foldchange","text":"<p>Short Description</p> <p>The <code>sm.tl.foldchange</code> function computes the fold change in cell-type abundance between samples or ROIs,  using the <code>from_group</code> parameter to specify the reference group by its column name in <code>imageid</code>.  It normalizes cell abundance to the total cell count within each sample/ROI to adjust for size differences,  a feature that can be disabled. The function uses a Fisher exact test to calculate p-values, assessing the  statistical significance of the observed changes.  </p> <p>Results are stored in the <code>.uns</code> section of the Anndata object for easy access and further analysis.</p>"},{"location":"Functions/tl/foldchange/#scimap.tools.foldchange--function","title":"Function","text":""},{"location":"Functions/tl/foldchange/#scimap.tools.foldchange.foldchange","title":"<code>foldchange(adata, from_group, to_group=None, imageid='imageid', phenotype='phenotype', normalize=True, subset_phenotype=None, label='foldchange', verbose=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The input AnnData object containing single-cell data for fold change analysis.</p> required <code>from_group</code> <code>list of str</code> <p>Specifies the reference sample(s) or Region of Interest (ROI) for calculating fold change. If multiple samples or ROIs are provided (e.g., ['ROI1', 'ROI2']), they will be aggregated to serve as a singular reference point for comparison.</p> required <code>to_group</code> <code>list of str</code> <p>Defines a specific set of samples/ROIs to compare against the reference group specified in <code>from_group</code>. If not provided, the reference will be compared to all other groups within the <code>imageid</code> column. For example, ['ROI3', 'ROI4'].</p> <code>None</code> <code>imageid</code> <code>str</code> <p>The column in <code>adata.obs</code> that holds the sample/ROI identifiers.</p> <code>'imageid'</code> <code>phenotype</code> <code>str</code> <p>The column in <code>adata.obs</code> that contains cell type or phenotype information.</p> <code>'phenotype'</code> <code>normalize</code> <code>bool</code> <p>If True, adjusts cell counts based on the total number of cells within each sample/ROI to account for differences in sample/ROI area. If <code>subset_phenotype</code> is provided, normalization considers only the total cells of the specified cell types.</p> <code>True</code> <code>subset_phenotype</code> <code>list of str</code> <p>Limits the analysis to a particular subset of cell types. Only cell types listed here will be included in the fold change computation.</p> <code>None</code> <code>label</code> <code>str</code> <p>Designates the key under which the fold change results (both fold change values and p-values) are stored in <code>adata.uns</code>. The results will be accessible as <code>&lt;label&gt;_fc</code> for fold changes and <code>&lt;label&gt;_pval</code> for p-values.</p> <code>'foldchange'</code> <code>verbose</code> <code>bool</code> <p>Enables the display of detailed progress updates and information about the execution steps when set to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>The input <code>adata</code> object, updated with fold change analysis results. The fold change values and p-values can be found in <code>adata.uns['&lt;label&gt;_fc']</code> and <code>adata.uns['&lt;label&gt;_pval']</code>, respectively.</p> Example <pre><code># Basic usage with automatic comparison to all other groups\nadata = sm.tl.foldchange(adata, from_group=['ROI1'], imageid='imageid', phenotype='phenotype', normalize=True, label='roi_comparison')\n\n# Specifying a subset of groups for comparison\nadata = sm.tl.foldchange(adata, from_group=['image_1'], to_group=['image_2', 'image_3'], imageid='imageid', phenotype='phenotype', normalize=True, label='specific_roi_comparison')\n\n# Focusing on specific cell types for fold change analysis\nadata = sm.tl.foldchange(adata, from_group=['ROI1'], to_group=['ROI3', 'ROI4'], subset_phenotype=['T cells', 'B cells', 'Macrophages'], label='subset_phenotype_comparison')\n</code></pre> Source code in <code>scimap/tools/foldchange.py</code> <pre><code>def foldchange (adata, \n                from_group, \n                to_group=None, \n                imageid='imageid', \n                phenotype='phenotype',\n                normalize=True, \n                subset_phenotype=None, \n                label='foldchange',\n                verbose=True):\n    \"\"\"\n\n\nParameters:\n    adata (anndata.AnnData):\n        The input AnnData object containing single-cell data for fold change analysis.\n\n    from_group (list of str):  \n        Specifies the reference sample(s) or Region of Interest (ROI) for calculating fold change. If multiple samples or ROIs are provided (e.g., ['ROI1', 'ROI2']), they will be aggregated to serve as a singular reference point for comparison.\n\n    to_group (list of str, optional):  \n        Defines a specific set of samples/ROIs to compare against the reference group specified in `from_group`. If not provided, the reference will be compared to all other groups within the `imageid` column. For example, ['ROI3', 'ROI4'].\n\n    imageid (str):  \n        The column in `adata.obs` that holds the sample/ROI identifiers.\n\n    phenotype (str):  \n        The column in `adata.obs` that contains cell type or phenotype information.\n\n    normalize (bool):  \n        If True, adjusts cell counts based on the total number of cells within each sample/ROI to account for differences in sample/ROI area. If `subset_phenotype` is provided, normalization considers only the total cells of the specified cell types.\n\n    subset_phenotype (list of str, optional):  \n        Limits the analysis to a particular subset of cell types. Only cell types listed here will be included in the fold change computation.\n\n    label (str):   \n        Designates the key under which the fold change results (both fold change values and p-values) are stored in `adata.uns`. The results will be accessible as `&lt;label&gt;_fc` for fold changes and `&lt;label&gt;_pval` for p-values.\n\n    verbose (bool):  \n        Enables the display of detailed progress updates and information about the execution steps when set to True.\n\nReturns:\n    adata (anndata.AnnData):\n        The input `adata` object, updated with fold change analysis results. The fold change values and p-values can be found in `adata.uns['&lt;label&gt;_fc']` and `adata.uns['&lt;label&gt;_pval']`, respectively.\n\n\nExample:\n    ```python\n\n    # Basic usage with automatic comparison to all other groups\n    adata = sm.tl.foldchange(adata, from_group=['ROI1'], imageid='imageid', phenotype='phenotype', normalize=True, label='roi_comparison')\n\n    # Specifying a subset of groups for comparison\n    adata = sm.tl.foldchange(adata, from_group=['image_1'], to_group=['image_2', 'image_3'], imageid='imageid', phenotype='phenotype', normalize=True, label='specific_roi_comparison')\n\n    # Focusing on specific cell types for fold change analysis\n    adata = sm.tl.foldchange(adata, from_group=['ROI1'], to_group=['ROI3', 'ROI4'], subset_phenotype=['T cells', 'B cells', 'Macrophages'], label='subset_phenotype_comparison')\n\n    ```\n\n    \"\"\"\n\n    # prepare data\n    data = adata.obs[[imageid,phenotype]]\n\n    # convert from and to groups to list\n    if isinstance(from_group, str):\n        from_group = [from_group]\n    if isinstance(to_group, str):\n        to_group = [to_group]\n\n    # subset phenotype of interest\n    if subset_phenotype is not None:\n        if isinstance (subset_phenotype, str):\n            subset_phenotype = [subset_phenotype]\n        data = data[data[phenotype].isin(subset_phenotype)]\n\n    # subset data    \n    from_data = data[data[imageid].isin(from_group)]\n    if len(from_group) &gt; 1:\n        combined_name = '_'.join(from_group)\n        #from_data[imageid] = combined_name\n        from_data.loc[:, imageid] = combined_name\n\n\n    from_data.loc[:, imageid] = from_data[imageid].astype('str').astype('category')\n    from_data.loc[:, phenotype] = from_data[phenotype].astype('str').astype('category')\n    if to_group is None:\n        to_data = data[~data[imageid].isin(from_group)]\n    else:\n        to_data = data[data[imageid].isin(to_group)]\n    to_data.loc[:, imageid] = to_data[imageid].astype('str').astype('category')\n    to_data.loc[:, phenotype] = to_data[phenotype].astype('str').astype('category')\n\n\n    if verbose:\n        print('calculating foldchange')\n\n    # consolidated counts dataframe\n    from_data_consolidated = pd.DataFrame(from_data.groupby([imageid,phenotype],observed=False).size()).unstack().fillna(0)\n    from_data_consolidated.columns = np.unique(from_data_consolidated.columns.get_level_values(1))\n\n    to_data_consolidated = pd.DataFrame(to_data.groupby([imageid,phenotype],observed=False).size()).unstack().fillna(0)\n    to_data_consolidated.columns = np.unique(to_data_consolidated.columns.get_level_values(1))\n\n    # make backup of the sample names\n    from_b = list(from_data_consolidated.index)\n    to_b = list(to_data_consolidated.index)\n\n    # make sure from_data_consolidated and to_data_consolidated has the same columns\n    x = from_data_consolidated.T\n    x.columns = x.columns.astype(str)\n    y = to_data_consolidated.T\n    y.columns = y.columns.astype(str)\n    consolidated = x.merge(y, how='outer', left_index=True, right_index=True).fillna(0)\n\n    # split it back into from and to\n    from_data_consolidated = consolidated[from_b].T\n    to_data_consolidated = consolidated[to_b].T\n\n    # create the total minus to and from tables\n    from_data_total = abs(from_data_consolidated.sub( from_data_consolidated.sum(axis=1), axis=0))\n    to_data_total = abs(to_data_consolidated.sub( to_data_consolidated.sum(axis=1), axis=0))\n\n    # \n    if verbose:\n        print('calculating P values')\n    p_vals = []\n    for i in from_data_consolidated.columns:\n        #a = from_data_consolidated[i][0]\n        a = from_data_consolidated[i].iloc[0]\n        #c = from_data_total[i][0]\n        c = from_data_total[i].iloc[0]\n        for j in to_data_consolidated.index:\n            #b = to_data_consolidated[i][j]\n            b = to_data_consolidated[i].loc[j]\n            d = to_data_total[i][j]\n            oddsratio, pvalue = stats.fisher_exact([[a, b], [c, d]])\n            p_vals.append(pvalue)\n\n    # replace 0 with a small number (1 cell) to avoind inf\n    from_data_consolidated_zero = from_data_consolidated.replace(0, 1, inplace=False)\n    to_data_consolidated_zero = to_data_consolidated.replace(0, 1, inplace=False)\n\n    # normalize based on area i.e total cells if user requests\n    if normalize is True:\n        # Normalize for total cells\n        from_data_ratio = from_data_consolidated_zero.div(from_data_consolidated_zero.sum(axis=1), axis=0)\n        to_data_ratio = to_data_consolidated_zero.div(to_data_consolidated_zero.sum(axis=1), axis=0)   \n    else:\n        from_data_ratio = from_data_consolidated_zero\n        to_data_ratio = to_data_consolidated_zero\n\n    # foldchange\n    fold_change = to_data_ratio.div(from_data_ratio.values,  axis=1)\n    fold_change.index.name = '-'.join(from_group)\n\n    # reshape the pvalues to the todata df\n    p_values = np.reshape(p_vals, to_data_consolidated.shape)\n    p_values = pd.DataFrame(p_values, columns = to_data_consolidated.columns, index= to_data_consolidated.index)\n\n    # return data\n    adata.uns[str(label)+'_pval'] = p_values\n    adata.uns[str(label)+'_fc'] = fold_change\n\n    return adata\n</code></pre>"},{"location":"Functions/tl/phenotype_cells/","title":"phenotype_cells","text":"<p>Short Description</p> <p><code>sm.tl.phenotype_cells</code>: This function annotates each cell in the dataset with a phenotype based on <code>scaled data</code> and a predefined <code>phenotype workflow</code>. Before using this function, ensure the data is scaled with the <code>sm.tl.rescale</code> function.</p> <p>Description of the Phenotype Workflow File: Find an example <code>phenotype_workflow.csv</code> here.</p> <p>The <code>phenotype_workflow</code> file outlines six gating strategies for cell phenotyping:</p> <ul> <li>allpos: Requires all specified markers to be positive for a cell to be assigned the phenotype.</li> <li>allneg: Requires all specified markers to be negative for a cell to be assigned the phenotype.</li> <li>anypos: Requires at least one of the specified markers to be positive for a cell to be assigned the phenotype. For example, a macrophage could be identified if it is positive for any of the markers <code>CD68</code>, <code>CD163</code>, or <code>CD206</code>.</li> <li>anyneg: Requires at least one of the specified markers to be negative for a cell to be assigned the phenotype.</li> <li>pos: Specifies that a cell must be positive for the given marker(s) to be assigned the phenotype. If used for multiple markers, cells not meeting all criteria may still be classified as a potential phenotype, allowing for later refinement by the user. For instance, regulatory T cells could be defined as <code>CD4+</code> and <code>FOXP3+</code>; cells not fully meeting these criteria might be labeled as likely-regulatory T cells for further evaluation.</li> <li>neg: Specifies that a cell must be negative for the given marker(s) to be assigned the phenotype.</li> </ul> <p>Recommendation: Prioritize using positive markers to define phenotypes whenever possible.</p>"},{"location":"Functions/tl/phenotype_cells/#scimap.tools.phenotype_cells--function","title":"Function","text":""},{"location":"Functions/tl/phenotype_cells/#scimap.tools.phenotype_cells.phenotype_cells","title":"<code>phenotype_cells(adata, phenotype, gate=0.5, label='phenotype', imageid='imageid', pheno_threshold_percent=None, pheno_threshold_abs=None, verbose=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The input AnnData object containing single-cell data for phenotyping.</p> required <code>phenotype</code> <code>DataFrame</code> <p>A DataFrame specifying the gating strategy for cell phenotyping. It should outline the workflow for phenotype classification based on marker expression levels. An example workflow is available at this GitHub link.</p> required <code>gate</code> <code>float</code> <p>The threshold value for determining positive cell classification based on scaled data. By convention, values above this threshold are considered to indicate positive cells. </p> <code>0.5</code> <code>label</code> <code>str</code> <p>The name of the column in <code>adata.obs</code> where the final phenotype classifications will be stored. This label will be used to access the phenotyping results within the <code>AnnData</code> object.</p> <code>'phenotype'</code> <code>imageid</code> <code>str</code> <p>The name of the column in <code>adata.obs</code> that contains unique image identifiers. This is crucial for analyses that require differentiation of data based on the source image, especially when using phenotype threshold parameters (<code>pheno_threshold_percent</code> or <code>pheno_threshold_abs</code>).</p> <code>'imageid'</code> <code>pheno_threshold_percent</code> <code>float</code> <p>A threshold value (between 0 and 100) specifying the minimum percentage of cells that must exhibit a particular phenotype for it to be considered valid. Phenotypes not meeting this threshold are reclassified as 'unknown'. This parameter is useful for minimizing the impact of low-frequency false positives. </p> <code>None</code> <code>pheno_threshold_abs</code> <code>int</code> <p>Similar to <code>pheno_threshold_percent</code>, but uses an absolute cell count instead of a percentage. Phenotypes with cell counts below this threshold are reclassified as 'unknown'. This can help in addressing rare phenotype classifications that may not be meaningful. </p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If set to <code>True</code>, the function will print detailed messages about its progress and the steps being executed.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>The input AnnData object, updated to include the phenotype classifications for each cell. The phenotyping results can be found in <code>adata.obs[label]</code>, where <code>label</code> is the name specified by the user for the phenotype column.</p> Example <pre><code># Load the phenotype workflow CSV file\nphenotype = pd.read_csv('path/to/csv/file/')  \n\n# Apply phenotyping to cells based on the specified workflow\nadata = sm.tl.phenotype_cells(adata, phenotype=phenotype, gate=0.5, label=\"phenotype\")\n</code></pre> Source code in <code>scimap/tools/phenotype_cells.py</code> <pre><code>def phenotype_cells (adata, \n                     phenotype, \n                     gate = 0.5, \n                     label=\"phenotype\", \n                     imageid='imageid',\n                     pheno_threshold_percent=None, \n                     pheno_threshold_abs=None,\n                     verbose=True\n                     ):\n    \"\"\"\n\nParameters:\n    adata (anndata.AnnData):  \n        The input AnnData object containing single-cell data for phenotyping.\n\n    phenotype (pd.DataFrame):  \n        A DataFrame specifying the gating strategy for cell phenotyping. It should outline the workflow for phenotype classification based on marker expression levels. An example workflow is available at [this GitHub link](https://github.com/ajitjohnson/scimap/blob/master/scimap/tests/_data/phenotype_workflow.csv).\n\n    gate (float, optional):  \n        The threshold value for determining positive cell classification based on scaled data. By convention, values above this threshold are considered to indicate positive cells. \n\n    label (str):  \n        The name of the column in `adata.obs` where the final phenotype classifications will be stored. This label will be used to access the phenotyping results within the `AnnData` object.\n\n    imageid (str, optional):  \n        The name of the column in `adata.obs` that contains unique image identifiers. This is crucial for analyses that require differentiation of data based on the source image, especially when using phenotype threshold parameters (`pheno_threshold_percent` or `pheno_threshold_abs`).\n\n    pheno_threshold_percent (float, optional):  \n        A threshold value (between 0 and 100) specifying the minimum percentage of cells that must exhibit a particular phenotype for it to be considered valid. Phenotypes not meeting this threshold are reclassified as 'unknown'. This parameter is useful for minimizing the impact of low-frequency false positives. \n\n    pheno_threshold_abs (int, optional):  \n        Similar to `pheno_threshold_percent`, but uses an absolute cell count instead of a percentage. Phenotypes with cell counts below this threshold are reclassified as 'unknown'. This can help in addressing rare phenotype classifications that may not be meaningful. \n\n    verbose (bool):  \n        If set to `True`, the function will print detailed messages about its progress and the steps being executed.\n\nReturns:\n    adata (anndata.AnnData):  \n        The input AnnData object, updated to include the phenotype classifications for each cell. The phenotyping results can be found in `adata.obs[label]`, where `label` is the name specified by the user for the phenotype column.\n\nExample:    \n    ```python\n\n    # Load the phenotype workflow CSV file\n    phenotype = pd.read_csv('path/to/csv/file/')  \n\n    # Apply phenotyping to cells based on the specified workflow\n    adata = sm.tl.phenotype_cells(adata, phenotype=phenotype, gate=0.5, label=\"phenotype\")\n\n    ```\n\n    \"\"\"\n    # Create a dataframe from the adata object\n    data = pd.DataFrame(adata.X, columns = adata.var.index, index= adata.obs.index)\n\n    # Function to calculate the phenotype scores\n    def phenotype_cells (data,phenotype,gate,group):\n\n        # Subset the phenotype based on the group\n        phenotype = phenotype[phenotype.iloc[:,0] == group]\n\n        # Parser to parse the CSV file into four categories\n        def phenotype_parser (p, cell):\n            # Get the index and subset the phenotype row being passed in\n            location = p.iloc[:,1] == cell\n            idx = [i for i, x in enumerate(location) if x][0]\n            phenotype = p.iloc[idx,:]\n            # Calculate\n            pos = phenotype[phenotype == 'pos'].index.tolist()\n            neg = phenotype[phenotype == 'neg'].index.tolist()\n            anypos = phenotype[phenotype == 'anypos'].index.tolist()\n            anyneg = phenotype[phenotype == 'anyneg'].index.tolist()\n            allpos = phenotype[phenotype == 'allpos'].index.tolist()\n            allneg = phenotype[phenotype == 'allneg'].index.tolist()\n            return {'pos': pos, 'neg': neg ,'anypos': anypos, 'anyneg': anyneg, 'allpos': allpos, 'allneg': allneg}\n            #return pos, neg, anypos, anyneg\n\n        # Run the phenotype_parser function on all rows\n        p_list = phenotype.iloc[:,1].tolist()\n        r_phenotype = lambda x: phenotype_parser(cell=x, p=phenotype) # Create lamda function\n        all_phenotype = list(map(r_phenotype, p_list)) # Apply function\n        all_phenotype = dict(zip(p_list, all_phenotype)) # Name the lists\n\n        # Define function to check if there is any marker that does not satisfy the gate\n        def gate_satisfation_lessthan (marker, data, gate):\n            fail = np.where(data[marker] &lt; gate, 1, 0) # 1 is fail\n            return fail\n        # Corresponding lamda function\n        r_gate_satisfation_lessthan = lambda x: gate_satisfation_lessthan(marker=x, data=data, gate=gate)\n\n        # Define function to check if there is any marker that does not satisfy the gate\n        def gate_satisfation_morethan (marker, data, gate):\n            fail = np.where(data[marker] &gt; gate, 1, 0)\n            return fail\n        # Corresponding lamda function\n        r_gate_satisfation_morethan = lambda x: gate_satisfation_morethan(marker=x, data=data, gate=gate)\n\n        def prob_mapper (data, all_phenotype, cell, gate):\n\n            if verbose:\n                print(\"Phenotyping \" + str(cell))\n\n            # Get the appropriate dict from all_phenotype\n            p = all_phenotype[cell]\n\n            # Identiy the marker used in each category\n            pos = p.get('pos')\n            neg = p.get('neg')\n            anypos = p.get('anypos')\n            anyneg = p.get('anyneg')\n            allpos = p.get('allpos')\n            allneg = p.get('allneg')\n\n            # Perform computation for each group independently\n            # Positive marker score\n            if len(pos) != 0:\n                pos_score = data[pos].mean(axis=1).values\n                pos_fail = list(map(r_gate_satisfation_lessthan, pos)) if len(pos) &gt; 1 else []\n                pos_fail = np.amax(pos_fail, axis=0) if len(pos) &gt; 1 else []\n            else:\n                pos_score = np.repeat(0, len(data))\n                pos_fail = []\n\n            # Negative marker score\n            if len(neg) != 0:\n                neg_score = (1-data[neg]).mean(axis=1).values\n                neg_fail = list(map(r_gate_satisfation_morethan, neg)) if len(neg) &gt; 1 else []\n                neg_fail = np.amax(neg_fail, axis=0) if len(neg) &gt; 1 else []\n            else:\n                neg_score = np.repeat(0, len(data))\n                neg_fail = []\n\n            # Any positive score\n            anypos_score = np.repeat(0, len(data)) if len(anypos) == 0 else data[anypos].max(axis=1).values\n\n            # Any negative score\n            anyneg_score = np.repeat(0, len(data)) if len(anyneg) == 0 else (1-data[anyneg]).max(axis=1).values\n\n            # All positive score\n            if len(allpos) != 0:\n                allpos_score = data[allpos]\n                allpos_score['score'] = allpos_score.max(axis=1)\n                allpos_score.loc[(allpos_score &lt; gate).any(axis = 1), 'score'] = 0\n                allpos_score = allpos_score['score'].values + 0.01 # A small value is added to give an edge over the matching positive cell\n            else:\n                allpos_score = np.repeat(0, len(data))\n\n\n            # All negative score\n            if len(allneg) != 0:\n                allneg_score = 1- data[allneg]\n                allneg_score['score'] = allneg_score.max(axis=1)\n                allneg_score.loc[(allneg_score &lt; gate).any(axis = 1), 'score'] = 0\n                allneg_score = allneg_score['score'].values + 0.01\n            else:\n                allneg_score = np.repeat(0, len(data))\n\n\n            # Total score calculation\n            # Account for differences in the number of categories used for calculation of the final score\n            number_of_non_empty_features = np.sum([len(pos) != 0,\n                                                len(neg) != 0,\n                                                len(anypos) != 0,\n                                                len(anyneg) != 0,\n                                                len(allpos) != 0,\n                                                len(allneg) != 0])\n\n            total_score = (pos_score + neg_score + anypos_score + anyneg_score + allpos_score + allneg_score) / number_of_non_empty_features\n\n            return {cell: total_score, 'pos_fail': pos_fail ,'neg_fail': neg_fail}\n            #return total_score, pos_fail, neg_fail\n\n\n        # Apply the fuction to get the total score for all cell types\n        r_prob_mapper = lambda x: prob_mapper (data=data, all_phenotype=all_phenotype, cell=x, gate=gate) # Create lamda function\n        final_scores = list(map(r_prob_mapper, [*all_phenotype])) # Apply function\n        final_scores = dict(zip([*all_phenotype], final_scores)) # Name the lists\n\n        # Combine the final score to annotate the cells with a label\n        final_score_df = pd.DataFrame()\n        for i in [*final_scores]:\n            df = pd.DataFrame(final_scores[i][i])\n            final_score_df= pd.concat([final_score_df, df], axis=1)\n        # Name the columns\n        final_score_df.columns = [*final_scores]\n        final_score_df.index = data.index\n        # Add a column called unknown if all markers have a value less than the gate (0.5)\n        unknown = group + str('-rest')\n        final_score_df[unknown] = (final_score_df &lt; gate).all(axis=1).astype(int)\n\n        # Name each cell\n        labels = final_score_df.idxmax(axis=1)\n\n        # Group all failed instances (i.e. when multiple markers were given\n        # any one of the marker fell into neg or pos zones of the gate)\n        pos_fail_all = pd.DataFrame()\n        for i in [*final_scores]:\n            df = pd.DataFrame(final_scores[i]['pos_fail'])\n            df.columns = [i] if len(df) != 0 else []\n            pos_fail_all= pd.concat([pos_fail_all, df], axis=1)\n        pos_fail_all.index = data.index if len(pos_fail_all) != 0 else []\n        # Same for Neg\n        neg_fail_all = pd.DataFrame()\n        for i in [*final_scores]:\n            df = pd.DataFrame(final_scores[i]['neg_fail'])\n            df.columns = [i] if len(df) != 0 else []\n            neg_fail_all= pd.concat([neg_fail_all, df], axis=1)\n        neg_fail_all.index = data.index if len(neg_fail_all) != 0 else []\n\n\n        # Modify the labels with the failed annotations\n        if len(pos_fail_all) != 0:\n            for i in pos_fail_all.columns:\n                labels[(labels == i) &amp; (pos_fail_all[i] == 1)] = 'likely-' + i\n        # Do the same for negative\n        if len(neg_fail_all) != 0:\n            for i in neg_fail_all.columns:\n                labels[(labels == i) &amp; (neg_fail_all[i] == 1)] = 'likely-' + i\n\n        # Retun the labels\n        return labels\n\n    # Create an empty dataframe to hold the labeles from each group\n    phenotype_labels = pd.DataFrame()\n\n    # Loop through the groups to apply the phenotype_cells function\n    for i in phenotype.iloc[:,0].unique():\n\n        if phenotype_labels.empty:\n            phenotype_labels = pd.DataFrame(phenotype_cells(data = data, group = i, phenotype=phenotype, gate=gate))\n            phenotype_labels.columns = [i]\n\n        else:\n            # Find the column with the cell-type of interest\n            column_of_interest = [] # Empty list to hold the column name\n            try:\n                column_of_interest = phenotype_labels.columns[phenotype_labels.eq(i).any()]\n            except:\n                pass\n            # If the cell-type of interest was not found just add NA\n            if len(column_of_interest) == 0:\n                phenotype_labels[i] = np.nan\n            else:\n                #cells_of_interest = phenotype_labels[phenotype_labels[column_of_interest] == i].index\n                cells_of_interest = phenotype_labels[phenotype_labels[column_of_interest].eq(i).any(axis=1)].index\n                d = data.loc[cells_of_interest]\n                if verbose:\n                    print(\"-- Subsetting \" + str(i))\n                phenotype_l = pd.DataFrame(phenotype_cells(data = d, group = i, phenotype=phenotype, gate=gate), columns = [i])\n                phenotype_labels = phenotype_labels.merge(phenotype_l, how='outer', left_index=True, right_index=True)\n\n    # Rearrange the rows back to original\n    phenotype_labels = phenotype_labels.reindex(data.index)\n    phenotype_labels = phenotype_labels.replace('-rest', np.nan, regex=True)\n\n    if verbose:\n        print(\"Consolidating the phenotypes across all groups\")\n    phenotype_labels_Consolidated = phenotype_labels.fillna(method='ffill', axis = 1)\n    phenotype_labels[label] = phenotype_labels_Consolidated.iloc[:,-1].values\n\n    # replace nan to 'other cells'\n    phenotype_labels[label] = phenotype_labels[label].fillna('Unknown')\n\n    # Apply the phenotype threshold if given\n    if pheno_threshold_percent or pheno_threshold_abs is not None:\n        p = pd.DataFrame(phenotype_labels[label])\n        q = pd.DataFrame(adata.obs[imageid])\n        p = q.merge(p, how='outer', left_index=True, right_index=True)\n\n        # Function to remove phenotypes that are less than the given threshold\n        def remove_phenotype(p, ID, pheno_threshold_percent, pheno_threshold_abs):\n            d = p[p[imageid] == ID]\n            x = pd.DataFrame(d.groupby([label]).size())\n            x.columns = ['val']\n            # FInd the phenotypes that are less than the given threshold\n            if pheno_threshold_percent is not None:\n                fail = list(x.loc[x['val'] &lt; x['val'].sum() * pheno_threshold_percent/100].index)\n            if pheno_threshold_abs is not None:\n                fail = list(x.loc[x['val'] &lt; pheno_threshold_abs].index)\n            d[label] = d[label].replace(dict(zip(fail, ['Unknown'] * len(fail) )))\n            # Return\n            return d\n\n        # Apply function to all images\n        r_remove_phenotype = lambda x: remove_phenotype (p=p, ID=x,\n                                                         pheno_threshold_percent=pheno_threshold_percent,\n                                                         pheno_threshold_abs=pheno_threshold_abs) # Create lamda function\n        final_phrnotypes= list(map(r_remove_phenotype, list(p[imageid].unique()))) # Apply function\n\n        final_phrnotypes = pd.concat(final_phrnotypes, join='outer')\n        phenotype_labels = final_phrnotypes.reindex(adata.obs.index)\n\n\n    # Return to adata\n    adata.obs[label] = phenotype_labels[label]\n\n    #for i in phenotype_labels.columns:\n    #    adata.obs[i] = phenotype_labels[i]\n\n    return adata\n</code></pre>"},{"location":"Functions/tl/spatial_aggregate/","title":"spatial_aggregate","text":"<p>Short Description</p> <p><code>sm.tl.spatial_aggregate</code>: This function identifies spatial clusters of phenotypically similar cells  within specified regions. By adjusting the <code>purity</code> parameter, users can specify the minimum  percentage of similarity required among cells within a defined <code>radius</code> or nearest neighbors,  enabling precise delineation of cellular aggregates.</p>"},{"location":"Functions/tl/spatial_aggregate/#scimap.tools.spatial_aggregate--function","title":"Function","text":""},{"location":"Functions/tl/spatial_aggregate/#scimap.tools.spatial_aggregate.spatial_aggregate","title":"<code>spatial_aggregate(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid', z_coordinate=None, purity=60, phenotype='phenotype', method='radius', radius=30, knn=10, imageid='imageid', subset=None, verbose=True, label='spatial_aggregate')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The annotated data matrix of shape (n_obs, n_vars), where rows correspond to cells and columns to genes, used for spatial analysis.</p> required <code>x_coordinate</code> <code>(str, required)</code> <p>The column name in <code>adata</code> containing the x-coordinates of cells.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <code>(str, required)</code> <p>The column name in <code>adata</code> containing the y-coordinates of cells.</p> <code>'Y_centroid'</code> <code>z_coordinate</code> <code>(str, required)</code> <p>The column name in <code>adata</code> containing the z-coordinates of cells.</p> <code>None</code> <code>purity</code> <code>int</code> <p>The minimum percentage (between 1 and 100) of cells with a similar phenotype required in a neighborhood for it to be considered a cluster. </p> <code>60</code> <code>phenotype</code> <code>(str, required)</code> <p>The column name in <code>adata</code> representing cell phenotype information or any other categorical classification of cells.</p> <code>'phenotype'</code> <code>method</code> <code>str</code> <p>The neighborhood definition method: 'radius' for radial distance-based neighborhoods or 'knn' for k-nearest neighbors-based neighborhoods. </p> <code>'radius'</code> <code>radius</code> <code>int</code> <p>The radius used to define a neighborhood around each cell, applicable when <code>method='radius'</code>. Measured in the same units as x and y coordinates.</p> <code>30</code> <code>knn</code> <code>int</code> <p>The number of nearest neighbors to consider for defining a neighborhood around each cell, applicable when <code>method='knn'</code>.</p> <code>10</code> <code>imageid</code> <code>str</code> <p>The column name in <code>adata</code> containing identifiers for different images, allowing for analysis within specific images.</p> <code>'imageid'</code> <code>subset</code> <code>str</code> <p>The identifier of a specific image to restrict the analysis to. If provided, analysis will only be performed on this subset.</p> <code>None</code> <code>label</code> <code>str</code> <p>The key under which to store the results in <code>adata.obs</code>, allowing for customized labeling of the output.</p> <code>'spatial_aggregate'</code> <code>verbose</code> <code>bool</code> <code>True</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>The input AnnData object updated with the results stored under <code>adata.obs[label]</code>, where <code>label</code> is the specified output label.</p> Example <pre><code># Analyze spatial aggregation using the radius method\nadata = sm.tl.spatial_aggregate(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                                phenotype='phenotype', method='radius', radius=30, purity=60,\n                                imageid='imageid', subset=None, label='spatial_aggregate_radius')\n\n# Analyze spatial aggregation using the knn method\nadata = sm.tl.spatial_aggregate(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                                phenotype='phenotype', method='knn', knn=10, purity=60,\n                                imageid='imageid', subset=None, label='spatial_aggregate_knn')\n\n# Subset analysis to a specific image using the radius method\nadata = sm.tl.spatial_aggregate(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                                phenotype='phenotype', method='radius', radius=30, purity=60,\n                                imageid='imageid', subset='image_01', label='spatial_aggregate_image_01')\n</code></pre> Source code in <code>scimap/tools/spatial_aggregate.py</code> <pre><code>def spatial_aggregate (adata, \n                       x_coordinate='X_centroid',\n                       y_coordinate='Y_centroid',\n                       z_coordinate= None,\n                       purity = 60, \n                       phenotype='phenotype', \n                       method='radius', \n                       radius=30, \n                       knn=10, \n                       imageid='imageid',\n                       subset=None,\n                       verbose=True,\n                       label='spatial_aggregate'):\n    \"\"\"\n\nParameters:\n        adata (anndata.AnnData):  \n            The annotated data matrix of shape (n_obs, n_vars), where rows correspond to cells and columns to genes, used for spatial analysis.\n\n        x_coordinate (str, required):  \n            The column name in `adata` containing the x-coordinates of cells.\n\n        y_coordinate (str, required):  \n            The column name in `adata` containing the y-coordinates of cells.\n\n        z_coordinate (str, required):  \n            The column name in `adata` containing the z-coordinates of cells.\n\n        purity (int, optional):  \n            The minimum percentage (between 1 and 100) of cells with a similar phenotype required in a neighborhood for it to be considered a cluster. \n\n        phenotype (str, required):  \n            The column name in `adata` representing cell phenotype information or any other categorical classification of cells.\n\n        method (str, optional):  \n            The neighborhood definition method: 'radius' for radial distance-based neighborhoods or 'knn' for k-nearest neighbors-based neighborhoods. \n\n        radius (int, optional):  \n            The radius used to define a neighborhood around each cell, applicable when `method='radius'`. Measured in the same units as x and y coordinates.\n\n        knn (int, optional):  \n            The number of nearest neighbors to consider for defining a neighborhood around each cell, applicable when `method='knn'`.\n\n        imageid (str, optional):  \n            The column name in `adata` containing identifiers for different images, allowing for analysis within specific images.\n\n        subset (str, optional):  \n            The identifier of a specific image to restrict the analysis to. If provided, analysis will only be performed on this subset.\n\n        label (str, optional):  \n            The key under which to store the results in `adata.obs`, allowing for customized labeling of the output.\n\n        verbose (bool):  \n        If set to `True`, the function will print detailed messages about its progress and the steps being executed.\n\nReturns:\n        adata (anndata.AnnData):    \n            The input AnnData object updated with the results stored under `adata.obs[label]`, where `label` is the specified output label.\n\nExample:\n    ```python\n\n    # Analyze spatial aggregation using the radius method\n    adata = sm.tl.spatial_aggregate(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                                    phenotype='phenotype', method='radius', radius=30, purity=60,\n                                    imageid='imageid', subset=None, label='spatial_aggregate_radius')\n\n    # Analyze spatial aggregation using the knn method\n    adata = sm.tl.spatial_aggregate(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                                    phenotype='phenotype', method='knn', knn=10, purity=60,\n                                    imageid='imageid', subset=None, label='spatial_aggregate_knn')\n\n    # Subset analysis to a specific image using the radius method\n    adata = sm.tl.spatial_aggregate(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                                    phenotype='phenotype', method='radius', radius=30, purity=60,\n                                    imageid='imageid', subset='image_01', label='spatial_aggregate_image_01')\n\n    ```\n    \"\"\"\n\n    # Error statements\n    #if purity &lt; 51:\n    #    raise ValueError('purity should be set to a value greater than 50')\n\n    def spatial_aggregate_internal (adata_subset, x_coordinate,y_coordinate,z_coordinate,phenotype,purity,\n                                    method,radius,knn,imageid,subset,label):\n\n\n        # Create a DataFrame with the necessary inforamtion\n        if z_coordinate is not None:\n            if verbose:\n                print(\"Including Z -axis\")\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'z': adata_subset.obs[z_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n        else:\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n\n        #data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n\n        # Identify neighbourhoods based on the method used\n        # a) KNN method\n        if method == 'knn':\n            if verbose:\n                print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n            if z_coordinate is not None:\n                tree = BallTree(data[['x','y','z']], leaf_size= 2)\n                ind = tree.query(data[['x','y','z']], k=knn, return_distance= False)\n            else:\n                tree = BallTree(data[['x','y']], leaf_size= 2)\n                ind = tree.query(data[['x','y']], k=knn, return_distance= False)\n            neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n            neighbours.drop(0, axis=1, inplace=True) # Remove self neighbour\n\n        # b) Local radius method\n        if method == 'radius':\n            if verbose:\n                print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n            if z_coordinate is not None:\n                kdt = BallTree(data[['x','y','z']], metric='euclidean') \n                ind = kdt.query_radius(data[['x','y','z']], r=radius, return_distance=False)\n            else:\n                kdt = BallTree(data[['x','y']], metric='euclidean') \n                ind = kdt.query_radius(data[['x','y']], r=radius, return_distance=False)\n\n            for i in range(0, len(ind)): ind[i] = np.delete(ind[i], np.argwhere(ind[i] == i))#remove self\n            neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n\n\n# =============================================================================\n#         if method == 'knn':\n#             if verbose:\n#                 print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n#             tree = BallTree(data[['x','y']], leaf_size= 2)\n#             ind = tree.query(data[['x','y']], k=knn, return_distance= False)\n#             neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n#             neighbours.drop(0, axis=1, inplace=True) # Remove self neighbour\n#         \n#         # b) Local radius method\n#         if method == 'radius':\n#             if verbose:\n#                 print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n#             kdt = BallTree(data[['x','y']], leaf_size= 2) \n#             ind = kdt.query_radius(data[['x','y']], r=radius, return_distance=False)\n#             for i in range(0, len(ind)): ind[i] = np.delete(ind[i], np.argwhere(ind[i] == i))#remove self\n#             neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n# =============================================================================\n\n        # Map phenotype\n        phenomap = dict(zip(list(range(len(ind))), data['phenotype'])) # Used for mapping\n\n        # Loop through (all functionized methods were very slow)\n        for i in neighbours.columns:\n            neighbours[i] = neighbours[i].dropna().map(phenomap, na_action='ignore')\n\n        # Drop NA\n        #n_dropped = neighbours.dropna(how='all')\n\n\n        # Collapse all the neighbours into a single column\n        n = pd.DataFrame(neighbours.stack(), columns = [\"neighbour_phenotype\"])\n        n.index = n.index.get_level_values(0) # Drop the multi index\n        n = pd.DataFrame(n)\n        n['order'] = list(range(len(n)))\n\n        # Merge with real phenotype\n        n_m = n.merge(data['phenotype'], how='inner', left_index=True, right_index=True)\n        n_m['neighbourhood'] = n_m.index\n        n = n_m.sort_values(by=['order'])\n\n        # Count the neighbours\n        k = n.groupby(['neighbourhood','neighbour_phenotype']).size().unstack().fillna(0)\n        k = k.div(k.sum(axis=1), axis=0)\n\n        # Iteratte over all rows and find the column which passes the purity test\n        #def col_name_mapper (row_data, purity):\n        #    p = row_data[row_data &gt;= purity/100]\n        #    #phenotype_name = 'non-significant' if len(p.index) == 0 else p.index[0]\n        #    phenotype_name = 'non-significant' if len(p.index) == 0 else p.idxmax()\n        #    return phenotype_name\n        # Apply the iteration function\n        #aggregate_pheno = pd.DataFrame(k.apply(lambda x: col_name_mapper(row_data=x,purity=purity), axis=1))\n\n\n        # Within the spatial_aggregate_internal function\n        # Create an empty DataFrame to hold the results\n        aggregate_pheno = pd.DataFrame(index=k.index, columns=[0])\n\n        # Iterate over rows in DataFrame k\n        for idx, row in k.iterrows():\n            filtered_row = row[row &gt;= purity / 100]  # Apply purity threshold\n            if not filtered_row.empty:  # Check if the filtered row is not empty\n                # If not empty, find the index of the maximum value\n                max_idx = filtered_row.idxmax()\n            else:\n                # If empty, set to 'non-significant'\n                max_idx = 'non-significant'\n            # Store the result\n            aggregate_pheno.at[idx, 0] = max_idx\n\n\n        #aggregate_pheno = pd.DataFrame(k[k&gt;=purity/100].idxmax(axis=1).fillna('non-significant'))\n        aggregate_pheno.columns = ['spatial_aggregate']\n\n        # Return \n        return aggregate_pheno\n\n\n    # Subset a particular image if needed\n    if subset is not None:\n        adata_list = [adata[adata.obs[imageid] == subset]]\n    else:\n        adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n\n    # Apply function to all images and create a master dataframe\n    # Create lamda function \n    r_spatial_aggregate_internal = lambda x: spatial_aggregate_internal(adata_subset=x,\n                                                                          x_coordinate=x_coordinate,\n                                                                          y_coordinate=y_coordinate,\n                                                                          z_coordinate=z_coordinate,\n                                                                          phenotype=phenotype,\n                                                                          method=method,\n                                                                          radius=radius,knn=knn,\n                                                                          imageid=imageid,subset=subset,\n                                                                          purity=purity,\n                                                                          label=label) \n    all_data = list(map(r_spatial_aggregate_internal, adata_list)) # Apply function \n\n    # Merge all the results into a single dataframe    \n    result = []\n    for i in range(len(all_data)):\n        result.append(all_data[i])\n    result = pd.concat(result, join='outer')  \n\n    # Reindex the cells\n    result = result.reindex(adata.obs.index)\n    result = result.fillna('non-significant')\n\n    # Add to adata\n    adata.obs[label] = result\n\n    # Return        \n    return adata\n</code></pre>"},{"location":"Functions/tl/spatial_cluster/","title":"spatial_cluster","text":"<p>Short Description</p> <p><code>sm.tl.spatial_cluster</code>: This function clusters cells based on their spatial  neighborhood matrices, which can be derived from analyses such as <code>sm.tl.spatial_expression</code>,  <code>sm.tl.spatial_count</code>, or <code>sm.tl.spatial_lda</code>. By leveraging various clustering algorithms,  including k-means, phenograph, and leiden, it enables the identification of spatially  coherent cell groups or microenvironments within tissue sections.</p>"},{"location":"Functions/tl/spatial_cluster/#scimap.tools.spatial_cluster--function","title":"Function","text":""},{"location":"Functions/tl/spatial_cluster/#scimap.tools.spatial_cluster.spatial_cluster","title":"<code>spatial_cluster(adata, df_name='spatial_count', method='kmeans', k=10, n_pcs=None, resolution=1, phenograph_clustering_metric='euclidean', nearest_neighbors=30, random_state=0, label=None, verbose=True, output_dir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix or path to an AnnData object, containing spatial gene expression data.</p> required <code>df_name</code> <code>str</code> <p>Specifies the label of the spatial analysis results to use for clustering. Default options are 'spatial_count' and 'spatial_expression'.</p> <code>'spatial_count'</code> <code>method</code> <code>str</code> <p>The clustering method to apply. Supported methods include 'kmeans', 'phenograph', and 'leiden'.</p> <code>'kmeans'</code> <code>k</code> <code>int</code> <p>Number of clusters to form when using K-Means clustering. Applies only if method='kmeans'.</p> <code>10</code> <code>n_pcs</code> <code>int</code> <p>Number of principal components to use in 'leiden' clustering. If None, all components are used.</p> <code>None</code> <code>resolution</code> <code>float</code> <p>Controls the granularity of clustering. Higher values lead to more clusters. Applies to 'leiden' and 'phenograph'.</p> <code>1</code> <code>phenograph_clustering_metric</code> <code>str</code> <p>The metric for defining nearest neighbors in 'phenograph' clustering. Choices include 'euclidean', 'manhattan', 'cosine', etc.</p> <code>'euclidean'</code> <code>nearest_neighbors</code> <code>int</code> <p>Number of nearest neighbors to consider in the graph construction step, for 'leiden' and 'phenograph'.</p> <code>30</code> <code>random_state</code> <code>int</code> <p>Seed for random number generation, ensuring reproducible results.</p> <code>0</code> <code>label</code> <code>str</code> <p>Custom label for storing results in <code>adata.obs</code>. Defaults to method name (e.g., 'spatial_kmeans').</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If set to <code>True</code>, the function will print detailed messages about its progress and the steps being executed.</p> <code>True</code> <code>output_dir</code> <code>str</code> <p>Directory path for saving output files. If None, results are not saved to disk.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>The input <code>adata</code> object updated with clustering results in <code>adata.obs[label]</code>.</p> Example <pre><code># Apply K-Means clustering\nadata = sm.tl.spatial_cluster(adata, df_name='spatial_count', method='kmeans', k=10, label='cluster_kmeans')\n\n# Apply Leiden clustering with specific resolution and principal components\nadata = sm.tl.spatial_cluster(adata, df_name='spatial_expression', method='leiden', resolution=0.5, n_pcs=20, label='cluster_leiden')\n\n# Apply Phenograph clustering with a specific metric and nearest neighbors\nadata = sm.tl.spatial_cluster(adata, df_name='spatial_lda', method='phenograph', phenograph_clustering_metric='manhattan', nearest_neighbors=15, label='cluster_phenograph')\n</code></pre> Source code in <code>scimap/tools/spatial_cluster.py</code> <pre><code>def spatial_cluster(\n    adata,\n    df_name='spatial_count',\n    method='kmeans',\n    k=10,\n    n_pcs=None,\n    resolution=1,\n    phenograph_clustering_metric='euclidean',\n    nearest_neighbors=30,\n    random_state=0,\n    label=None,\n    verbose=True,\n    output_dir=None,\n):\n    \"\"\"\n\n\n    Parameters:\n            adata (anndata.AnnData):\n                Annotated data matrix or path to an AnnData object, containing spatial gene expression data.\n\n            df_name (str):\n                Specifies the label of the spatial analysis results to use for clustering. Default options are 'spatial_count' and 'spatial_expression'.\n\n            method (str):\n                The clustering method to apply. Supported methods include 'kmeans', 'phenograph', and 'leiden'.\n\n            k (int):\n                Number of clusters to form when using K-Means clustering. Applies only if method='kmeans'.\n\n            n_pcs (int, optional):\n                Number of principal components to use in 'leiden' clustering. If None, all components are used.\n\n            resolution (float):\n                Controls the granularity of clustering. Higher values lead to more clusters. Applies to 'leiden' and 'phenograph'.\n\n            phenograph_clustering_metric (str):\n                The metric for defining nearest neighbors in 'phenograph' clustering. Choices include 'euclidean', 'manhattan', 'cosine', etc.\n\n            nearest_neighbors (int):\n                Number of nearest neighbors to consider in the graph construction step, for 'leiden' and 'phenograph'.\n\n            random_state (int):\n                Seed for random number generation, ensuring reproducible results.\n\n            label (str, optional):\n                Custom label for storing results in `adata.obs`. Defaults to method name (e.g., 'spatial_kmeans').\n\n            verbose (bool):\n                If set to `True`, the function will print detailed messages about its progress and the steps being executed.\n\n            output_dir (str, optional):\n                Directory path for saving output files. If None, results are not saved to disk.\n\n    Returns:\n            adata (anndata.AnnData):\n                The input `adata` object updated with clustering results in `adata.obs[label]`.\n\n    Example:\n        ```python\n        # Apply K-Means clustering\n        adata = sm.tl.spatial_cluster(adata, df_name='spatial_count', method='kmeans', k=10, label='cluster_kmeans')\n\n        # Apply Leiden clustering with specific resolution and principal components\n        adata = sm.tl.spatial_cluster(adata, df_name='spatial_expression', method='leiden', resolution=0.5, n_pcs=20, label='cluster_leiden')\n\n        # Apply Phenograph clustering with a specific metric and nearest neighbors\n        adata = sm.tl.spatial_cluster(adata, df_name='spatial_lda', method='phenograph', phenograph_clustering_metric='manhattan', nearest_neighbors=15, label='cluster_phenograph')\n        ```\n    \"\"\"\n\n    # Load the andata object\n    if isinstance(adata, str):\n        imid = str(adata.rsplit('/', 1)[-1])\n        adata = ad.read_h5ad(adata)\n    else:\n        adata = adata\n\n    # Make a copy of adata to modify\n    adata_copy = adata.copy()\n\n    # Error check\n    try:\n        adata_copy.uns[df_name]\n    except KeyError:\n        print(\n            str(\n                'Supplied df_name not found, please run `sm.tl.spatial_expression` or LDA, counts or other similar methods'\n            )\n        )\n\n    # Crete a new anndata object with the user defined spatial information\n    adata_new = ad.AnnData(adata_copy.uns[df_name].fillna(0))\n    adata_new.obs = adata_copy.obs\n\n    # Create a meaningful label name\n    if label is None:\n        label = 'spatial_' + str(method)\n\n    # Run the clustering algorithm\n    adata_new = cluster(\n        adata=adata_new,\n        method=method,\n        k=k,\n        n_pcs=n_pcs,\n        resolution=resolution,\n        phenograph_clustering_metric=phenograph_clustering_metric,\n        nearest_neighbors=nearest_neighbors,\n        use_raw=False,\n        random_state=random_state,\n        label=label,\n    )\n\n    # Get the clusters and append that to original adata object\n    result = adata_new.obs[label]\n    result = result.reindex(adata.obs.index)\n    adata.obs[label] = result\n\n    # Save data if requested\n    if output_dir is not None:\n        output_dir = pathlib.Path(output_dir)\n        output_dir.mkdir(exist_ok=True, parents=True)\n        adata.write(output_dir / imid)\n    else:\n        # Return data\n        return adata\n</code></pre>"},{"location":"Functions/tl/spatial_count/","title":"spatial_count","text":"<p>Short Description</p> <p><code>sm.tl.spatial_count</code> computes a neighborhood matrix from spatial data using categorical variables,  such as cell types, to identify local cell clusters. It offers two neighborhood definition methods:</p> <ul> <li>Radius Method: Identifies neighbors within a specified radius for each cell, allowing for  the exploration of spatial relationships based on physical proximity.</li> <li>KNN Method: Determines neighbors based on the K nearest neighbors, focusing on the closest  spatial associations irrespective of physical distance.</li> </ul> <p>The generated neighborhood matrix is stored in <code>adata.uns</code>, providing a basis for further analysis.  To uncover Recurrent Cellular Neighborhoods (RCNs) that share similar spatial patterns, users can  cluster the neighborhood matrix using the <code>spatial_cluster</code> function. This approach enables the  identification of spatially coherent cell groups, facilitating insights into the cellular  architecture of tissues.</p>"},{"location":"Functions/tl/spatial_count/#scimap.tools.spatial_count--function","title":"Function","text":""},{"location":"Functions/tl/spatial_count/#scimap.tools.spatial_count.spatial_count","title":"<code>spatial_count(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid', z_coordinate=None, phenotype='phenotype', method='radius', radius=30, knn=10, imageid='imageid', subset=None, verbose=True, label='spatial_count')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix with spatial information.</p> required <code>x_coordinate</code> <code>(str, required)</code> <p>Column name containing x-coordinates.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <code>(str, required)</code> <p>Column name containing y-coordinates.</p> <code>'Y_centroid'</code> <code>z_coordinate</code> <code>str</code> <p>Column name containing z-coordinates, for 3D spatial data.</p> <code>None</code> <code>phenotype</code> <code>(str, required)</code> <p>Column name containing phenotype or any categorical cell classification.</p> <code>'phenotype'</code> <code>method</code> <code>str</code> <p>Neighborhood definition method: 'radius' for fixed distance, 'knn' for K nearest neighbors.</p> <code>'radius'</code> <code>radius</code> <code>int</code> <p>Radius used to define neighborhoods (applicable when method='radius').</p> <code>30</code> <code>knn</code> <code>int</code> <p>Number of nearest neighbors to consider (applicable when method='knn').</p> <code>10</code> <code>imageid</code> <code>str</code> <p>Column name containing image identifiers, for analyses limited to specific images.</p> <code>'imageid'</code> <code>subset</code> <code>str</code> <p>Specific image identifier for subsetting data before analysis.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If True, prints progress and informational messages.</p> <code>True</code> <code>label</code> <code>str</code> <p>Key for storing results in <code>adata.uns</code>.</p> <code>'spatial_count'</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>Updated AnnData object with the neighborhood matrix stored in <code>adata.uns[label]</code>.</p> Example <pre><code># Analyze spatial relationships using the radius method\nadata = sm.tl.spatial_count(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                      phenotype='phenotype', method='radius', radius=50,\n                      label='neighborhood_radius50')\n\n# Explore spatial neighborhoods with KNN\nadata = sm.tl.spatial_count(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                      phenotype='phenotype', method='knn', knn=15,\n                      label='neighborhood_knn15')\n\n# 3D spatial analysis using a radius method\nadata = sm.tl.spatial_count(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                      z_coordinate='Z_centroid', phenotype='phenotype', method='radius', radius=30,\n                      label='neighborhood_3D_radius30')\n</code></pre> Source code in <code>scimap/tools/spatial_count.py</code> <pre><code>def spatial_count (adata,\n                   x_coordinate='X_centroid',\n                   y_coordinate='Y_centroid',\n                   z_coordinate=None,\n                   phenotype='phenotype',\n                   method='radius',\n                   radius=30,knn=10,\n                   imageid='imageid',\n                   subset=None,\n                   verbose=True,\n                   label='spatial_count'):\n    \"\"\"\nParameters:\n        adata (anndata.AnnData):  \n            Annotated data matrix with spatial information.\n\n        x_coordinate (str, required):  \n            Column name containing x-coordinates.\n\n        y_coordinate (str, required):  \n            Column name containing y-coordinates.\n\n        z_coordinate (str, optional):  \n            Column name containing z-coordinates, for 3D spatial data.\n\n        phenotype (str, required):  \n            Column name containing phenotype or any categorical cell classification.\n\n        method (str, optional):  \n            Neighborhood definition method: 'radius' for fixed distance, 'knn' for K nearest neighbors.\n\n        radius (int, optional):  \n            Radius used to define neighborhoods (applicable when method='radius').\n\n        knn (int, optional):  \n            Number of nearest neighbors to consider (applicable when method='knn').\n\n        imageid (str, optional):  \n            Column name containing image identifiers, for analyses limited to specific images.\n\n        subset (str, optional):  \n            Specific image identifier for subsetting data before analysis.\n\n        verbose (bool, optional):  \n            If True, prints progress and informational messages.\n\n        label (str, optional):  \n            Key for storing results in `adata.uns`.\n\nReturns:\n        adata (anndata.AnnData):  \n            Updated AnnData object with the neighborhood matrix stored in `adata.uns[label]`.\n\nExample:\n    ```python\n\n    # Analyze spatial relationships using the radius method\n    adata = sm.tl.spatial_count(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                          phenotype='phenotype', method='radius', radius=50,\n                          label='neighborhood_radius50')\n\n    # Explore spatial neighborhoods with KNN\n    adata = sm.tl.spatial_count(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                          phenotype='phenotype', method='knn', knn=15,\n                          label='neighborhood_knn15')\n\n    # 3D spatial analysis using a radius method\n    adata = sm.tl.spatial_count(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                          z_coordinate='Z_centroid', phenotype='phenotype', method='radius', radius=30,\n                          label='neighborhood_3D_radius30')\n\n    ```\n    \"\"\"\n\n    def spatial_count_internal (adata_subset,x_coordinate,y_coordinate,z_coordinate,phenotype,method,radius,knn,\n                                imageid,subset,label):\n\n        # Create a dataFrame with the necessary inforamtion\n        if z_coordinate is not None:\n            if verbose:\n                print(\"Including Z -axis\")\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'z': adata_subset.obs[z_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n        else:\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n\n\n        # Create a DataFrame with the necessary inforamtion\n        #data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n\n        # Identify neighbourhoods based on the method used\n        # a) KNN method\n        if method == 'knn':\n            if verbose:\n                print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n            if z_coordinate is not None:\n                tree = BallTree(data[['x','y','z']], leaf_size= 2)\n                ind = tree.query(data[['x','y','z']], k=knn, return_distance= False)\n            else:\n                tree = BallTree(data[['x','y']], leaf_size= 2)\n                ind = tree.query(data[['x','y']], k=knn, return_distance= False)\n            neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n            neighbours.drop(0, axis=1, inplace=True) # Remove self neighbour\n\n        # b) Local radius method\n        if method == 'radius':\n            if verbose:\n                print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n            if z_coordinate is not None:\n                kdt = BallTree(data[['x','y','z']], metric='euclidean') \n                ind = kdt.query_radius(data[['x','y','z']], r=radius, return_distance=False)\n            else:\n                kdt = BallTree(data[['x','y']], metric='euclidean') \n                ind = kdt.query_radius(data[['x','y']], r=radius, return_distance=False)\n\n            for i in range(0, len(ind)): ind[i] = np.delete(ind[i], np.argwhere(ind[i] == i))#remove self\n            neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n\n        # Map phenotype\n        phenomap = dict(zip(list(range(len(ind))), data['phenotype'])) # Used for mapping\n\n        # Loop through (all functionized methods were very slow)\n        for i in neighbours.columns:\n            neighbours[i] = neighbours[i].dropna().map(phenomap, na_action='ignore')\n\n        # Drop NA\n        #n_dropped = neighbours.dropna(how='all')\n\n        # Collapse all the neighbours into a single column\n        n = pd.DataFrame(neighbours.stack(), columns = [\"neighbour_phenotype\"])\n        n.index = n.index.get_level_values(0) # Drop the multi index\n        n = pd.DataFrame(n)\n        n['order'] = list(range(len(n)))\n\n        # Merge with real phenotype\n        n_m = n.merge(data['phenotype'], how='inner', left_index=True, right_index=True)\n        n_m['neighbourhood'] = n_m.index\n        n = n_m.sort_values(by=['order'])\n\n        # Normalize based on total cell count\n        k = n.groupby(['neighbourhood','neighbour_phenotype']).size().unstack().fillna(0)\n        k = k.div(k.sum(axis=1), axis=0)\n\n        # return the normalized neighbour occurance count\n        return k\n\n    # Subset a particular image if needed\n    if subset is not None:\n        adata_list = [adata[adata.obs[imageid] == subset]]\n    else:\n        adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n\n    # Apply function to all images and create a master dataframe\n    # Create lamda function \n    r_spatial_count_internal = lambda x: spatial_count_internal(adata_subset=x,x_coordinate=x_coordinate,\n                                                   y_coordinate=y_coordinate,\n                                                   z_coordinate=z_coordinate,\n                                                   phenotype=phenotype,\n                                                   method=method,radius=radius,knn=knn,\n                                                   imageid=imageid,subset=subset,label=label) \n    all_data = list(map(r_spatial_count_internal, adata_list)) # Apply function \n\n\n    # Merge all the results into a single dataframe    \n    result = []\n    for i in range(len(all_data)):\n        result.append(all_data[i])\n    result = pd.concat(result, join='outer')  \n\n    # Reindex the cells\n    result = result.reindex(adata.obs.index)\n    result = result.fillna(0)\n\n    # Add to adata\n    adata.uns[label] = result\n\n    # Return        \n    return adata\n</code></pre>"},{"location":"Functions/tl/spatial_distance/","title":"spatial_distance","text":"<p>Short Description</p> <p><code>sm.tl.spatial_distance</code>: This function computes the average shortest distance  between specified phenotypes or clusters, supporting analysis of both 2D and 3D spatial data.  It facilitates the quantitative assessment of spatial relationships among cellular phenotypes  or clusters within tissue sections or 3D cultures.</p>"},{"location":"Functions/tl/spatial_distance/#scimap.tools.spatial_distance--function","title":"Function","text":""},{"location":"Functions/tl/spatial_distance/#scimap.tools.spatial_distance.spatial_distance","title":"<code>spatial_distance(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid', z_coordinate=None, phenotype='phenotype', subset=None, imageid='imageid', verbose=True, label='spatial_distance')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix with spatial information.</p> required <code>x_coordinate</code> <code>(str, required)</code> <p>Column name containing x-coordinates.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <code>(str, required)</code> <p>Column name containing y-coordinates.</p> <code>'Y_centroid'</code> <code>z_coordinate</code> <code>str</code> <p>Column name containing z-coordinates, for 3D spatial data analysis.</p> <code>None</code> <code>phenotype</code> <code>(str, required)</code> <p>Column name containing the phenotype information or any categorical cell classification.</p> <code>'phenotype'</code> <code>subset</code> <code>str</code> <p>Identifier for a subset of data to analyze, typically an image ID.</p> <code>None</code> <code>imageid</code> <code>str</code> <p>Column name containing image identifiers, useful for analyzing distances within specific images.</p> <code>'imageid'</code> <code>verbose</code> <code>bool</code> <p>If True, prints progress and informational messages during the calculation.</p> <code>True</code> <code>label</code> <code>str</code> <p>Custom label for storing results in <code>adata.uns</code>.</p> <code>'spatial_distance'</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>The input <code>adata</code> object, updated with the spatial distance results stored in <code>adata.uns[label]</code>.</p> Example <pre><code># Calculate spatial distance in 2D\nadata = sm.tl.spatial_distance(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                         phenotype='cell_type', label='2D_distance')\n\n# Calculate spatial distance in 3D\nadata = sm.tl.spatial_distance(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                         z_coordinate='Z_centroid', phenotype='cell_type', label='3D_distance')\n\n# Calculate spatial distance for a specific image subset\nadata = sm.tl.spatial_distance(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                         phenotype='cell_type', imageid='image_id', subset='image01',\n                         label='distance_image01')\n</code></pre> Source code in <code>scimap/tools/spatial_distance.py</code> <pre><code>def spatial_distance (adata,\n                      x_coordinate='X_centroid',\n                      y_coordinate='Y_centroid',\n                      z_coordinate=None,\n                      phenotype='phenotype',\n                      subset=None,\n                      imageid='imageid',\n                      verbose=True,\n                      label='spatial_distance'):\n    \"\"\"\n\nParameters:\n        adata (anndata.AnnData):  \n            Annotated data matrix with spatial information.\n\n        x_coordinate (str, required):  \n            Column name containing x-coordinates.\n\n        y_coordinate (str, required):  \n            Column name containing y-coordinates.\n\n        z_coordinate (str, optional):  \n            Column name containing z-coordinates, for 3D spatial data analysis.\n\n        phenotype (str, required):  \n            Column name containing the phenotype information or any categorical cell classification.\n\n        subset (str, optional):  \n            Identifier for a subset of data to analyze, typically an image ID.\n\n        imageid (str, optional):  \n            Column name containing image identifiers, useful for analyzing distances within specific images.\n\n        verbose (bool, optional):  \n            If True, prints progress and informational messages during the calculation.\n\n        label (str, optional):  \n            Custom label for storing results in `adata.uns`.\n\nReturns:\n        adata (anndata.AnnData):  \n            The input `adata` object, updated with the spatial distance results stored in `adata.uns[label]`.\n\nExample:\n    ```python\n\n    # Calculate spatial distance in 2D\n    adata = sm.tl.spatial_distance(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                             phenotype='cell_type', label='2D_distance')\n\n    # Calculate spatial distance in 3D\n    adata = sm.tl.spatial_distance(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                             z_coordinate='Z_centroid', phenotype='cell_type', label='3D_distance')\n\n    # Calculate spatial distance for a specific image subset\n    adata = sm.tl.spatial_distance(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                             phenotype='cell_type', imageid='image_id', subset='image01',\n                             label='distance_image01')\n\n    ```\n    \"\"\"\n\n\n    def spatial_distance_internal (adata_subset,x_coordinate,y_coordinate,z_coordinate,\n                                   phenotype,subset,imageid,label):\n\n        if verbose:\n            print(\"Processing Image: \" + str(adata_subset.obs[imageid].unique()[0]))\n        # Create a dataFrame with the necessary inforamtion\n        if z_coordinate is not None:\n            if verbose:\n                print(\"Including Z -axis\")\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'z': adata_subset.obs[z_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n        else:\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n\n        # Function to identify shortest distance for each phenotype of interest\n        def distance (pheno):\n            pheno_interest = data[data['phenotype'] == pheno]\n            # Build the ball-tree for search space\n            tree = BallTree(pheno_interest[['x','y']], metric='euclidean') \n            # Calculate shortest distance (if statement to account for K)\n            if len(pheno_interest) &gt; 1:\n                dist, ind = tree.query(data[['x','y']], k=2, return_distance= True)\n                dist = pd.DataFrame(dist)\n                dist.loc[dist[0] == 0, 0]  = dist[1]\n                dist = dist[0].values\n            else:\n                dist, ind = tree.query(data[['x','y']], k=1, return_distance= True)\n                dist = list(itertools.chain.from_iterable(dist))\n            return dist\n\n        # Run in parallel for all phenotypes\n        phenotype_list = list(data['phenotype'].unique())\n        # Apply function\n        final_dist = Parallel(n_jobs=-1)(delayed(distance)(pheno=i) for i in phenotype_list)     \n        final_dist = pd.DataFrame(final_dist, index = phenotype_list, columns = data.index).T\n\n        return final_dist\n\n    # subset a particular subset of cells if the user wants else break the adata into list of anndata objects\n    if subset is not None:\n        adata_list = [adata[adata.obs[imageid].isin(subset)]]\n    else:\n        adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n\n    # Apply function to all images and create a master dataframe\n    # Create lamda function \n    r_spatial_distance_internal = lambda x: spatial_distance_internal (adata_subset=x,\n                                                                       x_coordinate=x_coordinate,y_coordinate=y_coordinate, z_coordinate=z_coordinate,\n                                                                       phenotype=phenotype,subset=subset,imageid=imageid,label=label) \n    all_data = list(map(r_spatial_distance_internal, adata_list)) # Apply function \n\n    # Merge all the results into a single dataframe    \n    result = []\n    for i in range(len(all_data)):\n        result.append(all_data[i])\n    result = pd.concat(result, join='outer')  \n\n\n    # Add to anndata\n    adata.uns[label] = result\n\n    # return\n    return adata\n</code></pre>"},{"location":"Functions/tl/spatial_expression/","title":"spatial_expression","text":"<p>Short Description</p> <p><code>sm.tl.spatial_expression</code>: This function generates a neighborhood weighted matrix from spatial data,  integrating expression values to assess local cellular environments. </p> <p>It employs two approaches for neighborhood definition:</p> <ul> <li>Radius Method: Identifies neighbors within a specified radius, enabling analyses based on physical proximity.</li> <li>KNN Method: Determines neighbors based on the K nearest neighbors, focusing on immediate spatial relationships.</li> </ul> <p>The output, a proportion matrix reflecting local expression patterns, is stored in <code>adata.uns</code>.  This matrix can be further analyzed using the <code>spatial_cluster</code> function to identify Recurrent  Cellular Neighborhoods (RCNs), facilitating the exploration of spatial expression dynamics and  neighborhood-specific gene expression patterns.</p>"},{"location":"Functions/tl/spatial_expression/#scimap.tools.spatial_expression--function","title":"Function","text":""},{"location":"Functions/tl/spatial_expression/#scimap.tools.spatial_expression.spatial_expression","title":"<code>spatial_expression(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid', z_coordinate=None, method='radius', radius=30, knn=10, imageid='imageid', use_raw=True, log=True, subset=None, label='spatial_expression', verbose=True, output_dir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>The AnnData object, containing spatial gene expression data.</p> required <code>x_coordinate</code> <code>(str, required)</code> <p>Column name in <code>adata</code> for the x-coordinates.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <code>(str, required)</code> <p>Column name in <code>adata</code> for the y-coordinates.</p> <code>'Y_centroid'</code> <code>z_coordinate</code> <code>str</code> <p>Column name in <code>adata</code> for the z-coordinates, for 3D spatial data analysis.</p> <code>None</code> <code>method</code> <code>str</code> <p>Method for defining neighborhoods: 'radius' for fixed distance, 'knn' for K nearest neighbors.</p> <code>'radius'</code> <code>radius</code> <code>int</code> <p>Radius for defining local neighborhoods when using the 'radius' method.</p> <code>30</code> <code>knn</code> <code>int</code> <p>Number of nearest neighbors to consider when using the 'knn' method.</p> <code>10</code> <code>imageid</code> <code>str</code> <p>Column name in <code>adata</code> for image identifiers, useful for analyses within specific images.</p> <code>'imageid'</code> <code>use_raw</code> <code>bool</code> <p>Whether to use raw or processed data for calculation. Log transformation is applied if <code>log=True</code>.</p> <code>True</code> <code>log</code> <code>bool</code> <p>Apply log transformation to the data (requires <code>use_raw=True</code>).</p> <code>True</code> <code>subset</code> <code>str</code> <p>Identifier for a subset of data, typically an image ID, for targeted analysis.</p> <code>None</code> <code>label</code> <code>str</code> <p>Custom label for storing the weighted matrix in <code>adata.uns</code>.</p> <code>'spatial_expression'</code> <code>verbose</code> <code>bool</code> <p>If True, enables progress and informational messages.</p> <code>True</code> <code>output_dir</code> <code>str</code> <p>Directory path for saving output files.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>The input <code>adata</code> object, updated with the spatial expression results in <code>adata.uns[label]</code>.</p> Example <pre><code># Calculate spatial expression using a 30-pixel radius\nadata = sm.tl.spatial_expression(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                           method='radius', radius=30, \n                           label='expression_radius_30')\n\n# Calculate spatial expression using 10 nearest neighbors\nadata = sm.tl.spatial_expression(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                           method='knn', knn=10, use_raw=True,\n                           label='expression_knn_10')\n\n# Analyze spatial expression within a specific image using radius method\nadata = sm.tl.spatial_expression(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                           method='radius', radius=50, imageid='imageid', subset='specific_image',\n                           label='expression_specific_image')\n</code></pre> Source code in <code>scimap/tools/spatial_expression.py</code> <pre><code>def spatial_expression (adata, \n                        x_coordinate='X_centroid',\n                        y_coordinate='Y_centroid',\n                        z_coordinate=None,\n                        method='radius', \n                        radius=30, \n                        knn=10, \n                        imageid='imageid', \n                        use_raw=True, \n                        log=True, \n                        subset=None,\n                        label='spatial_expression',\n                        verbose=True,\n                        output_dir=None):\n    \"\"\"\nParameters:\n        adata (anndata.AnnData):  \n            The AnnData object, containing spatial gene expression data.\n\n        x_coordinate (str, required):  \n            Column name in `adata` for the x-coordinates.\n\n        y_coordinate (str, required):  \n            Column name in `adata` for the y-coordinates.\n\n        z_coordinate (str, optional):  \n            Column name in `adata` for the z-coordinates, for 3D spatial data analysis.\n\n        method (str, optional):  \n            Method for defining neighborhoods: 'radius' for fixed distance, 'knn' for K nearest neighbors.\n\n        radius (int, optional):  \n            Radius for defining local neighborhoods when using the 'radius' method.\n\n        knn (int, optional):  \n            Number of nearest neighbors to consider when using the 'knn' method.\n\n        imageid (str, optional):  \n            Column name in `adata` for image identifiers, useful for analyses within specific images.\n\n        use_raw (bool, optional):  \n            Whether to use raw or processed data for calculation. Log transformation is applied if `log=True`.\n\n        log (bool, optional):  \n            Apply log transformation to the data (requires `use_raw=True`).\n\n        subset (str, optional):  \n            Identifier for a subset of data, typically an image ID, for targeted analysis.\n\n        label (str, optional):  \n            Custom label for storing the weighted matrix in `adata.uns`.\n\n        verbose (bool, optional):  \n            If True, enables progress and informational messages.\n\n        output_dir (str, optional):  \n            Directory path for saving output files.\n\nReturns:\n        adata (anndata.AnnData):  \n            The input `adata` object, updated with the spatial expression results in `adata.uns[label]`.\n\nExample:\n        ```python\n\n        # Calculate spatial expression using a 30-pixel radius\n        adata = sm.tl.spatial_expression(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                                   method='radius', radius=30, \n                                   label='expression_radius_30')\n\n        # Calculate spatial expression using 10 nearest neighbors\n        adata = sm.tl.spatial_expression(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                                   method='knn', knn=10, use_raw=True,\n                                   label='expression_knn_10')\n\n        # Analyze spatial expression within a specific image using radius method\n        adata = sm.tl.spatial_expression(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                                   method='radius', radius=50, imageid='imageid', subset='specific_image',\n                                   label='expression_specific_image')\n\n        ```\n    \"\"\"\n\n    # Load the andata object    \n    if isinstance(adata, str):\n        imid = str(adata.rsplit('/', 1)[-1])\n        adata = anndata.read(adata)\n    else:\n        adata = adata\n\n\n    # Error statements\n    if use_raw is False:\n        if all(adata.X[0] &lt; 1) is False:\n            raise ValueError('Please run `sm.pp.rescale` first if you wish to use `use_raw = False`')\n\n\n    def spatial_expression_internal (adata_subset, x_coordinate, y_coordinate,z_coordinate,log,\n                                     method, radius, knn, imageid, use_raw, subset,label):\n\n\n        # Create a dataFrame with the necessary inforamtion\n        if z_coordinate is not None:\n            if verbose:\n                print(\"Including Z -axis\")\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'z': adata_subset.obs[z_coordinate] })\n        else:\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate] })\n\n\n        # Create a DataFrame with the necessary inforamtion\n        #data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate]})\n\n        # Identify neighbourhoods based on the method used\n\n        # a) KNN method\n        if method == 'knn':\n            if verbose:\n                print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n            if z_coordinate is not None:\n                tree = BallTree(data, leaf_size= 2)\n                dist, ind = tree.query(data, k=knn, return_distance= True)\n            else:\n                tree = BallTree(data, leaf_size= 2)\n                dist, ind = tree.query(data, k=knn, return_distance= True)\n\n        # b) Local radius method\n        if method == 'radius':\n            if verbose:\n                print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n            if z_coordinate is not None:\n                kdt = BallTree(data, metric='euclidean') \n                ind, dist = kdt.query_radius(data, r=radius, return_distance=True)\n            else:\n                kdt = BallTree(data, metric='euclidean') \n                ind, dist = kdt.query_radius(data, r=radius, return_distance=True)\n\n# =============================================================================\n#         # a) KNN method\n#         if method == 'knn':\n#             if verbose:\n#                 print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n#             tree = BallTree(data, leaf_size= 2)\n#             dist, ind = tree.query(data, k=knn, return_distance= True)\n# \n#         # b) Local radius method\n#         if method == 'radius':\n#             if verbose:\n#                 print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n#             kdt = BallTree(data, metric='euclidean')\n#             ind, dist = kdt.query_radius(data, r=radius, return_distance= True)\n#             \n# =============================================================================\n\n        # Normalize range (0-1) and account for total number of cells \n        d = scipy.sparse.lil_matrix((len(data), len(data)))\n        for row, (columns, values) in enumerate(zip(ind, dist)):\n            # Drop self-distance element.\n            idx = columns != row\n            columns = columns[idx]\n            values = values[idx]\n            if len(values) == 1:\n                values = [1.0]\n            elif len(values) &gt; 1:\n                # Normalize distances.\n                values = (values.max() - values) / (values.max() - values.min())\n                values /= values.sum()\n            # Assign row to matrix.\n            d[row, columns] = values\n\n        # convert to csr sparse matrix\n        wn_matrix_sparse = d.tocsr()\n\n\n        # Calculation of spatial lag\n        if use_raw==True:\n            if log is True:\n                spatial_lag = pd.DataFrame(wn_matrix_sparse * np.log1p(adata_subset.raw.X), columns = adata_subset.var.index, index=adata_subset.obs.index)\n            else:\n                spatial_lag = pd.DataFrame(wn_matrix_sparse * adata_subset.raw.X, columns = adata_subset.var.index, index=adata_subset.obs.index)\n        else:\n            spatial_lag = pd.DataFrame(wn_matrix_sparse * adata_subset.X, columns = adata_subset.var.index, index=adata_subset.obs.index)\n\n        # return value\n        return spatial_lag\n\n    # Subset a particular image if needed\n    if subset is not None:\n        adata_list = [adata[adata.obs[imageid] == subset]]\n    else:\n        adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n\n    # Apply function to all images and create a master dataframe\n    # Create lamda function \n    r_spatial_expression_internal = lambda x: spatial_expression_internal(adata_subset=x, \n                                                                x_coordinate=x_coordinate, \n                                                                y_coordinate=y_coordinate, \n                                                                z_coordinate=z_coordinate,\n                                                                method=method, radius=radius, \n                                                                knn=knn, imageid=imageid, \n                                                                use_raw=use_raw, subset=subset,\n                                                                log=log,\n                                                                label=label) \n    all_data = list(map(r_spatial_expression_internal, adata_list)) # Apply function \n\n    # Merge all the results into a single dataframe    \n    result = []\n    for i in range(len(all_data)):\n        result.append(all_data[i])\n    result = pd.concat(result, join='outer')  \n\n    # Reindex the cells\n    result = result.fillna(0)\n    result = result.reindex(adata.obs.index)\n\n    # Add to adata\n    adata.uns[label] = result\n\n    # Save data if requested\n    if output_dir is not None:\n        output_dir = pathlib.Path(output_dir)\n        output_dir.mkdir(exist_ok=True, parents=True)\n        adata.write(output_dir / imid)\n    else:    \n        # Return data\n        return adata\n</code></pre>"},{"location":"Functions/tl/spatial_interaction/","title":"spatial_interaction","text":"<p>Short Description</p> <p><code>sm.tl.spatial_interaction</code>: This function quantifies the spatial interactions  between cell types, assessing their co-localization beyond random chance, with  support for both 2D and 3D datasets. By comparing observed adjacency frequencies  to a random distribution, it helps uncover significant cellular partnerships  within tissue contexts.</p>"},{"location":"Functions/tl/spatial_interaction/#scimap.tools.spatial_interaction--function","title":"Function","text":""},{"location":"Functions/tl/spatial_interaction/#scimap.tools.spatial_interaction.spatial_interaction","title":"<code>spatial_interaction(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid', z_coordinate=None, phenotype='phenotype', method='radius', radius=30, knn=10, permutation=1000, imageid='imageid', subset=None, pval_method='zscore', verbose=True, label='spatial_interaction')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix or path to an AnnData object, containing spatial gene expression data.</p> required <code>x_coordinate</code> <code>(str, required)</code> <p>Column name in <code>adata</code> for the x-coordinates.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <code>(str, required)</code> <p>Column name in <code>adata</code> for the y-coordinates.</p> <code>'Y_centroid'</code> <code>z_coordinate</code> <code>str</code> <p>Column name in <code>adata</code> for the z-coordinates, for 3D spatial data analysis.</p> <code>None</code> <code>phenotype</code> <code>(str, required)</code> <p>Column name in <code>adata</code> indicating cell phenotype or any categorical cell classification.</p> <code>'phenotype'</code> <code>method</code> <code>str</code> <p>Method to define neighborhoods: 'radius' for fixed distance, 'knn' for K nearest neighbors.</p> <code>'radius'</code> <code>radius</code> <code>int</code> <p>Radius for neighborhood definition (applies when method='radius').</p> <code>30</code> <code>knn</code> <code>int</code> <p>Number of nearest neighbors to consider (applies when method='knn').</p> <code>10</code> <code>permutation</code> <code>int</code> <p>Number of permutations for p-value calculation.</p> <code>1000</code> <code>imageid</code> <code>(str, required)</code> <p>Column name in <code>adata</code> for image identifiers, useful for analysis within specific images.</p> <code>'imageid'</code> <code>subset</code> <code>str</code> <p>Specific image identifier for targeted analysis.</p> <code>None</code> <code>pval_method</code> <code>str</code> <p>Method for p-value calculation: 'abs' for absolute difference, 'zscore' for z-score based significance.</p> <code>'zscore'</code> <code>verbose</code> <code>bool</code> <p>If set to <code>True</code>, the function will print detailed messages about its progress and the steps being executed.</p> <code>True</code> <code>label</code> <code>str</code> <p>Custom label for storing results in <code>adata.obs</code>.</p> <code>'spatial_interaction'</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>Updated <code>adata</code> object with spatial interaction results in <code>adata.obs[label]</code>.</p> Example <pre><code># Radius method for 2D data with absolute p-value calculation\nadata = sm.tl.spatial_interaction(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                            method='radius', radius=50, permutation=1000, pval_method='abs',\n                            label='interaction_radius_abs')\n\n# KNN method for 2D data with z-score based p-value calculation\nadata = sm.tl.spatial_interaction(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                            method='knn', knn=15, permutation=1000, pval_method='zscore',\n                            label='interaction_knn_zscore')\n\n# Radius method for 3D data analysis\nadata = sm.tl.spatial_interaction(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                            z_coordinate='Z_centroid', method='radius', radius=60, permutation=1000,\n                            pval_method='zscore', label='interaction_3D_zscore')\n</code></pre> Source code in <code>scimap/tools/spatial_interaction.py</code> <pre><code>def spatial_interaction (adata,\n                         x_coordinate='X_centroid',\n                         y_coordinate='Y_centroid',\n                         z_coordinate=None,\n                         phenotype='phenotype',\n                         method='radius', \n                         radius=30, \n                         knn=10,\n                         permutation=1000,\n                         imageid='imageid',\n                         subset=None,\n                         pval_method='zscore',\n                         verbose=True,\n                         label='spatial_interaction'):\n    \"\"\"\nParameters:\n        adata (anndata.AnnData):  \n            Annotated data matrix or path to an AnnData object, containing spatial gene expression data.\n\n        x_coordinate (str, required):  \n            Column name in `adata` for the x-coordinates.\n\n        y_coordinate (str, required):  \n            Column name in `adata` for the y-coordinates.\n\n        z_coordinate (str, optional):  \n            Column name in `adata` for the z-coordinates, for 3D spatial data analysis.\n\n        phenotype (str, required):  \n            Column name in `adata` indicating cell phenotype or any categorical cell classification.\n\n        method (str, optional):  \n            Method to define neighborhoods: 'radius' for fixed distance, 'knn' for K nearest neighbors.\n\n        radius (int, optional):  \n            Radius for neighborhood definition (applies when method='radius').\n\n        knn (int, optional):  \n            Number of nearest neighbors to consider (applies when method='knn').\n\n        permutation (int, optional):  \n            Number of permutations for p-value calculation.\n\n        imageid (str, required):  \n            Column name in `adata` for image identifiers, useful for analysis within specific images.\n\n        subset (str, optional):  \n            Specific image identifier for targeted analysis.\n\n        pval_method (str, optional):  \n            Method for p-value calculation: 'abs' for absolute difference, 'zscore' for z-score based significance.\n\n        verbose (bool):  \n            If set to `True`, the function will print detailed messages about its progress and the steps being executed.\n\n        label (str, optional):  \n            Custom label for storing results in `adata.obs`.\n\nReturns:\n        adata (anndata.AnnData):  \n            Updated `adata` object with spatial interaction results in `adata.obs[label]`.\n\nExample:\n        ```python\n\n        # Radius method for 2D data with absolute p-value calculation\n        adata = sm.tl.spatial_interaction(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                                    method='radius', radius=50, permutation=1000, pval_method='abs',\n                                    label='interaction_radius_abs')\n\n        # KNN method for 2D data with z-score based p-value calculation\n        adata = sm.tl.spatial_interaction(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                                    method='knn', knn=15, permutation=1000, pval_method='zscore',\n                                    label='interaction_knn_zscore')\n\n        # Radius method for 3D data analysis\n        adata = sm.tl.spatial_interaction(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                                    z_coordinate='Z_centroid', method='radius', radius=60, permutation=1000,\n                                    pval_method='zscore', label='interaction_3D_zscore')\n\n        ```\n    \"\"\"\n\n\n    def spatial_interaction_internal (adata_subset,x_coordinate,y_coordinate,\n                                      z_coordinate,\n                                      phenotype,\n                                      method, radius, knn,\n                                      permutation, \n                                      imageid,subset,\n                                      pval_method):\n        if verbose:\n            print(\"Processing Image: \" + str(adata_subset.obs[imageid].unique()))\n\n        # Create a dataFrame with the necessary inforamtion\n        if z_coordinate is not None:\n            if verbose:\n                print(\"Including Z -axis\")\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'z': adata_subset.obs[z_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n        else:\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n\n\n        # Identify neighbourhoods based on the method used\n        # a) KNN method\n        if method == 'knn':\n            if verbose:\n                print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n            if z_coordinate is not None:\n                tree = BallTree(data[['x','y','z']], leaf_size= 2)\n                ind = tree.query(data[['x','y','z']], k=knn, return_distance= False)\n            else:\n                tree = BallTree(data[['x','y']], leaf_size= 2)\n                ind = tree.query(data[['x','y']], k=knn, return_distance= False)\n            neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n            neighbours.drop(0, axis=1, inplace=True) # Remove self neighbour\n\n        # b) Local radius method\n        if method == 'radius':\n            if verbose:\n                print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n            if z_coordinate is not None:\n                kdt = BallTree(data[['x','y','z']], metric='euclidean') \n                ind = kdt.query_radius(data[['x','y','z']], r=radius, return_distance=False)\n            else:\n                kdt = BallTree(data[['x','y']], metric='euclidean') \n                ind = kdt.query_radius(data[['x','y']], r=radius, return_distance=False)\n\n            for i in range(0, len(ind)): ind[i] = np.delete(ind[i], np.argwhere(ind[i] == i))#remove self\n            neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n\n        # Map Phenotypes to Neighbours\n        # Loop through (all functionized methods were very slow)\n        phenomap = dict(zip(list(range(len(ind))), data['phenotype'])) # Used for mapping\n        if verbose:\n            print(\"Mapping phenotype to neighbors\")\n        for i in neighbours.columns:\n            neighbours[i] = neighbours[i].dropna().map(phenomap, na_action='ignore')\n\n        # Drop NA\n        neighbours = neighbours.dropna(how='all')\n\n        # Collapse all the neighbours into a single column\n        n = pd.DataFrame(neighbours.stack(), columns = [\"neighbour_phenotype\"])\n        n.index = n.index.get_level_values(0) # Drop the multi index\n\n        # Merge with real phenotype\n        n = n.merge(data['phenotype'], how='inner', left_index=True, right_index=True)\n\n        # Permutation\n        if verbose:\n            print('Performing '+ str(permutation) + ' permutations')\n\n        def permutation_pval (data):\n            data = data.assign(neighbour_phenotype=np.random.permutation(data['neighbour_phenotype']))\n            #data['neighbour_phenotype'] = np.random.permutation(data['neighbour_phenotype'])\n            data_freq = data.groupby(['phenotype','neighbour_phenotype'],observed=False).size().unstack()\n            data_freq = data_freq.fillna(0).stack().values \n            return data_freq\n\n        # Apply function\n        final_scores = Parallel(n_jobs=-1)(delayed(permutation_pval)(data=n) for i in range(permutation)) \n        perm = pd.DataFrame(final_scores).T\n\n        # Consolidate the permutation results\n        if verbose:\n            print('Consolidating the permutation results')\n        # Calculate P value\n        # real\n        n_freq = n.groupby(['phenotype','neighbour_phenotype'],observed=False).size().unstack().fillna(0).stack() \n        # permutation\n        mean = perm.mean(axis=1)\n        std = perm.std(axis=1)\n        # P-value calculation\n        if pval_method == 'abs':\n            # real value - prem value / no of perm \n            p_values = abs(n_freq.values - mean) / (permutation+1)\n            p_values = p_values[~np.isnan(p_values)].values\n        if pval_method == 'zscore':\n            z_scores = (n_freq.values - mean) / std        \n            z_scores[np.isnan(z_scores)] = 0\n            p_values = scipy.stats.norm.sf(abs(z_scores))*2\n            p_values = p_values[~np.isnan(p_values)]\n\n        # Compute Direction of interaction (interaction or avoidance)\n        direction = ((n_freq.values - mean) / abs(n_freq.values - mean)).fillna(1)\n\n        # Normalize based on total cell count\n        k = n.groupby(['phenotype','neighbour_phenotype'],observed=False).size().unstack().fillna(0)\n        # add neighbour phenotype that are not present to make k a square matrix\n        columns_to_add = dict.fromkeys(np.setdiff1d(k.index,k.columns), 0)\n        k = k.assign(**columns_to_add)\n\n        total_cell_count = data['phenotype'].value_counts()\n        total_cell_count = total_cell_count[k.columns].values # keep only cell types that are present in the column of k\n        # total_cell_count = total_cell_count.reindex(k.columns).values # replaced by above\n        k_max = k.div(total_cell_count, axis = 0)\n        k_max = k_max.div(k_max.max(axis=1), axis=0).stack()\n\n        # DataFrame with the neighbour frequency and P values\n        count = (k_max.values * direction).values # adding directionallity to interaction\n        neighbours = pd.DataFrame({'count': count,'p_val': p_values}, index = k_max.index)\n        #neighbours.loc[neighbours[neighbours['p_val'] &gt; p_val].index,'count'] = np.NaN\n        #del neighbours['p_val']\n        neighbours.columns = [adata_subset.obs[imageid].unique()[0], 'pvalue_' + str(adata_subset.obs[imageid].unique()[0])]\n        neighbours = neighbours.reset_index()\n        #neighbours = neighbours['count'].unstack()\n\n        # return\n        return neighbours\n\n\n    # subset a particular subset of cells if the user wants else break the adata into list of anndata objects\n    if subset is not None:\n        adata_list = [adata[adata.obs[imageid] == subset]]\n    else:\n        adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n\n\n    # Apply function to all images and create a master dataframe\n    # Create lamda function \n    r_spatial_interaction_internal = lambda x: spatial_interaction_internal (adata_subset=x, x_coordinate=x_coordinate, y_coordinate=y_coordinate, \n                                                                             z_coordinate=z_coordinate, phenotype=phenotype, method=method,  radius=radius, knn=knn, permutation=permutation, imageid=imageid,subset=subset,pval_method=pval_method) \n    all_data = list(map(r_spatial_interaction_internal, adata_list)) # Apply function \n\n\n    # Merge all the results into a single dataframe    \n    df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['phenotype', 'neighbour_phenotype'], how='outer'), all_data)\n\n\n    # Add to anndata\n    adata.uns[label] = df_merged\n\n    # return\n    return adata\n</code></pre>"},{"location":"Functions/tl/spatial_lda/","title":"spatial_lda","text":"<p>Short Description</p> <p><code>sm.tl.spatial_lda</code>: This function constructs a neighborhood matrix based on  user-specified categorical variables, such as cell types,  and applies Latent Dirichlet Allocation (LDA) to model the latent space of  cellular distributions. It returns weights that describe the spatial  organization of cells, facilitating the identification of Recurrent Cellular Neighborhoods (RCNs). </p> <p>The <code>sm.tl.spatial_cluster</code> function should be utilized to cluster these  latent vectors into RCNs, offering insights into the spatial dynamics  of cellular environments.</p>"},{"location":"Functions/tl/spatial_lda/#scimap.tools.spatial_lda--function","title":"Function","text":""},{"location":"Functions/tl/spatial_lda/#scimap.tools.spatial_lda.spatial_lda","title":"<code>spatial_lda(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid', z_coordinate=None, phenotype='phenotype', method='radius', radius=30, knn=10, imageid='imageid', num_motifs=10, random_state=0, subset=None, verbose=True, label='spatial_lda', **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>AnnData object, containing spatial gene expression data.</p> required <code>x_coordinate</code> <code>(str, required)</code> <p>Column name in <code>adata</code> denoting the x-coordinates.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <code>(str, required)</code> <p>Column name in <code>adata</code> denoting the y-coordinates.</p> <code>'Y_centroid'</code> <code>z_coordinate</code> <code>str</code> <p>Column name in <code>adata</code> for z-coordinates, for 3D spatial data.</p> <code>None</code> <code>phenotype</code> <code>(str, required)</code> <p>Column name in <code>adata</code> indicating cell phenotype or classification.</p> <code>'phenotype'</code> <code>method</code> <code>str</code> <p>Neighborhood definition method: 'radius' for fixed distance, 'knn' for K nearest neighbors.</p> <code>'radius'</code> <code>radius</code> <code>int</code> <p>Radius defining local neighborhoods (when method='radius').</p> <code>30</code> <code>knn</code> <code>int</code> <p>Number of nearest neighbors for neighborhood definition (when method='knn').</p> <code>10</code> <code>imageid</code> <code>str</code> <p>Column name in <code>adata</code> specifying image identifiers, for analyses within specific images.</p> <code>'imageid'</code> <code>num_motifs</code> <code>int</code> <p>Number of latent motifs to identify.</p> <code>10</code> <code>random_state</code> <code>int</code> <p>Seed for random number generator, ensuring reproducibility.</p> <code>0</code> <code>subset</code> <code>str</code> <p>Specific image identifier for targeted analysis.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If True, enables progress and informational messages.</p> <code>True</code> <code>label</code> <code>str</code> <p>Custom label for storing results in <code>adata.uns</code>.</p> <code>'spatial_lda'</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>The input <code>adata</code> object, updated with spatial LDA results in <code>adata.uns[label]</code>.</p> Example <pre><code># Analyze spatial motifs using the radius method \nadata = sm.tl.spatial_lda(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                    method='radius', radius=50, num_motifs=10,\n                    label='lda_radius_50')\n\n# KNN method with specific image subset\nadata = sm.tl.spatial_lda(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                    method='knn', knn=15, num_motifs=15, subset='image_01',\n                    label='lda_knn_15_image_01')\n\n# 3D spatial data analysis using the radius method\nadata = am.tl.spatial_lda(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid', z_coordinate='Z_centroid',\n                    method='radius', radius=100, num_motifs=20, label='lda_3D_radius_100')\n</code></pre> Source code in <code>scimap/tools/spatial_lda.py</code> <pre><code>def spatial_lda (adata, \n                 x_coordinate='X_centroid',\n                 y_coordinate='Y_centroid',\n                 z_coordinate= None,\n                 phenotype='phenotype', \n                 method='radius', \n                 radius=30, \n                 knn=10,\n                 imageid='imageid',\n                 num_motifs=10, \n                 random_state=0, \n                 subset=None,\n                 verbose=True,\n                 label='spatial_lda',**kwargs):\n    \"\"\"\nParameters:\n        adata (anndata.AnnData):  \n            AnnData object, containing spatial gene expression data.\n\n        x_coordinate (str, required):  \n            Column name in `adata` denoting the x-coordinates.\n\n        y_coordinate (str, required):  \n            Column name in `adata` denoting the y-coordinates.\n\n        z_coordinate (str, optional):  \n            Column name in `adata` for z-coordinates, for 3D spatial data.\n\n        phenotype (str, required):  \n            Column name in `adata` indicating cell phenotype or classification.\n\n        method (str, optional):  \n            Neighborhood definition method: 'radius' for fixed distance, 'knn' for K nearest neighbors.\n\n        radius (int, optional):  \n            Radius defining local neighborhoods (when method='radius').\n\n        knn (int, optional):  \n            Number of nearest neighbors for neighborhood definition (when method='knn').\n\n        imageid (str, optional):  \n            Column name in `adata` specifying image identifiers, for analyses within specific images.\n\n        num_motifs (int, optional):  \n            Number of latent motifs to identify.\n\n        random_state (int, optional):  \n            Seed for random number generator, ensuring reproducibility.\n\n        subset (str, optional):  \n            Specific image identifier for targeted analysis.\n\n        verbose (bool, optional):  \n            If True, enables progress and informational messages.\n\n        label (str, optional):  \n            Custom label for storing results in `adata.uns`.\n\nReturns:\n        adata (anndata.AnnData):  \n            The input `adata` object, updated with spatial LDA results in `adata.uns[label]`.\n\nExample:\n        ```python\n\n        # Analyze spatial motifs using the radius method \n        adata = sm.tl.spatial_lda(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                            method='radius', radius=50, num_motifs=10,\n                            label='lda_radius_50')\n\n        # KNN method with specific image subset\n        adata = sm.tl.spatial_lda(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid',\n                            method='knn', knn=15, num_motifs=15, subset='image_01',\n                            label='lda_knn_15_image_01')\n\n        # 3D spatial data analysis using the radius method\n        adata = am.tl.spatial_lda(adata, x_coordinate='X_centroid', y_coordinate='Y_centroid', z_coordinate='Z_centroid',\n                            method='radius', radius=100, num_motifs=20, label='lda_3D_radius_100')\n        ```\n\n    \"\"\"\n\n\n    # Function\n    def spatial_lda_internal (adata_subset, x_coordinate,y_coordinate,z_coordinate,phenotype, \n                              method, radius, knn, imageid):\n\n        # Print which image is being processed\n        if verbose:\n            print('Processing: ' + str(np.unique(adata_subset.obs[imageid])))\n\n\n        # Create a dataFrame with the necessary inforamtion\n        if z_coordinate is not None:\n            if verbose:\n                print(\"Including Z -axis\")\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'z': adata_subset.obs[z_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n        else:\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n\n\n        # Create a DataFrame with the necessary inforamtion\n        #data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n\n        # Identify neighbourhoods based on the method used\n        # a) KNN method\n\n        if method == 'knn':\n            if verbose:\n                print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n            if z_coordinate is not None:\n                tree = BallTree(data[['x','y','z']], leaf_size= 2)\n                ind = tree.query(data[['x','y','z']], k=knn, return_distance= False)\n            else:\n                tree = BallTree(data[['x','y']], leaf_size= 2)\n                ind = tree.query(data[['x','y']], k=knn, return_distance= False)\n            ind = list(np.array(item) for item in ind)\n\n\n        # b) Local radius method\n        if method == 'radius':\n            if verbose:\n                print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n            if z_coordinate is not None:\n                kdt = BallTree(data[['x','y','z']], metric='euclidean') \n                ind = kdt.query_radius(data[['x','y','z']], r=radius, return_distance=False)\n            else:\n                kdt = BallTree(data[['x','y']], metric='euclidean') \n                ind = kdt.query_radius(data[['x','y']], r=radius, return_distance=False)\n\n\n# =============================================================================\n#         if method == 'knn':\n#             if verbose:\n#                 print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n#             tree = BallTree(data[['x','y']], leaf_size= 2)\n#             ind = tree.query(data[['x','y']], k=knn, return_distance= False)\n#             #ind = [np.array(x) for x in ind]\n#             ind = list(np.array(item) for item in ind)\n#             \n#         # b) Local radius method\n#         if method == 'radius':\n#             if verbose:\n#                 print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n#             kdt = BallTree(data[['x','y']], leaf_size= 2) \n#             ind = kdt.query_radius(data[['x','y']], r=radius, return_distance=False)\n#             \n# =============================================================================\n\n        # Map phenotype\n        phenomap = dict(zip(list(range(len(ind))), data['phenotype'])) # Used for mapping\n        for i in range(len(ind)):\n            ind[i] = [phenomap[letter] for letter in ind[i]]\n\n        # return\n        return ind\n\n    # Subset a particular image if needed\n    if subset is not None:\n        adata_list = [adata[adata.obs[imageid] == subset]]\n    else:\n        adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n\n    # Apply function to all images\n    # Create lamda function \n    r_spatial_lda_internal = lambda x: spatial_lda_internal(adata_subset=x,\n                                                            x_coordinate=x_coordinate,\n                                                            y_coordinate=y_coordinate,\n                                                            z_coordinate=z_coordinate,\n                                                            phenotype=phenotype, \n                                                            method=method, \n                                                            radius=radius, \n                                                            knn=knn, \n                                                            imageid=imageid) \n    all_data = list(map(r_spatial_lda_internal, adata_list)) # Apply function \n\n    # combine all the data into one\n    texts = np.concatenate( all_data, axis=0 ).tolist()\n\n    # LDA pre-processing\n    if verbose:\n        print ('Pre-Processing Spatial LDA')\n    # Create Dictionary\n    id2word = corpora.Dictionary(texts)\n\n    # Term Document Frequency\n    corpus = [id2word.doc2bow(text) for text in texts]\n\n    # Build LDA model\n    if verbose:\n        print ('Training Spatial LDA')\n    try:\n        lda_model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n                                                   id2word=id2word,\n                                                   num_topics=num_motifs, \n                                                   random_state=random_state,**kwargs)\n    except:\n        lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n                                                   id2word=id2word,\n                                                   num_topics=num_motifs, \n                                                   random_state=random_state,**kwargs)\n\n    # Compute Coherence Score\n    if verbose:\n        print ('Calculating the Coherence Score')\n    coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n    coherence_lda = coherence_model_lda.get_coherence()\n    if verbose:\n        print('\\nCoherence Score: ', coherence_lda)\n\n    # isolate the latent features\n    if verbose:\n        print ('Gathering the latent weights')\n    topic_weights = []\n    for row_list in lda_model[corpus]:\n        tmp = np.zeros(num_motifs)\n        for i, w in row_list:\n            tmp[i] = w\n        topic_weights.append(tmp)\n    # conver to dataframe\n    arr = pd.DataFrame(topic_weights, index=adata.obs.index).fillna(0)\n    arr = arr.add_prefix('Motif_')\n\n    # isolate the weights of phenotypes\n    pattern = \"(\\d\\.\\d+).\\\"(.*?)\\\"\"\n    cell_weight = pd.DataFrame(index=np.unique(adata.obs[phenotype]))\n    for i in range(0, len(lda_model.print_topics())):\n        level1 = lda_model.print_topics()[i][1]\n        tmp = pd.DataFrame(re.findall(pattern, level1))\n        tmp.index = tmp[1]\n        tmp = tmp.drop(columns=1)\n        tmp.columns = ['Motif_'+ str(i)]\n        cell_weight = cell_weight.merge(tmp, how='outer', left_index=True, right_index=True)\n    # fill zeros\n    cell_weight = cell_weight.fillna(0).astype(float)\n\n    # save the results in anndata object\n    adata.uns[label] = arr # save the weight for each cell\n    adata.uns[str(label)+'_probability'] = cell_weight # weights of each cell type\n    #adata.uns[str(label)+'_model'] = lda_model\n\n    # return\n    return adata\n</code></pre>"},{"location":"Functions/tl/spatial_pscore/","title":"spatial_pscore","text":"<p>Short Description</p> <p>sm.tl.spatial_pscore: This function introduces a refined scoring system to quantify the proximity between  specified cell types within spatial data, including support for 3D datasets. It calculates two distinct scores:</p> <ul> <li>Proximity Density: Total number of interactions identified divided by the total number of  cells of the cell-types that were used for interaction analysis.  </li> <li>Proximity Volume: Total number of interactions identified divided by the total number of all cells in the data.  </li> </ul> <p>Interaction sites are cataloged and accessible in <code>adata.obs</code>. Both scores are stored in <code>adata.uns</code>.</p>"},{"location":"Functions/tl/spatial_pscore/#scimap.tools.spatial_pscore--functions","title":"Functions","text":""},{"location":"Functions/tl/spatial_pscore/#scimap.tools.spatial_pscore.spatial_pscore","title":"<code>spatial_pscore(adata, proximity, score_by='imageid', x_coordinate='X_centroid', y_coordinate='Y_centroid', z_coordinate=None, phenotype='phenotype', method='radius', radius=20, knn=3, imageid='imageid', subset=None, verbose=True, label='spatial_pscore')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix with spatial information.</p> required <code>proximity</code> <code>list</code> <p>List of cell types to calculate proximity scores for, e.g., ['CellType-A', 'CellType-B'].</p> required <code>score_by</code> <code>str</code> <p>Column name for ROI comparison. Scores are computed within these regions if specified.</p> <code>'imageid'</code> <code>x_coordinate</code> <code>(str, required)</code> <p>Column name for x-coordinates.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <code>(str, required)</code> <p>Column name for y-coordinates.</p> <code>'Y_centroid'</code> <code>z_coordinate</code> <code>str</code> <p>Column name for z-coordinates, for 3D spatial data.</p> <code>None</code> <code>phenotype</code> <code>(str, required)</code> <p>Column name indicating cell phenotype or classification.</p> <code>'phenotype'</code> <code>method</code> <code>str</code> <p>Neighborhood definition method: 'radius' for fixed distance, 'knn' for K nearest neighbors.</p> <code>'radius'</code> <code>radius</code> <code>int</code> <p>Radius defining local neighborhoods (applicable for 'radius' method).</p> <code>20</code> <code>knn</code> <code>int</code> <p>Number of nearest neighbors to consider (applicable for 'knn' method).</p> <code>3</code> <code>imageid</code> <code>str</code> <p>Column name specifying image identifiers, for analyses within specific images.</p> <code>'imageid'</code> <code>subset</code> <code>str</code> <p>Identifier for subset analysis, typically an image ID.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If True, enables progress and informational messages.</p> <code>True</code> <code>label</code> <code>str</code> <p>Custom label for storing results in <code>adata.obs</code> and <code>adata.uns</code>.</p> <code>'spatial_pscore'</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>Updated <code>adata</code> object with proximity scores stored in both <code>adata.obs[label]</code> and <code>adata.uns[label]</code>.</p> Example <pre><code># Compute proximity scores between two cell types across all images\nadata = sm.tl.spatial_pscore(adata, proximity=['CellType-A', 'CellType-B'],\n                       method='radius', radius=20, label='proximity_score_all')\n\n# Compute proximity scores within a specific image subset\nadata = sm.tl.spatial_pscore(adata, proximity=['CellType-C', 'CellType-D'],\n                       method='knn', knn=3, imageid='imageid', subset='image_02',\n                       label='proximity_score_image_02')\n\n# 3D data proximity score calculation\nadata = sm.tl.spatial_pscore(adata, proximity=['CellType-E', 'CellType-F'],\n                       x_coordinate='X_centroid', y_coordinate='Y_centroid', z_coordinate='Z_centroid',\n                       method='radius', radius=30, label='proximity_score_3D')\n</code></pre> Source code in <code>scimap/tools/spatial_pscore.py</code> <pre><code>def spatial_pscore (adata,proximity, \n                    score_by='imageid', \n                    x_coordinate='X_centroid',\n                    y_coordinate='Y_centroid',\n                    z_coordinate= None,\n                    phenotype='phenotype',\n                    method='radius',\n                    radius=20,\n                    knn=3,\n                    imageid='imageid',\n                    subset=None, \n                    verbose= True,\n                    label='spatial_pscore'):\n    \"\"\"\nParameters:\n        adata (anndata.AnnData):  \n            Annotated data matrix with spatial information.\n\n        proximity (list):  \n            List of cell types to calculate proximity scores for, e.g., ['CellType-A', 'CellType-B'].\n\n        score_by (str, optional):  \n            Column name for ROI comparison. Scores are computed within these regions if specified.\n\n        x_coordinate (str, required):  \n            Column name for x-coordinates.\n\n        y_coordinate (str, required):  \n            Column name for y-coordinates.\n\n        z_coordinate (str, optional):  \n            Column name for z-coordinates, for 3D spatial data.\n\n        phenotype (str, required):  \n            Column name indicating cell phenotype or classification.\n\n        method (str, optional):  \n            Neighborhood definition method: 'radius' for fixed distance, 'knn' for K nearest neighbors.\n\n        radius (int, optional):  \n            Radius defining local neighborhoods (applicable for 'radius' method).\n\n        knn (int, optional):  \n            Number of nearest neighbors to consider (applicable for 'knn' method).\n\n        imageid (str, optional):  \n            Column name specifying image identifiers, for analyses within specific images.\n\n        subset (str, optional):  \n            Identifier for subset analysis, typically an image ID.\n\n        verbose (bool, optional):  \n            If True, enables progress and informational messages.\n\n        label (str, optional):  \n            Custom label for storing results in `adata.obs` and `adata.uns`.\n\nReturns:\n        adata (anndata.AnnData):  \n            Updated `adata` object with proximity scores stored in both `adata.obs[label]` and `adata.uns[label]`.\n\nExample:\n        ```python\n\n        # Compute proximity scores between two cell types across all images\n        adata = sm.tl.spatial_pscore(adata, proximity=['CellType-A', 'CellType-B'],\n                               method='radius', radius=20, label='proximity_score_all')\n\n        # Compute proximity scores within a specific image subset\n        adata = sm.tl.spatial_pscore(adata, proximity=['CellType-C', 'CellType-D'],\n                               method='knn', knn=3, imageid='imageid', subset='image_02',\n                               label='proximity_score_image_02')\n\n        # 3D data proximity score calculation\n        adata = sm.tl.spatial_pscore(adata, proximity=['CellType-E', 'CellType-F'],\n                               x_coordinate='X_centroid', y_coordinate='Y_centroid', z_coordinate='Z_centroid',\n                               method='radius', radius=30, label='proximity_score_3D')\n\n        ```\n    \"\"\"\n\n\n    # Start\n    def spatial_pscore_internal (adata_subset,proximity,x_coordinate,y_coordinate,z_coordinate,phenotype,method,radius,knn,\n                                imageid,subset,label):\n\n        # Create a dataFrame with the necessary inforamtion\n        if z_coordinate is not None:\n            if verbose:\n                print(\"Including Z -axis\")\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'z': adata_subset.obs[z_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n        else:\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n\n\n        # Create a DataFrame with the necessary inforamtion\n        #data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'phenotype': adata_subset.obs[phenotype]})\n\n        # Identify neighbourhoods based on the method used\n        # a) KNN method\n\n        if method == 'knn':\n            if verbose:\n                print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n            if z_coordinate is not None:\n                tree = BallTree(data[['x','y','z']], leaf_size= 2)\n                ind = tree.query(data[['x','y','z']], k=knn, return_distance= False)\n            else:\n                tree = BallTree(data[['x','y']], leaf_size= 2)\n                ind = tree.query(data[['x','y']], k=knn, return_distance= False)\n            neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n            neighbours_ind = neighbours.copy()\n\n        if method == 'radius':\n            if verbose:\n                print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n            if z_coordinate is not None:\n                kdt = BallTree(data[['x','y','z']], metric='euclidean') \n                ind = kdt.query_radius(data[['x','y','z']], r=radius, return_distance=False)\n            else:\n                kdt = BallTree(data[['x','y']], metric='euclidean') \n                ind = kdt.query_radius(data[['x','y']], r=radius, return_distance=False)\n            neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n            neighbours_ind = neighbours.copy() # neighbour DF\n\n# =============================================================================\n#             \n#         if method == 'knn':\n#             print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n#             tree = BallTree(data[['x','y']], leaf_size= 2)\n#             ind = tree.query(data[['x','y']], k=knn, return_distance= False)\n#             neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n#             neighbours_ind = neighbours.copy() # neighbour DF\n#             #neighbours.drop(0, axis=1, inplace=True) # Remove self neighbour\n#         \n#         # b) Local radius method\n#         if method == 'radius':\n#             print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n#             kdt = BallTree(data[['x','y']], metric='euclidean') \n#             ind = kdt.query_radius(data[['x','y']], r=radius, return_distance=False)\n#             #for i in range(0, len(ind)): ind[i] = np.delete(ind[i], np.argwhere(ind[i] == i))#remove self\n#             neighbours = pd.DataFrame(ind.tolist(), index = data.index) # neighbour DF\n#             neighbours_ind = neighbours.copy() # neighbour DF\n#             \n#             \n# =============================================================================\n        # Map phenotype\n        phenomap = dict(zip(list(range(len(ind))), data['phenotype'])) # Used for mapping\n        phenomap_ind = dict(zip(list(range(len(ind))), data.index)) # Used for mapping cell_nme\n\n        # Loop through (all functionized methods were very slow)\n        for i in neighbours.columns:\n            neighbours[i] = neighbours[i].dropna().map(phenomap, na_action='ignore')\n        # do the same index and cell name\n        for i in neighbours_ind.columns:\n            neighbours_ind[i] = neighbours_ind[i].dropna().map(phenomap_ind, na_action='ignore')\n\n\n        # Idetify all the neighbourhoods that contains the user defined proximity phenotypes\n        #for i in proximity:\n        #    print (str('Finding neighbourhoods with ') + str(i))\n        #    nn = neighbours[neighbours.isin([i])].dropna(how='all').index\n        #    neighbours = neighbours.loc[nn]\n        matches = np.ones(len(neighbours), bool)\n        for v in proximity:\n            matches &amp;= (neighbours == v).any(axis=1)\n        neighbours = neighbours[matches]\n\n\n        # Identify all the cells that was part of the neighbourhood in this analysis\n        neighbours_ind = neighbours_ind.loc[neighbours.index]\n        neighbours_ind_unique = pd.unique(neighbours_ind.values.ravel())\n\n        # subset the neighbourhood cells to include only the cells in the user defined list\n        cleaned_neighbours_ind_unique = [x for x in neighbours_ind_unique if str(x) != 'nan']\n        d = data.loc[cleaned_neighbours_ind_unique]\n        d = d[d['phenotype'].isin(proximity)].index\n\n        # return neighbours for score and image_neighbours for plotting on image\n        return {'neighbours': neighbours.index, 'image_neighbours': d }\n\n\n    # Subset a particular image if needed\n    if subset is not None:\n        adata_list = [adata[adata.obs[imageid] == subset]]\n    else:\n        adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n\n    # Apply function to all images and create a master dataframe\n    # Create lamda function \n    r_spatial_pscore_internal = lambda x: spatial_pscore_internal(adata_subset=x,proximity=proximity,\n                                                   x_coordinate=x_coordinate,\n                                                   y_coordinate=y_coordinate,\n                                                   z_coordinate=z_coordinate,\n                                                   phenotype=phenotype,\n                                                   method=method,radius=radius,knn=knn,\n                                                   imageid=imageid,subset=subset,label=label) \n    all_data = list(map(r_spatial_pscore_internal, adata_list)) # Apply function\n\n\n    # Merge all the results into a single dataframe    \n    proximity_site_cells =  np.concatenate([d['image_neighbours'] for d in all_data], axis=0)\n\n    # Add it to the AnnData Object\n    adata.obs[label] = np.where(adata.obs.index.isin(proximity_site_cells), '_'.join(proximity), \"other\")\n\n    ##### SCORING #####\n    proximity_neigh = np.concatenate([d['neighbours'] for d in all_data], axis=0)\n    wh_d = adata.obs.copy()\n    wh_d[label] = np.where(wh_d.index.isin(proximity_neigh), '_'.join(proximity), \"other\")\n\n    # Define a scoring system\n    name = '_'.join(proximity)\n    whole_data = wh_d[[score_by, label, phenotype]]\n\n    # proximity volume\n    p_v = whole_data.groupby([score_by, label], observed=False).size().unstack().fillna(0)\n    p_v ['All Cells'] = p_v[name] + p_v[\"other\"]\n    p_v['Proximity Volume'] = p_v[name] / p_v['All Cells']\n    p_v = p_v.fillna(0) # replace NA\n    p_v = p_v.replace([np.inf, -np.inf], 0)\n    p_v = p_v.drop(columns = 'other')\n\n    # subset the phenotypes of interest\n    w_d = whole_data[whole_data[phenotype].isin(proximity)]\n    # proximity density\n    p_d = w_d.groupby([score_by, label], observed=False).size().unstack().fillna(0)\n    p_d ['Celltype of interest'] = p_d[name] + p_d[\"other\"]\n    p_d['Proximity Density'] = p_d[name] / p_d['Celltype of interest']\n    p_d = p_d.fillna(0) # replace NA\n    p_d = p_d.replace([np.inf, -np.inf], 0)\n    p_d = p_d.drop(columns = ['other', name])\n\n    # Merge Promimity volumne and density\n    proximity_score = pd.merge(p_v, p_d, left_index=True, right_index=True)\n\n    # Add it to the anndata object\n    adata.uns[label] = proximity_score\n\n    # Print\n    if verbose:\n        print(\"Please check:\\nadata.obs['\" + str(label) + \"'] &amp;\\nadata.uns['\"+ str(label) + \"'] for results\")\n\n    # Return \n    return adata\n</code></pre>"},{"location":"Functions/tl/spatial_similarity_search/","title":"spatial_similarity_search","text":"<p>Short Description</p> <p><code>sm.tl.spatial_similarity_search</code>: This function enables the discovery of regions  within spatial datasets that resemble a specified region of interest (ROI)  in terms of molecular characteristics. Outcomes are stored in <code>adata.obs</code>,  facilitating subsequent visualization with <code>sm.pl.image_viewer</code>.  Users can iteratively adjust the <code>similarity_threshold</code> to refine results,  optimizing the identification of molecularly similar areas.</p>"},{"location":"Functions/tl/spatial_similarity_search/#scimap.tools.spatial_similarity_search--function","title":"Function","text":""},{"location":"Functions/tl/spatial_similarity_search/#scimap.tools.spatial_similarity_search.spatial_similarity_search","title":"<code>spatial_similarity_search(adata, ROI_column, x_coordinate='X_centroid', y_coordinate='Y_centroid', z_coordinate=None, similarity_threshold=0.5, ROI_subset=None, method='radius', radius=30, knn=10, imageid='imageid', use_raw=True, subset=None, label='spatial_similarity_search', reuse_similarity_matrix=None, morphological_features=None, use_only_morphological_features=False, verbose=True, output_dir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix or path to an AnnData object, containing spatial gene expression data.</p> required <code>x_coordinate</code> <code>(str, required)</code> <p>Column name in <code>adata</code> for the x-coordinates.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <code>(str, required)</code> <p>Column name in <code>adata</code> for the y-coordinates.</p> <code>'Y_centroid'</code> <code>z_coordinate</code> <code>str</code> <p>Column name in <code>adata</code> for the z-coordinates, for 3D spatial data analysis.</p> <code>None</code> <code>ROI_column</code> <code>(str, required)</code> <p>Column name in <code>adata.obs</code> indicating the ROIs or regions for similarity analysis.</p> required <code>similarity_threshold</code> <code>float</code> <p>Threshold to adjust the strictness of similarity, with a default of 0.5.</p> <code>0.5</code> <code>ROI_subset</code> <code>list</code> <p>List of specific ROIs within <code>ROI_column</code> for targeted similarity search.</p> <code>None</code> <code>method</code> <code>str</code> <p>'radius' or 'knn' for neighborhood definition, with a focus on proximity or nearest neighbors.</p> <code>'radius'</code> <code>radius,</code> <code>knn (int</code> <p>Parameters defining the spatial neighborhood for the chosen method.</p> required <code>imageid</code> <code>str</code> <p>Column name in <code>adata.obs</code> for image identifiers, facilitating analysis within specific images.</p> <code>'imageid'</code> <code>use_raw</code> <code>bool</code> <p>Whether to utilize raw data for analysis.</p> <code>True</code> <code>subset</code> <code>str</code> <p>Specific image identifier for targeted analysis, typically an image ID.</p> <code>None</code> <code>label</code> <code>str</code> <p>Custom label for storing results in <code>adata.obs</code> and <code>adata.uns</code>.</p> <code>'spatial_similarity_search'</code> <code>reuse_similarity_matrix</code> <code>str</code> <p>Reuse a previously computed similarity matrix to adjust thresholds without recalculating.</p> <code>None</code> <code>morphological_features</code> <code>list</code> <p>List of morphological features stored in <code>adata.obs</code> to include in similarity calculations.</p> <code>None</code> <code>use_only_morphological_features</code> <code>bool</code> <p>If true, calculates similarity based solely on morphological features.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>If set to <code>True</code>, the function will print detailed messages about its progress and the steps being executed.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>Updated <code>adata</code> object with spatial similarity search results stored under <code>adata.obs[{label}_{ROIname}]</code>.</p> Example <pre><code># Basic spatial similarity search within a specific ROI using radius method\nadata = sm.tl.spatial_similarity_search(adata, ROI_column='Tumor_ROI', similarity_threshold=0.6,\n                                  ROI_subset=['Tumor_ROI_1'], method='radius', radius=40,\n                                  label='tumor_similarity')\n\n# Adjusting similarity threshold and reusing similarity matrix\nadata = sm.tl.spatial_similarity_search(adata, ROI_column='Tumor_ROI', similarity_threshold=0.8,\n                                  reuse_similarity_matrix='tumor_similarity', label='tumor_similarity_adjusted')\n\n# Incorporating morphological features in similarity search\nadata = sm.tl.spatial_similarity_search(adata, ROI_column='Immune_ROI', similarity_threshold=0.5,\n                                  morphological_features=['Area', 'MajorAxisLength'],\n                                  use_only_morphological_features=True, label='immune_similarity_morph')\n\n# visulaize the results in napari\nimage_path = \"/Users/aj/Documents/exemplar-001/registration/exemplar-001.ome.tif\"\nsm.pl.image_viewer (image_path, adata, subset = 'unmicst-exemplar-001_cell', \n                    overlay='spatial_similarity_search_blood_vessel', point_color='White')\n</code></pre> Source code in <code>scimap/tools/spatial_similarity_search.py</code> <pre><code>def spatial_similarity_search (adata,\n                               ROI_column,\n                               x_coordinate='X_centroid',\n                               y_coordinate='Y_centroid',\n                               z_coordinate=None,\n                               similarity_threshold=0.5,\n                               ROI_subset = None,\n                               method='radius', \n                               radius=30, \n                               knn=10, \n                               imageid='imageid', \n                               use_raw=True, \n                               subset=None,\n                               label='spatial_similarity_search',\n                               reuse_similarity_matrix=None,\n                               morphological_features=None,\n                               use_only_morphological_features=False,\n                               verbose=True,\n                               output_dir=None):\n    \"\"\"\nParameters:\n        adata (anndata.AnnData):  \n            Annotated data matrix or path to an AnnData object, containing spatial gene expression data.\n\n        x_coordinate (str, required):  \n            Column name in `adata` for the x-coordinates.\n\n        y_coordinate (str, required):  \n            Column name in `adata` for the y-coordinates.\n\n        z_coordinate (str, optional):  \n            Column name in `adata` for the z-coordinates, for 3D spatial data analysis.\n\n        ROI_column (str, required):  \n            Column name in `adata.obs` indicating the ROIs or regions for similarity analysis.\n\n        similarity_threshold (float, optional):  \n            Threshold to adjust the strictness of similarity, with a default of 0.5.\n\n        ROI_subset (list, optional):  \n            List of specific ROIs within `ROI_column` for targeted similarity search.\n\n        method (str, optional):  \n            'radius' or 'knn' for neighborhood definition, with a focus on proximity or nearest neighbors.\n\n        radius, knn (int, optional):  \n            Parameters defining the spatial neighborhood for the chosen method.\n\n        imageid (str, optional):  \n            Column name in `adata.obs` for image identifiers, facilitating analysis within specific images.\n\n        use_raw (bool, optional):  \n            Whether to utilize raw data for analysis.\n\n        subset (str, optional):  \n            Specific image identifier for targeted analysis, typically an image ID.\n\n        label (str, optional):  \n            Custom label for storing results in `adata.obs` and `adata.uns`.\n\n        reuse_similarity_matrix (str, optional):  \n            Reuse a previously computed similarity matrix to adjust thresholds without recalculating.\n\n        morphological_features (list, optional):  \n            List of morphological features stored in `adata.obs` to include in similarity calculations.\n\n        use_only_morphological_features (bool, optional):  \n            If true, calculates similarity based solely on morphological features.\n\n        verbose (bool):  \n            If set to `True`, the function will print detailed messages about its progress and the steps being executed.\n\nReturns:\n        adata (anndata.AnnData):  \n            Updated `adata` object with spatial similarity search results stored under `adata.obs[{label}_{ROIname}]`.\n\nExample:\n        ```python\n\n        # Basic spatial similarity search within a specific ROI using radius method\n        adata = sm.tl.spatial_similarity_search(adata, ROI_column='Tumor_ROI', similarity_threshold=0.6,\n                                          ROI_subset=['Tumor_ROI_1'], method='radius', radius=40,\n                                          label='tumor_similarity')\n\n        # Adjusting similarity threshold and reusing similarity matrix\n        adata = sm.tl.spatial_similarity_search(adata, ROI_column='Tumor_ROI', similarity_threshold=0.8,\n                                          reuse_similarity_matrix='tumor_similarity', label='tumor_similarity_adjusted')\n\n        # Incorporating morphological features in similarity search\n        adata = sm.tl.spatial_similarity_search(adata, ROI_column='Immune_ROI', similarity_threshold=0.5,\n                                          morphological_features=['Area', 'MajorAxisLength'],\n                                          use_only_morphological_features=True, label='immune_similarity_morph')\n\n        # visulaize the results in napari\n        image_path = \"/Users/aj/Documents/exemplar-001/registration/exemplar-001.ome.tif\"\n        sm.pl.image_viewer (image_path, adata, subset = 'unmicst-exemplar-001_cell', \n                            overlay='spatial_similarity_search_blood_vessel', point_color='White')\n\n        ```\n    \"\"\"\n\n\n    #x_coordinate='X_centroid'; y_coordinate='Y_centroid'; method='radius'; radius=30; knn=10; imageid='imageid'; \n    #use_raw=True ; log=True; subset=None; label='spatial_similarity_search'; output_dir=None; ROI_column='ASMA'; ROI_subset = None; similarity_threshold=0.5\n    # morphological_features = ['Area', 'MajorAxisLength','MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation']\n    #adata_subset = adata.copy()\n\n    # Load the andata object    \n    if isinstance(adata, str):\n        imid = str(adata.rsplit('/', 1)[-1])\n        adata = anndata.read(adata)\n    else:\n        imid = \"adata_spatial_similarity_search\"\n        adata = adata\n\n    # Error statements\n    if use_raw is False:\n        if all(adata.X[0] &lt; 1) is False:\n            raise ValueError('Please run `sm.pp.rescale` first if you wish to use `use_raw = False`')\n\n    # Function to calculate the distance between two vectors\n    @numba.jit(nopython=True, parallel=True, cache=True)\n    def euclidian_score(query_neighbourhood):\n        return 1.0 / ((np.sqrt(np.sum((spatial_lag_array - query_neighbourhood) ** 2, axis=1))) + 1.0)\n\n\n    def spatial_expression_internal (adata_subset, x_coordinate, y_coordinate,z_coordinate,\n                                     method, radius, knn, imageid, use_raw,\n                                     morphological_features, use_only_morphological_features):\n\n        # Create a DataFrame with the necessary inforamtion\n        #data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate]})\n\n        # Create a dataFrame with the necessary inforamtion\n        if z_coordinate is not None:\n            if verbose:\n                print(\"Including Z -axis\")\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate], 'z': adata_subset.obs[z_coordinate] })\n        else:\n            data = pd.DataFrame({'x': adata_subset.obs[x_coordinate], 'y': adata_subset.obs[y_coordinate] })\n\n\n        # Identify neighbourhoods based on the method used\n        # a) KNN method\n        if method == 'knn':\n            if verbose:\n                print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n            if z_coordinate is not None:\n                tree = BallTree(data, leaf_size= 2)\n                dist, ind = tree.query(data, k=knn, return_distance= True)\n            else:\n                tree = BallTree(data, leaf_size= 2)\n                dist, ind = tree.query(data, k=knn, return_distance= True)\n\n        # b) Local radius method\n        if method == 'radius':\n            if verbose:\n                print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n            if z_coordinate is not None:\n                kdt = BallTree(data, metric='euclidean') \n                dist, ind = kdt.query_radius(data, r=radius, return_distance=True)\n            else:\n                kdt = BallTree(data, metric='euclidean') \n                dist, ind = kdt.query_radius(data, r=radius, return_distance=True)\n\n# =============================================================================\n#         \n#         if method == 'knn':\n#             print(\"Identifying the \" + str(knn) + \" nearest neighbours for every cell\")\n#             tree = BallTree(data, leaf_size= 2)\n#             dist, ind = tree.query(data, k=knn, return_distance= True)\n# \n#             \n#         # b) Local radius method\n#         if method == 'radius':\n#             print(\"Identifying neighbours within \" + str(radius) + \" pixels of every cell\")\n#             kdt = BallTree(data, metric='euclidean')\n#             ind, dist = kdt.query_radius(data, r=radius, return_distance= True)\n#             \n# =============================================================================\n\n\n        # Normalize range (0-1) and account for total number of cells \n        d = scipy.sparse.lil_matrix((len(data), len(data)))\n        for row, (columns, values) in enumerate(zip(ind, dist)):\n            # Drop self-distance element.\n            idx = columns != row\n            columns = columns[idx]\n            values = values[idx]\n            if len(values) == 1:\n                values = [1.0]\n            elif len(values) &gt; 1:\n                # Normalize distances.\n                values = (values.max() - values) / (values.max() - values.min())\n                values /= values.sum()\n            # Assign row to matrix.\n            d[row, columns] = values\n\n        # convert to csr sparse matrix\n        wn_matrix_sparse = d.tocsr()\n\n        # to dense matrix\n        #dense = pd.DataFrame(wn_matrix_sparse.todense())\n\n\n        # normalize data\n        molecular_matrix = pd.DataFrame(adata_subset.raw.X, columns = adata_subset.var.index, index=adata_subset.obs.index)\n        # clip outliers\n        def clipping (x):\n                clip = x.clip(lower =np.percentile(x,0.01), upper=np.percentile(x,99.99)).tolist()\n                return clip\n        gmm_data = molecular_matrix.apply(clipping)\n        # log trasform\n        normalised_data = np.log1p(gmm_data)\n        # scale data\n        #transformer = RobustScaler().fit(n_log)\n        #normalised_data = pd.DataFrame(transformer.transform(n_log), columns = adata_subset.var.index, index=adata_subset.obs.index)\n        #normalised_data = n_log\n\n        #### Calculation of spatial lag\n\n        # a) use only morphological features?\n        if morphological_features is not None:\n            if isinstance(morphological_features, str):\n                morphological_features = [morphological_features]\n            morph_f = adata_subset.obs[morphological_features]\n\n            transformer = RobustScaler().fit(morph_f)\n            morph_f = pd.DataFrame(transformer.transform(morph_f), columns = morph_f.columns, index=morph_f.index)\n\n            if use_only_morphological_features is True:\n                spatial_lag = pd.DataFrame(wn_matrix_sparse * morph_f, columns = morph_f.columns, index=morph_f.index)\n\n\n        # b) use morphological features and molecular features?\n        if morphological_features is not None and use_only_morphological_features is False:\n            if use_raw==True:\n                combined_matrix = pd.concat([normalised_data, morph_f], axis=1)\n                spatial_lag = pd.DataFrame(wn_matrix_sparse * combined_matrix, columns = combined_matrix.columns, index=combined_matrix.index)     \n            else:\n                molecular_matrix = pd.DataFrame(adata_subset.X, columns = adata_subset.var.index, index=adata_subset.obs.index)\n                combined_matrix = pd.concat([molecular_matrix, morph_f], axis=1)\n                spatial_lag = pd.DataFrame(wn_matrix_sparse * combined_matrix, columns = combined_matrix.columns, index=combined_matrix.index) \n\n        # c) use only molecular features\n        if morphological_features is None:\n            if use_raw==True:\n                spatial_lag = pd.DataFrame(wn_matrix_sparse * normalised_data, columns = adata_subset.var.index, index=adata_subset.obs.index)\n            else:\n                spatial_lag = pd.DataFrame(wn_matrix_sparse * adata_subset.X, columns = adata_subset.var.index, index=adata_subset.obs.index)\n\n        # return value\n        return spatial_lag\n\n\n    # check if the user wants to reuse the spatial lag vector that was previously calculated\n    if reuse_similarity_matrix is None:\n        # Subset a particular image if needed\n        if subset is not None:\n            if isinstance(subset, str):\n                subset = [subset]\n            adata_list = [adata[adata.obs[imageid].isin(subset)]]\n        else:\n            adata_list = [adata[adata.obs[imageid] == i] for i in adata.obs[imageid].unique()]\n\n\n        # Apply function to all images and create a master dataframe\n        # Create lamda function \n        r_spatial_expression_internal = lambda x: spatial_expression_internal(adata_subset=x, \n                                                                    x_coordinate=x_coordinate, \n                                                                    y_coordinate=y_coordinate, \n                                                                    z_coordinate=z_coordinate,\n                                                                    method=method, radius=radius, \n                                                                    knn=knn, imageid=imageid, \n                                                                    use_raw=use_raw,\n                                                                    morphological_features=morphological_features, \n                                                                    use_only_morphological_features=use_only_morphological_features) \n\n        all_data = list(map(r_spatial_expression_internal, adata_list)) # Apply function \n\n        # Merge all the results into a single dataframe    \n        result = []\n        for i in range(len(all_data)):\n            result.append(all_data[i])\n        result = pd.concat(result, join='outer')  \n\n        # save the results in adata object\n        adata.uns[label] = result\n    else:\n        result = adata.uns[reuse_similarity_matrix]\n\n\n    ### Identify the ROI's of interest and then correlate it with all spatial lag\n\n    # calculate the distance between queri ROI and all neighbourhoods\n    # figure out the roi's that need to be processed\n    if ROI_subset is None:\n        ROI_subset = list(adata.obs[ROI_column].unique())\n        ROI_subset = [ x for x in ROI_subset if x != 'Other' ]\n    else:\n        if isinstance(ROI_subset, str):\n            ROI_subset = [ROI_subset]\n\n\n    # Figure out all the cells that fall within the user defined ROI's\n    query_neigh = adata[adata.obs[ROI_column].isin(ROI_subset)].obs[[ROI_column]]\n\n    #result = spatial_lag\n    #np.max(all_roi_scores)\n    #np.min(all_roi_scores)\n\n    # for each ROI calculate the median spatial lag\n    median_spatial_lag = pd.merge(result.loc[query_neigh.index], query_neigh, left_index=True, right_index=True, how='outer')\n    median_spatial_lag = median_spatial_lag.groupby(ROI_column, observed=False).median()\n\n    # apply the distance function to each defined ROI's\n    spatial_lag_array = np.array(result)\n    median_spatial_lag_array = np.array(median_spatial_lag)\n\n    # func\n    #all_roi_scores = np.array([distance.euclidean(median_spatial_lag_array[0],x) for x in spatial_lag_array])\n    #all_roi_scores = pd.DataFrame(all_roi_scores, columns=median_spatial_lag.index, index = result.index)\n    all_roi_scores = np.array([euclidian_score(x) for x in median_spatial_lag_array])\n    #all_roi_scores = median_spatial_lag.apply(euclidian_score, axis = 1) when spatial lag is a df\n    # convert that to a df for returning\n    all_roi_scores = pd.DataFrame(all_roi_scores, index=median_spatial_lag.index, columns = result.index).T\n\n    # rescale the scores\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    s = scaler.fit_transform(all_roi_scores)\n    all_roi_scores = pd.DataFrame(s, columns = all_roi_scores.columns, index= all_roi_scores.index)\n\n    ### Threshold the results to identify neighbourhoods that are similar to the \n    all_roi_scores_threshold = pd.DataFrame(np.where(all_roi_scores &gt;= similarity_threshold, 'similar_to_ROI', 'other'), index = all_roi_scores.index, columns = all_roi_scores.columns)\n\n    # rename columns of the \n    A = list(all_roi_scores.columns)\n    column_names = [label + \"_\" + str(s) for s in A]\n    all_roi_scores_threshold.columns = column_names\n\n    # delete the result columns from adata if they already exist\n    adata_obs = adata.obs\n    if any(x in adata_obs.columns for x in column_names):\n        adata_obs = adata_obs.drop(column_names, axis = 1)\n\n    # Merge the results with adata.obs\n    final_results = pd.merge(adata_obs, all_roi_scores_threshold, left_index=True, right_index=True, how='outer')\n\n    # Reindex the cells\n    final_results = final_results.replace(np.nan, 'not_computed')\n    final_results = final_results.reindex(adata.obs.index)\n\n    # return the data\n    adata.obs = final_results\n\n    # Save data if requested\n    if output_dir is not None:\n        output_dir = pathlib.Path(output_dir)\n        output_dir.mkdir(exist_ok=True, parents=True)\n        adata.write(output_dir / imid)\n    else:    \n        # Return data\n        return adata\n</code></pre>"},{"location":"Functions/tl/umap/","title":"umap","text":"<p>Short Description</p> <p><code>sm.tl.umap</code>: This function enables dimensionality reduction on high-dimensional  datasets using UMAP, allowing for the visualization of complex data structures  in a lower-dimensional space. It supports customization through various parameters,  including data source selection, logarithmic transformation, and manifold  approximation settings, accommodating a wide range of analytical needs. Results  are stored in <code>adata.obsm</code>, ready for subsequent visualization or analysis.</p>"},{"location":"Functions/tl/umap/#scimap.tools.umap--function","title":"Function","text":""},{"location":"Functions/tl/umap/#scimap.tools.umap.umap","title":"<code>umap(adata, use_layer=None, use_raw=False, log=False, n_neighbors=15, n_components=2, metric='euclidean', min_dist=0.1, random_state=0, label='umap', **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>adata</code> <code>AnnData</code> <p>Annotated data matrix or path to an AnnData object, containing spatial gene expression data.</p> required <code>use_layer</code> <code>str</code> <p>Specifies a layer in <code>adata.layers</code> for UMAP. Defaults to using <code>adata.X</code>.</p> <code>None</code> <code>use_raw</code> <code>bool</code> <p>Whether to use <code>adata.raw.X</code> for the analysis.</p> <code>False</code> <code>log</code> <code>bool</code> <p>Applies natural log transformation to the data if <code>True</code>.</p> <code>False</code> <code>n_neighbors</code> <code>int</code> <p>Number of neighboring points used in manifold approximation.</p> <code>15</code> <code>n_components</code> <code>int</code> <p>Dimensionality of the target embedding space.</p> <code>2</code> <code>metric</code> <code>str</code> <p>Metric used to compute distances in high-dimensional space.</p> <code>'euclidean'</code> <code>min_dist</code> <code>float</code> <p>Effective minimum distance between embedded points.</p> <code>0.1</code> <code>random_state</code> <code>int</code> <p>Seed used by the random number generator for reproducibility.</p> <code>0</code> <code>label</code> <code>str</code> <p>Key for storing UMAP results in <code>adata.obsm</code>.</p> <code>'umap'</code> <p>Returns:</p> Name Type Description <code>adata</code> <code>AnnData</code> <p>The input <code>adata</code> object, updated with UMAP embedding results in <code>adata.obsm[label]</code>.</p> Example <pre><code># Basic UMAP reduction\nadata = sm.tl.umap(adata, n_neighbors=15, min_dist=0.1, label='umap_basic')\n\n# UMAP using specific layer and log transformation\nadata = sm.tl.umap(adata, use_layer='counts', use_raw=True, log=True, n_neighbors=30, min_dist=0.05, label='umap_layer_log')\n\n# UMAP with a different metric and higher dimensionality\nadata = sm.tl.umap(adata, metric='manhattan', n_components=3, n_neighbors=50, label='umap_manhattan_3d')\n\n# plot results\nsm.pl.umap(adata)\n</code></pre> Source code in <code>scimap/tools/umap.py</code> <pre><code>def umap (adata, \n          use_layer=None, \n          use_raw=False, \n          log=False,\n          n_neighbors=15, \n          n_components=2, \n          metric='euclidean',\n          min_dist=0.1, \n          random_state=0, \n          label='umap', **kwargs):\n    \"\"\"\nParameters:\n        adata (anndata.AnnData):  \n            Annotated data matrix or path to an AnnData object, containing spatial gene expression data.\n\n        use_layer (str, optional):  \n            Specifies a layer in `adata.layers` for UMAP. Defaults to using `adata.X`.\n\n        use_raw (bool, optional):  \n            Whether to use `adata.raw.X` for the analysis.\n\n        log (bool, optional):  \n            Applies natural log transformation to the data if `True`.\n\n        n_neighbors (int, optional):  \n            Number of neighboring points used in manifold approximation.\n\n        n_components (int, optional):  \n            Dimensionality of the target embedding space.\n\n        metric (str, optional):  \n            Metric used to compute distances in high-dimensional space.\n\n        min_dist (float, optional):  \n            Effective minimum distance between embedded points.\n\n        random_state (int, optional):  \n            Seed used by the random number generator for reproducibility.\n\n        label (str, optional):  \n            Key for storing UMAP results in `adata.obsm`.\n\nReturns:\n        adata (anndata.AnnData):  \n            The input `adata` object, updated with UMAP embedding results in `adata.obsm[label]`.\n\nExample:\n        ```python\n\n        # Basic UMAP reduction\n        adata = sm.tl.umap(adata, n_neighbors=15, min_dist=0.1, label='umap_basic')\n\n        # UMAP using specific layer and log transformation\n        adata = sm.tl.umap(adata, use_layer='counts', use_raw=True, log=True, n_neighbors=30, min_dist=0.05, label='umap_layer_log')\n\n        # UMAP with a different metric and higher dimensionality\n        adata = sm.tl.umap(adata, metric='manhattan', n_components=3, n_neighbors=50, label='umap_manhattan_3d')\n\n        # plot results\n        sm.pl.umap(adata)\n\n        ```\n    \"\"\"\n\n    # adata_layer=None;use_raw=False;log=False;n_neighbors=15;n_components=2;metric='euclidean';min_dist=0.1;\n    # random_state=0;\n    # load data\n    if use_layer is not None:\n        data = adata.layers[use_layer]\n    elif use_raw is True:\n        data = adata.raw.X\n    else:\n        data = adata.X\n\n    # log the data if user requests\n    if log is True:\n        data = np.log1p(data)\n\n\n    # embedding\n    embedding = um.UMAP(n_neighbors=n_neighbors,\n                          n_components=n_components,\n                          metric=metric,\n                          min_dist=min_dist,\n                          random_state=random_state).fit_transform(data)\n\n    # plot\n    #plt.scatter(embedding[:, 0], embedding[:, 1], s=5)\n\n    # return data\n    adata.obsm[label] = embedding\n    return adata\n</code></pre>"},{"location":"tutorials/Releases/CHANGELOG/","title":"1.3.14 (2024-03-20)","text":"<ul> <li>Added tutorials</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#0210-2022-05-29","title":"0.21.0 (2022-05-29)","text":"<ul> <li>Added <code>sm.hl.animate</code> and <code>sm.pl.umap</code></li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#02016-2022-05-28","title":"0.20.16 (2022-05-28)","text":"<ul> <li>Added <code>sm.tl.umap</code> and <code>sm.tl.spatial_similarity_search</code></li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#0190-2022-04-03","title":"0.19.0 (2022-04-03)","text":"<ul> <li>Included support for <code>Apple M1</code> machines</li> <li>Included support for native rendering of Zarr stored images using Napari: <code>pl.image_viewer</code> and <code>pl.gate_finder</code></li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#0140-2021-04-10","title":"0.14.0 (2021-04-10)","text":"<ul> <li>Included <code>sm.tl.foldchange</code> function. Also calculated p-val by Fisher exact test</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#0120-2021-02-12","title":"0.12.0 (2021-02-12)","text":"<ul> <li>Included <code>sm.pl.voronoi</code> function. Now possible to draw voronoi diagram of the images using X/Y coordinates</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#0110-2021-01-30","title":"0.11.0 (2021-01-30)","text":"<ul> <li>Included <code>spatial_pscore</code> function</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#0100-2020-11-27","title":"0.10.0 (2020-11-27)","text":"<ul> <li>Included <code>stacked_barplot</code> function to generate a stacked barplot from any two cloumns</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#090-2020-11-21","title":"0.9.0 (2020-11-21)","text":"<ul> <li>Updated <code>pl.image_viewer</code> and <code>pl.gate_finder</code> functions -     Implemeted Zarr functionality for napari viz.</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#087-2020-11-18","title":"0.8.7 (2020-11-18)","text":"<ul> <li>Updated <code>pl.spatial_interaction</code> function to include two additional parameters -     <code>subset_phenotype</code> and <code>subset_neighbour_phenotype</code>. </li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#083-2020-11-16","title":"0.8.3 (2020-11-16)","text":"<ul> <li>Added <code>hl.add_roi</code> function. Used to incorporate ROI's extracted from Omero into the scimap object.</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#080-2020-11-09","title":"0.8.0 (2020-11-09)","text":"<ul> <li>Updated <code>pp.mcmicro_to_scimap</code> function. Added a new parameter <code>unique_CellId</code></li> <li>Added a helper function <code>scimap_to_csv</code> to save the andata object as a CSV.</li> <li>Added documentation and tests for <code>scimap_to_csv</code></li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#0710-2020-10-30","title":"0.7.10 (2020-10-30)","text":"<ul> <li>Updated <code>pp.rescale</code> function. If a gate is included in the <code>manual_gate.csv</code>     file but no gate value is provided, the algorithm simply scales the data between    0-1 without changing the undelying structure.</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#076-2020-10-27","title":"0.7.6 (2020-10-27)","text":"<ul> <li>Updated <code>hl.spatial_distance</code> to include option to convert to     log scale and also pass multiple <code>distance_to</code> parameter.</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#075-2020-10-27","title":"0.7.5 (2020-10-27)","text":"<ul> <li>Updated <code>hl.classify</code> to improve speed</li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#073-2020-10-27","title":"0.7.3 (2020-10-27)","text":"<ul> <li>Addition of binary view in <code>pl.spatial_interaction</code></li> </ul>"},{"location":"tutorials/Releases/CHANGELOG/#072-2020-10-26","title":"0.7.2 (2020-10-26)","text":"<ul> <li>Addition of <code>hl.classify</code> function.</li> <li>Documentation for <code>hl.classify</code> function.</li> <li>Readme file modification</li> </ul>"},{"location":"tutorials/Releases/license/","title":"License","text":"<p>The MIT License (MIT)</p> <p>Copyright \u00a9 2020, Ajit Johnson Nirmal</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"tutorials/archive/1-scimap-tutorial-getting-started/","title":"Getting Started with Scimap","text":"<pre><code>#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Fri Jun 26 23:11:32 2020\n@author: Ajit Johnson Nirmal\nScimap Getting Started tutorial\n\"\"\"\n</code></pre> <pre><code>'\\nCreated on Fri Jun 26 23:11:32 2020\\n@author: Ajit Johnson Nirmal\\nScimap Getting Started tutorial\\n'\n</code></pre> <pre><code># Before you start make sure you have installed the following packages\n# pip install scimap\n# pip install scanpy\n# pip install leidenalg\n# pip install PyQt5\n</code></pre>"},{"location":"tutorials/archive/1-scimap-tutorial-getting-started/#tutorial-material","title":"Tutorial material","text":"<p>You can download the material for this tutorial from the following link: The presentation files are available here:</p>"},{"location":"tutorials/archive/1-scimap-tutorial-getting-started/#tutorial-video","title":"Tutorial video","text":"<pre><code>from IPython.display import HTML\nHTML('&lt;iframe width=\"450\" height=\"250\" src=\"https://www.youtube.com/embed/knh5elRksUk\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen&gt;&lt;/iframe&gt;')\n</code></pre> <pre><code># Load necessary libraries\nimport sys\nimport os\nimport anndata as ad\nimport pandas as pd\nimport scanpy as sc\nimport seaborn as sns; sns.set(color_codes=True)\n\n# Import Scimap\nimport scimap as sm\n</code></pre> <pre><code># Set the working directory\nos.chdir (\"/Users/aj/Desktop/scimap_tutorial/\")\n</code></pre>"},{"location":"tutorials/archive/1-scimap-tutorial-getting-started/#load-data-using-anndata","title":"Load data using AnnData","text":"<pre><code># Load data\ndata = pd.read_csv ('counts_table.csv') # Counts matrix\nmeta = pd.read_csv ('meta_data.csv') # Meta data like x and y coordinates \n\n# combine the data and metadata file to generate the AnnData object\nadata = ad.AnnData (data)\nadata.obs = meta\n</code></pre> <p>Print adata to check for it's content</p> <pre><code>adata\n</code></pre> <pre><code>AnnData object with n_obs \u00d7 n_vars = 4825 \u00d7 48\n    obs: 'X_centroid', 'Y_centroid', 'Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation'\n</code></pre> <pre><code>adata.obs # prints the meta data\n</code></pre> X_centroid Y_centroid Area MajorAxisLength MinorAxisLength Eccentricity Solidity Extent Orientation 0 511.555556 9.846154 117 14.532270 10.273628 0.707261 0.959016 0.750000 -0.695369 1 579.330097 9.398058 103 16.056286 8.776323 0.837396 0.903509 0.613095 1.115707 2 630.958333 12.883333 120 15.222005 10.310756 0.735653 0.975610 0.681818 0.151616 3 745.194631 16.275168 149 14.380200 13.404759 0.362027 0.967532 0.662222 -0.270451 4 657.173653 18.035928 167 17.675831 12.110106 0.728428 0.943503 0.695833 -0.810890 ... ... ... ... ... ... ... ... ... ... 4820 559.597403 1091.577922 154 18.150307 11.683288 0.765281 0.900585 0.570370 -0.342315 4821 619.983871 1092.959677 248 21.734414 15.565820 0.697912 0.864111 0.551111 1.432242 4822 583.317073 1093.573171 82 12.060039 9.539789 0.611784 0.964706 0.630769 0.203023 4823 607.064394 1101.583333 264 22.549494 15.905321 0.708858 0.882943 0.661654 0.691838 4824 641.592486 1100.132948 346 23.149806 19.375564 0.547257 0.945355 0.791762 -1.390516 <p>4825 rows \u00d7 9 columns</p> <pre><code>adata.X # prints the counts table\n</code></pre> <pre><code>array([[16640.564  ,   719.6325 ,   527.7094 , ...,  1085.735  ,\n          218.54701,  3170.47   ],\n       [16938.3    ,   686.5534 ,   469.30096, ...,  1075.6407 ,\n          164.48544,  3116.767  ],\n       [16243.542  ,   819.4167 ,   604.39166, ...,  1164.3917 ,\n          227.74167,  3156.1084 ],\n       ...,\n       [28656.256  ,   878.2561 ,   585.3293 , ...,  1233.183  ,\n         1243.5488 ,  3194.195  ],\n       [22054.818  ,   685.8485 ,   424.85226, ...,  1031.2424 ,\n          313.32574,  3038.8105 ],\n       [23992.854  ,   850.25146,   529.89886, ...,  1000.5578 ,\n          285.98267,  3087.3005 ]], dtype=float32)\n</code></pre> <pre><code>adata.var[0:5] # prints the first 5 channel or marker names\n</code></pre> DNA1 BG1 BG2 BG3 DNA2 <p>You would have noticed that - the data is not in log scale - All the DNA channels are there - The background channels are there If we diretly perform clustering or any other type of analysis, the above mentioned factors may affect the results and so it is recommended to remove them.</p>"},{"location":"tutorials/archive/1-scimap-tutorial-getting-started/#load-data-using-scimaps-helper-function","title":"Load data using scimap's helper function","text":"<p>Use this if the single-cell data was generated using mcmicro pipeline. With this function though many of the above limitations can be imediately addressed. By default it removes DNA channels and you can pass any channel name into <code>drop_markers</code> parameter inorder to not import them.</p> <pre><code>image_path = ['/Users/aj/Desktop/scimap_tutorial/mcmicro_output.csv']\nadata = sm.pp.mcmicro_to_scimap (image_path, drop_markers = [\"PERK\", \"NOS2\",\"BG1\",\"BG2\",\"BG3\",\"ACTIN\"])\n</code></pre> <pre><code>Loading mcmicro_output.csv\n</code></pre> <p>Check adata contents now as we did previously</p> <pre><code>adata\n</code></pre> <pre><code>AnnData object with n_obs \u00d7 n_vars = 4825 \u00d7 30\n    obs: 'X_centroid', 'Y_centroid', 'Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation', 'imageid'\n    uns: 'all_markers'\n</code></pre> <pre><code>adata.X # Will now contain log normalized data\n</code></pre> <pre><code>array([[6.3674684, 6.4287267, 7.3826084, ..., 6.990933 , 5.3915663,\n        8.061951 ],\n       [6.340171 , 6.094227 , 7.339796 , ..., 6.981601 , 5.1088834,\n        8.044872 ],\n       [6.503502 , 6.3549495, 7.4734573, ..., 7.0608125, 5.4325933,\n        8.057412 ],\n       ...,\n       [6.5583014, 6.660794 , 7.4199724, ..., 7.1181645, 7.1265283,\n        8.069404 ],\n       [6.3370404, 6.281594 , 7.2397914, ..., 6.939489 , 5.7504296,\n        8.01955  ],\n       [6.3805585, 6.180567 , 7.2547846, ..., 6.909312 , 5.659422 ,\n        8.035377 ]], dtype=float32)\n</code></pre> <pre><code>adata.raw.X # contains the raw data\n</code></pre> <pre><code>array([[ 581.5812 ,  618.38464, 1606.7778 , ..., 1085.735  ,  218.54701,\n        3170.47   ],\n       [ 565.8932 ,  442.29126, 1539.3981 , ..., 1075.6407 ,  164.48544,\n        3116.767  ],\n       [ 666.475  ,  574.3333 , 1759.6833 , ..., 1164.3917 ,  227.74167,\n        3156.1084 ],\n       ...,\n       [ 704.0732 ,  780.1707 , 1667.9878 , ..., 1233.183  , 1243.5488 ,\n        3194.195  ],\n       [ 564.1212 ,  533.64014, 1392.803  , ..., 1031.2424 ,  313.32574,\n        3038.8105 ],\n       [ 589.2572 ,  482.2659 , 1413.8584 , ..., 1000.5578 ,  285.98267,\n        3087.3005 ]], dtype=float32)\n</code></pre> <pre><code>adata.obs # prints the meta data\n</code></pre> X_centroid Y_centroid Area MajorAxisLength MinorAxisLength Eccentricity Solidity Extent Orientation imageid mcmicro_output_1 511.555556 9.846154 117 14.532270 10.273628 0.707261 0.959016 0.750000 -0.695369 mcmicro_output mcmicro_output_2 579.330097 9.398058 103 16.056286 8.776323 0.837396 0.903509 0.613095 1.115707 mcmicro_output mcmicro_output_3 630.958333 12.883333 120 15.222005 10.310756 0.735653 0.975610 0.681818 0.151616 mcmicro_output mcmicro_output_4 745.194631 16.275168 149 14.380200 13.404759 0.362027 0.967532 0.662222 -0.270451 mcmicro_output mcmicro_output_5 657.173653 18.035928 167 17.675831 12.110106 0.728428 0.943503 0.695833 -0.810890 mcmicro_output ... ... ... ... ... ... ... ... ... ... ... mcmicro_output_4821 559.597403 1091.577922 154 18.150307 11.683288 0.765281 0.900585 0.570370 -0.342315 mcmicro_output mcmicro_output_4822 619.983871 1092.959677 248 21.734414 15.565820 0.697912 0.864111 0.551111 1.432242 mcmicro_output mcmicro_output_4823 583.317073 1093.573171 82 12.060039 9.539789 0.611784 0.964706 0.630769 0.203023 mcmicro_output mcmicro_output_4824 607.064394 1101.583333 264 22.549494 15.905321 0.708858 0.882943 0.661654 0.691838 mcmicro_output mcmicro_output_4825 641.592486 1100.132948 346 23.149806 19.375564 0.547257 0.945355 0.791762 -1.390516 mcmicro_output <p>4825 rows \u00d7 10 columns</p>"},{"location":"tutorials/archive/1-scimap-tutorial-getting-started/#we-can-use-scanpy-package-to-explore-the-data","title":"We can use scanpy package to explore the data","text":"<pre><code>sc.pl.highest_expr_genes(adata, n_top=20, ) # Most expressing proteins\n</code></pre> <pre><code>sc.tl.pca(adata, svd_solver='arpack') # peform PCA\nsc.pl.pca(adata, color='KI67') # scatter plot in the PCA coordinates\n</code></pre> <pre><code>sc.pl.pca_variance_ratio(adata) # PCs to the total variance in the data\n</code></pre> <pre><code># Save the results\nadata.write('tutorial_data.h5ad')\n</code></pre> <p>This concludes the <code>getting started</code> tutorial, continue with the <code>phenotyping</code> tutorial.</p>"},{"location":"tutorials/archive/2-scimap-tutorial-cell-phenotyping/","title":"Cell-Phenotyping using Scimap","text":"<pre><code>#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Fri Jun 28 18:10:06 2020\n@author: Ajit Johnson Nirmal\nScimap Cell Phenotyping Tutorial\n\"\"\"\n</code></pre> <pre><code>'\\nCreated on Fri Jun 28 18:10:06 2020\\n@author: Ajit Johnson Nirmal\\nScimap Cell Phenotyping Tutorial\\n'\n</code></pre>"},{"location":"tutorials/archive/2-scimap-tutorial-cell-phenotyping/#tutorial-material","title":"Tutorial material","text":"<p>You can download the material for this tutorial from the following link: The presentation files are available here:</p>"},{"location":"tutorials/archive/2-scimap-tutorial-cell-phenotyping/#tutorial-video","title":"Tutorial video","text":"<pre><code>from IPython.display import HTML\nHTML('&lt;iframe width=\"450\" height=\"250\" src=\"https://www.youtube.com/embed/knh5elRksUk\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen&gt;&lt;/iframe&gt;')\n</code></pre> <pre><code># Load necessary libraries\nimport sys\nimport os\nimport anndata as ad\nimport pandas as pd\nimport scanpy as sc\nimport seaborn as sns; sns.set(color_codes=True)\n\n# Import Scimap\nimport scimap as sm\n</code></pre> <pre><code># Set the working directory\nos.chdir (\"/Users/aj/Desktop/scimap_tutorial/\")\n</code></pre> <pre><code># Load data\nadata = ad.read('tutorial_data.h5ad')\n</code></pre>"},{"location":"tutorials/archive/2-scimap-tutorial-cell-phenotyping/#clustering-and-data-exploration","title":"Clustering and data exploration","text":"<p>You could use clustering and marker expression analysis within clusters to assign cell types similar to what is carried out with single-cell sequencing data.</p> <pre><code>sc.pp.neighbors(adata, n_neighbors=30, n_pcs=10) # Computing the neighborhood graph\n</code></pre> <pre><code>sc.tl.umap(adata) # Build a UMAP to visualize the neighbourhood graph\n</code></pre> <pre><code>sc.pl.umap(adata, color=['CD3D', 'CD20', 'CD163'], cmap= 'vlag', use_raw=False, s=30) # Plot the UMAP\n</code></pre> <p></p> <p>We can already begin to spot issues with carrying out this mode of phenotyping approach. As you can see there is an area of co-expression of CD3D and CD20, which is likely because of segmentation errors. Additionally the boundaries are not distinct between cell-types and it is highly likely that errors will be introduced due to this reason. </p> <pre><code>sc.tl.leiden(adata, resolution = 1) # Clustering the neighborhood graph\n</code></pre> <pre><code>sc.pl.umap(adata, color=['leiden', 'CD3D', 'CD20'],cmap= 'vlag', use_raw=False) # View the clustering\n</code></pre> <p></p>"},{"location":"tutorials/archive/2-scimap-tutorial-cell-phenotyping/#finding-marker-genes","title":"Finding marker genes","text":"<pre><code>sc.tl.rank_genes_groups(adata, 'leiden', method='t-test')\nsc.pl.rank_genes_groups(adata, n_genes=10, sharey=False, fontsize=16)\n</code></pre> <p>From the above plots, it is likely that clusters 1, 2 and 7 could be combined to form a T cell cluster. However, as mentioned earlier the boundaries are not clear and it only get increasingly complex as one would want to perform deeper phenotyping such as CD4 helper T cells, CD8 T cells, regulatory T cells and so on. </p> <p>Additionally, marker analsyis suggests that CD30 is most expressed in cluster 8. If you look at the actual image, you will realize that CD30 is not expressed by any cell in this image and the analysis is picking up high background fluorescence. </p>"},{"location":"tutorials/archive/2-scimap-tutorial-cell-phenotyping/#probability-distribution-based-phenotyping","title":"Probability distribution based phenotyping","text":"<p>This approach is more labor intensive, however is significantly more sensitive and much more scalable than clustering based approaches. Takes less than 5 mins to run over a million cells once the gates are identified.</p>"},{"location":"tutorials/archive/2-scimap-tutorial-cell-phenotyping/#in-order-to-run-the-method-you-need-2-things","title":"In order to run the method, you need 2 things","text":"<ul> <li>a gating workflow strategy <code>.csv file</code></li> <li>manual gates <code>.csv file</code>. If manual gates are not provided, the algorithm will attempt to rescale the data by fitting two gaussians on the data. However, it is adviced to perform manual gating as I have found it to be more sensitive.</li> </ul> <p>The algorithm involves three steps: 1. Identify the gates using <code>sm.pl.gate_finder</code> 2. Rescale the data based on the identified gates using <code>sm.pp.rescale</code> 3. Run the phenotyping algorithm on the rescaled data using <code>sm.tl.phenotype</code></p>"},{"location":"tutorials/archive/2-scimap-tutorial-cell-phenotyping/#define-manual-gates-to-rescale-data-before-running-the-phenotyping-algorithm","title":"Define manual gates to rescale data before running the phenotyping algorithm","text":"<p>Instantiating the Qt GUI can take a few seconds and if you create the Viewer before it is finished, the kernel will die and the viewer will not launch. For this reason the %gui qt magic command should always be run in a separate cell from creating the viewer</p> <pre><code>%gui qt\n</code></pre>"},{"location":"tutorials/archive/2-scimap-tutorial-cell-phenotyping/#step-1-identify-the-gates-using-smplgate_finder","title":"Step 1: Identify the gates using <code>sm.pl.gate_finder</code>","text":"<pre><code>image_path = '/Users/aj/Desktop/scimap_tutorial/reactive_core.tif'\nmarker_of_interest = 'CD45'\n</code></pre> <pre><code>sm.pl.gate_finder (image_path, adata, marker_of_interest, \n                   from_gate = 5, to_gate = 9, increment = 0.1, \n                   markers=['ASMA','DNA11', 'CD20', 'CD3D'], point_size=6)\n</code></pre>"},{"location":"tutorials/archive/2-scimap-tutorial-cell-phenotyping/#step-2-rescale-the-data-based-on-the-identified-gates-using-smpprescale","title":"Step 2: Rescale the data based on the identified gates using <code>sm.pp.rescale</code>","text":"<p>Note: Below we are passing a <code>manual_gates.csv</code> into the <code>gate</code> parameter. This contatins gates that were visually determined using the <code>sm.pl.gate_finder</code> function. For the markers included in the <code>manual_gates.csv</code> file,  the function will scale the data such that cells with expression greater than the gate  will be considered as positive for that marker and cells with expression below the gate is considered negative. </p> <p>For markers that are not included in the <code>manual_gates.csv</code> file, the function will automatically try to determine a gate by running a gaussian mixture model algorithm on the data. </p>"},{"location":"tutorials/archive/2-scimap-tutorial-cell-phenotyping/#note-for-v0220","title":"Note (for &gt;=v.0.22.0)","text":"<p>Please note that passing manual gates for multiple images has been introduced in <code>scimap &gt;=v.0.22.0</code></p> <pre><code># Load the manual gates and rescale the data based on the gates\nmanual_gate = pd.read_csv('manual_gates.csv')\nadata = sm.pp.rescale (adata, gate=manual_gate)\n</code></pre> <pre><code>Scaling Image [mcmicro_output]\nCategories (1, object): [mcmicro_output]\nFinding the optimal gate for CD10\nFinding the optimal gate for CD2\nFinding the optimal gate for CD30\nFinding the optimal gate for CD43\nFinding the optimal gate for CD5\nFinding the optimal gate for CD57\nFinding the optimal gate for CD7\nFinding the optimal gate for KI67\nFinding the optimal gate for MHCI\nFinding the optimal gate for PDL1\nFinding the optimal gate for PS6\nFinding the optimal gate for PSTAT3\nScaling ASMA\nScaling CD163\nScaling CD206\nScaling CD68\nScaling CD20\nScaling CD21\nScaling CD3D\nScaling CD45\nScaling CD56\nScaling CD8A\nScaling FOXP3\nScaling CD11B\nScaling CD11C\nScaling CD15\nScaling CD4\nScaling PD1\nScaling HLADR\nScaling CD25\n</code></pre> <pre><code># View the scaled data (note that the log data is replaced with scaled data)\n# If you ever want the log data back you will need to run-  np.log1p(adata.raw.X)\nadata.X \n</code></pre> <pre><code>array([[0.17841106, 0.45723783, 0.49234127, ..., 0.15973007, 0.1665647 ,\n        0.20024123],\n       [0.155838  , 0.21377199, 0.34924023, ..., 0.1522421 , 0.0885678 ,\n        0.15338667],\n       [0.29090098, 0.37456273, 0.50752728, ..., 0.21580293, 0.17788475,\n        0.18778977],\n       ...,\n       [0.33621626, 0.70161347, 0.70359459, ..., 0.26182348, 0.60810172,\n        0.22068843],\n       [0.15324935, 0.51044092, 0.60877724, ..., 0.11845023, 0.26558105,\n        0.08391592],\n       [0.18923565, 0.431478  , 0.58019522, ..., 0.09423545, 0.24047052,\n        0.12733514]])\n</code></pre>"},{"location":"tutorials/archive/2-scimap-tutorial-cell-phenotyping/#step-3-run-the-phenotyping-algorithm-on-the-rescaled-data-using-smtlphenotype","title":"Step 3: Run the phenotyping algorithm on the rescaled data using <code>sm.tl.phenotype</code>","text":"<pre><code># Load the gating workflow\nphenotype = pd.read_csv('phenotype_workflow.csv')\nadata = sm.tl.phenotype_cells (adata, phenotype=phenotype, label=\"phenotype\") \n</code></pre> <pre><code>Phenotyping Other Immune cells\nPhenotyping ASMA+ cells\n-- Subsetting Other Immune cells\nPhenotyping T cells\nPhenotyping B cells\nPhenotyping Myeloid Lineage\nPhenotyping NK cells\nPhenotyping Granulocytes\n-- Subsetting Myeloid Lineage\nPhenotyping T cells\nPhenotyping B cells\nPhenotyping NK cells\nPhenotyping Granulocytes\nPhenotyping CD68+ Macrophages\nPhenotyping M2 Macrophages\nPhenotyping Myeloid Dendritic cells\nPhenotyping Follicular Dendritic cells\n-- Subsetting T cells\nPhenotyping CD4 T cells\nPhenotyping CD8 T cells\n-- Subsetting CD4 T cells\nPhenotyping Regulatory T cells\nPhenotyping Follicular Helper T cells\n-- Subsetting CD8 T cells\nPhenotyping PD1+ T cells\n-- Subsetting Myeloid Dendritic cells\nPhenotyping CD25+ Dendritic cells\nConsolidating the phenotypes across all groups\n</code></pre> <pre><code># Summary of the phenotyping\nadata.obs['phenotype'].value_counts()\n</code></pre> <pre><code>B cells                       2037\nCD4 T cells                    502\nASMA+ cells                    420\nRegulatory T cells             418\nCD8 T cells                    322\nFollicular Helper T cells      282\nT cells                        146\nUnknown                        140\nOther Immune cells             137\nMyeloid Dendritic cells        124\nFollicular Dendritic cells      87\nMyeloid Lineage                 80\nPD1+ T cells                    63\nM2 Macrophages                  55\nGranulocytes                     8\nNK cells                         3\nCD25+ Dendritic cells            1\nName: phenotype, dtype: int64\n</code></pre> <p>It is likely that <code>CD25+ Dendritic cells, NK cells &amp; Granulocytes</code> are artifacts. You could set <code>pheno_threshold_abs= 10</code> to move these cells into <code>unknown</code> category.</p> <p>Once the phenotyping is performed, it is adviced to overlay the phenotypes on the image and check if they are correct. If not, alter the <code>phenotyping workflow</code> file or the <code>manual gate</code> to account for the errors.</p> <pre><code># View phenotypes\nsm.pl.image_viewer (image_path, adata, overlay = 'phenotype', point_color='white', point_size=6)\n</code></pre> <pre><code># View Leiden clustering\nsm.pl.image_viewer (image_path, adata, overlay = 'leiden', point_color='white', point_size=6)\n</code></pre>"},{"location":"tutorials/archive/2-scimap-tutorial-cell-phenotyping/#heatmap-and-umap-of-the-probability-based-phenotyping","title":"Heatmap and UMAP of the probability based phenotyping","text":"<pre><code>sc.tl.dendrogram(adata, groupby='phenotype')\n</code></pre> <pre><code>sc.pl.matrixplot(adata, var_names= adata.var.index, groupby='phenotype', dendrogram=True, use_raw=False, cmap=\"vlag\", standard_scale='var')\n</code></pre> <pre><code>GridSpec(2, 3, height_ratios=[0, 10.5], width_ratios=[9.6, 0.8, 0.2])\n</code></pre> <pre><code>sc.pl.umap(adata, color=['leiden', 'phenotype']) # View the clustering\n</code></pre> <pre><code>sns.set(rc={'figure.figsize':(11.7,8.27)})\nsc.pl.umap(adata, color=['phenotype'],legend_loc='on data', title='', frameon=False, s = 100) # View the clustering\n</code></pre> <pre><code>sc.pl.umap(adata, color=['CD3D', 'PD1', 'CD20'],cmap= 'vlag', use_raw=False, frameon=False, s = 100) # View the clustering\n</code></pre> <p>As it can be seen from above 3 UMAP's it would have been very difficult to find the Follicular helper T cells by a pure clustering approach. Also, the B cells as can be seen above does not from a nice seperate cluster. These among other illustrate the importance of using the probability based algorithm for deep phenotyping.</p> <pre><code># Confirm Follicular helper T cells in the image\nsm.pl.image_viewer (image_path, adata, \n                    overlay = 'phenotype', overlay_category=['Follicular Helper T cells'], \n                    markers = ['CD3D','CD20','PD1','CD8A','CD4','DNA11'],\n                    point_color='white', point_size=6)\n</code></pre> <pre><code># Save the results\nadata.write('tutorial_data.h5ad')\n</code></pre> <p>This concludes this tutorial</p>"},{"location":"tutorials/archive/3-Cell_Type_calling_and_adding_ROIs/","title":"Cell-Phenotyping and adding ROIs","text":"<pre><code>\"\"\"\nCreated on Mon May 16 19:00:32 2022\n@author: Ajit Johnson Nirmal\nSCIMAP tutorial May 2022\n\"\"\"\n</code></pre> <pre><code># load packages\nimport scimap as sm\nimport scanpy as sc\nimport pandas as pd\n</code></pre>"},{"location":"tutorials/archive/3-Cell_Type_calling_and_adding_ROIs/#tutorial-material","title":"Tutorial material","text":"<p>You can download the material for this tutorial from the following link: The jupyter notebook is available here:</p> <pre><code>common_path = \"/Users/aj/Dropbox (Partners HealthCare)/conferences/scimap_tutorial/may_2022_tutorial/\"\n#common_path = \"C:/Users/ajn16/Dropbox (Partners HealthCare)/conferences/scimap_tutorial/may_2022_tutorial/\"\n</code></pre> <pre><code># load data\nadata = sm.pp.mcmicro_to_scimap (image_path= str(common_path) + 'exemplar_001/quantification/unmicst-exemplar-001_cell.csv')\n</code></pre> <pre><code>Loading unmicst-exemplar-001_cell.csv\n</code></pre> <pre><code>adata\n</code></pre> <pre><code>AnnData object with n_obs \u00d7 n_vars = 11170 \u00d7 9\n    obs: 'X_centroid', 'Y_centroid', 'Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation', 'imageid'\n    uns: 'all_markers'\n</code></pre> <pre><code># Markers in dataset\nadata.var.index\n</code></pre> <pre><code>Index(['ELANE', 'CD57', 'CD45', 'CD11B', 'SMA', 'CD16', 'ECAD', 'FOXP3',\n       'NCAM'],\n      dtype='object')\n</code></pre>"},{"location":"tutorials/archive/3-Cell_Type_calling_and_adding_ROIs/#manually-gate-the-data","title":"manually gate the data","text":"<pre><code># manually gate the data\nimage_path = str(common_path) + 'exemplar_001/registration/exemplar-001.ome.tif'\n</code></pre> <pre><code>marker_of_interest = 'ECAD'\n</code></pre> <pre><code>sm.pl.gate_finder (image_path, adata, marker_of_interest, \n                   from_gate = 5, to_gate = 9, increment = 0.1, \n                   point_size=10)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/archive/3-Cell_Type_calling_and_adding_ROIs/#rescale-the-data-based-on-the-manual-gates","title":"rescale the data based on the manual gates","text":"<pre><code>manual_gate = pd.read_csv(str(common_path) + 'manual_gates.csv')\n</code></pre> <pre><code>manual_gate\n</code></pre> markers gate 0 ELANE 7.9 1 CD57 8.1 2 CD45 6.3 3 CD11B 7.2 4 SMA 7.6 5 CD16 6.8 6 ECAD 7.4 7 FOXP3 7.0 8 NCAM 7.2 <pre><code># rescale the data\nadata = sm.pp.rescale (adata, gate=manual_gate)\n</code></pre> <pre><code>Scaling Image ['unmicst-exemplar-001_cell']\nScaling ELANE\nScaling CD57\nScaling CD45\nScaling CD11B\nScaling SMA\nScaling CD16\nScaling ECAD\nScaling FOXP3\nScaling NCAM\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/archive/3-Cell_Type_calling_and_adding_ROIs/#phenotyping-cells","title":"Phenotyping cells","text":"<pre><code># load the phenotyping workflow\nphenotype = pd.read_csv(str(common_path) + 'phenotype_workflow.csv')\n</code></pre> <pre><code>phenotype.style.format(na_rep='')\n</code></pre> Unnamed: 0 Unnamed: 1 CD57 CD45 CD11B SMA CD16 ECAD FOXP3 0 all Other Immune cells anypos anypos anypos anypos anypos 1 all ASMA+ cells pos 2 all Tumor pos 3 Other Immune cells Myeloid pos 4 Other Immune cells NK cells pos 5 Other Immune cells Neutrophils pos 6 Other Immune cells Treg pos <pre><code># Run the phenotyping algorithm\nadata = sm.tl.phenotype_cells (adata, phenotype=phenotype, label=\"phenotype\") \n</code></pre> <pre><code>Phenotyping Other Immune cells\nPhenotyping ASMA+ cells\nPhenotyping Tumor\n-- Subsetting Other Immune cells\nPhenotyping Myeloid\nPhenotyping NK cells\nPhenotyping Neutrophils\nPhenotyping Treg\nConsolidating the phenotypes across all groups\n</code></pre> <pre><code># Check the number of phenotyped cells\nadata.obs['phenotype'].value_counts()\n</code></pre> <pre><code>Other Immune cells    3707\nTumor                 2499\nUnknown               1782\nMyeloid               1140\nNeutrophils            895\nASMA+ cells            457\nTreg                   364\nNK cells               326\nName: phenotype, dtype: int64\n</code></pre> <pre><code># Visualize cell types\nsm.pl.image_viewer (image_path, adata, overlay = 'phenotype', point_color='white', point_size=10)\n</code></pre> <pre><code># add seg mask\nseg_mask_path = str(common_path) + 'exemplar_001/qc/s3seg/unmicst-exemplar-001/cellOutlines.ome.tif'\nsm.pl.image_viewer (image_path, adata, \n                    seg_mask = seg_mask_path,\n                    overlay = 'phenotype', \n                    point_color='white', \n                    point_size=10)\n</code></pre> <pre><code># Visualize heatmap of cell types\nsc.pl.matrixplot(adata, var_names= adata.var.index, groupby='phenotype', dendrogram=True, use_raw=False, cmap=\"vlag\", standard_scale='var')\n</code></pre> <pre><code>... storing 'imageid' as categorical\n... storing 'phenotype' as categorical\n\n\nWARNING: dendrogram data not found (using key=dendrogram_phenotype). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.\n</code></pre>"},{"location":"tutorials/archive/3-Cell_Type_calling_and_adding_ROIs/#voronoi-plots","title":"Voronoi Plots","text":"<pre><code>sm.pl.voronoi(adata, color_by='phenotype', \n                 voronoi_edge_color = 'black',\n                 voronoi_line_width = 0.3, \n                 voronoi_alpha = 0.8, \n                 size_max=5000,\n                 overlay_points=None, \n                 plot_legend=True, \n                 legend_size=6)\n</code></pre> <pre><code># Map user defined colors\ncolors = {'ASMA+ cells': '#8AC926', \n          'Myeloid': \"#E9D8A6\", \n          'NK cells':  \"#0A9396\",\n          'Neutrophils': \"#CA6702\", \n          'Other Immune cells':'#001219',\n          'Treg': \"#005F73\", \n          'Tumor':  \"#9B2226\",\n          'Unknown': '#BCB8B1'\n    }\n</code></pre> <pre><code>import matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [15, 10]\nsm.pl.voronoi(adata, color_by='phenotype', \n                  colors = colors,\n                 voronoi_edge_color = 'black',\n                 voronoi_line_width = 0.3, \n                 voronoi_alpha = 0.8, \n                 #size_max=5000,\n                 overlay_points=None, \n                 plot_legend=True, \n                 legend_size=6)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/archive/3-Cell_Type_calling_and_adding_ROIs/#adding-roi-to-images","title":"Adding ROI to images","text":"<pre><code>adata = sm.pl.addROI_image(image_path, adata, \n                             subset=None, \n                             imageid='imageid', \n                             overlay=None, overlay_category=None,\n                             markers=None, \n                             channel_names='default', \n                             x_coordinate='X_centroid', y_coordinate='Y_centroid', \n                             seg_mask=None, \n                             overwrite=True, \n                             label='ROI')\n</code></pre> <pre><code>        Opening Napari;\n        Add shape layers (on left) to draw ROI's. \n        Rename the shape layer to give a name to your ROI\n        Multiple shape layers are supported\n        ROI's should not overlap\n        Close Napari to save ROI's.\n\nIdentifying cells within selected ROI's\n\n\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  inside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  inside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  inside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  inside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  inside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  inside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n</code></pre> <pre><code># check ROI cell count\nadata.obs['ROI'].value_counts()\n</code></pre> <pre><code>Other        8075\nCD57-high    2115\nCD57-low      980\nName: ROI, dtype: int64\n</code></pre> <pre><code># Add ROI individually\nadata = sm.pl.addROI_image(image_path, adata, \n                     overwrite=True, \n                     label='ROI_individual')\n</code></pre> <pre><code>        Opening Napari;\n        Add shape layers (on left) to draw ROI's. \n        Rename the shape layer to give a name to your ROI\n        Multiple shape layers are supported\n        ROI's should not overlap\n        Close Napari to save ROI's.\n\nIdentifying cells within selected ROI's\n\n\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  inside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  inside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  inside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  inside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  inside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  inside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/plotting/_addROI_image.py:364: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  inside['ROI_internal'] = all_rois[all_rois['id'] == roi_id]['ROI'][roi_id]\n</code></pre> <pre><code># check number of cells\nadata.obs['ROI_individual'].value_counts()\n</code></pre> <pre><code>Other          8025\nCD57-high-2     969\nCD57-low-1      710\nCD57-high-1     427\nCD57-low-3      393\nCD57-low-2      293\nCD57-high-3     188\nartifacts       165\nName: ROI_individual, dtype: int64\n</code></pre> <pre><code># Scatter plot to show the differnt ROI's\nimport pandas as pd\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = 'browser'\ndef plotly (adata,phenotype,image_id=None,x='X_centroid',y='Y_centroid',size=2, **kwargs):\n    if image_id is not None:\n        adata = adata[adata.obs['imageid'] == image_id]    \n    data = pd.DataFrame({'x':adata.obs[x], 'y':adata.obs[y],'col': adata.obs[phenotype]})\n    data = data.sort_values(by=['col'])\n    fig = px.scatter(data, x=\"x\", y=\"y\", color=\"col\", **kwargs)\n    fig.update_traces(marker=dict(size=size),selector=dict(mode='markers'),hoverlabel = dict(namelength = -1))\n    fig.update_yaxes(autorange=\"reversed\", tickformat='g')\n    fig.update_xaxes(tickformat='g')\n    fig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)','paper_bgcolor': 'rgba(0, 0, 0, 0)'})\n    return fig\n\nplotly (adata,phenotype='ROI_individual',image_id=None,x='X_centroid',y='Y_centroid',size=10)\n</code></pre> <pre><code># voronoi plot\nsm.pl.voronoi(adata, color_by='ROI_individual', \n                 voronoi_edge_color = 'black',\n                 voronoi_line_width = 0.3, \n                 voronoi_alpha = 0.8, \n                 size_max=5000,\n                 overlay_points=None, \n                 plot_legend=True, \n                 legend_size=6)\n</code></pre> <pre><code>bdata = adata[adata.obs['ROI_individual'] != 'artifacts']\n</code></pre> <pre><code>plotly (bdata,phenotype='ROI_individual',image_id=None,x='X_centroid',y='Y_centroid',size=10)\n</code></pre> <pre><code># save adata\nadata.write(str(common_path) + 'may2022_tutorial.h5ad')\n</code></pre> <pre><code>... storing 'ROI' as categorical\n... storing 'ROI_individual' as categorical\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/archive/4-CellType_Proportion_Exploration/","title":"CellType Proportion Exploration","text":"<pre><code>\"\"\"\nCreated on Mon May 16 19:00:32 2022\n@author: Ajit Johnson Nirmal\nSCIMAP tutorial May 2022\n\"\"\"\n</code></pre> <pre><code># load packages\nimport scimap as sm\nimport scanpy as sc\nimport pandas as pd\nimport anndata as ad\n</code></pre>"},{"location":"tutorials/archive/4-CellType_Proportion_Exploration/#tutorial-material","title":"Tutorial material","text":"<p>You can download the material for this tutorial from the following link: The jupyter notebook is available here:</p> <pre><code>common_path = \"/Users/aj/Dropbox (Partners HealthCare)/conferences/scimap_tutorial/may_2022_tutorial/\"\n#common_path = \"C:/Users/ajn16/Dropbox (Partners HealthCare)/conferences/scimap_tutorial/may_2022_tutorial/\"\n</code></pre> <pre><code># load data\n#adata = sm.pp.mcmicro_to_scimap (image_path= str(common_path) + 'exemplar_001/quantification/unmicst-exemplar-001_cell.csv')\n#manual_gate = pd.read_csv(str(common_path) + 'manual_gates.csv')\n#adata = sm.pp.rescale (adata, gate=manual_gate)\n#phenotype = pd.read_csv(str(common_path) + 'phenotype_workflow.csv')\n#adata = sm.tl.phenotype_cells (adata, phenotype=phenotype, label=\"phenotype\") \n# add user defined ROI's before proceeding\n</code></pre> <pre><code># load saved anndata object\nadata = ad.read(str(common_path) + 'may2022_tutorial.h5ad')\n</code></pre> <pre><code>adata\n</code></pre> <pre><code>AnnData object with n_obs \u00d7 n_vars = 11170 \u00d7 9\n    obs: 'X_centroid', 'Y_centroid', 'Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation', 'imageid', 'phenotype', 'index_info', 'ROI', 'ROI_individual'\n    uns: 'all_markers', 'dendrogram_phenotype'\n</code></pre>"},{"location":"tutorials/archive/4-CellType_Proportion_Exploration/#investigate-cell-type-composition-within-the-rois","title":"Investigate cell-type composition within the ROI's","text":"<pre><code># https://scimap.xyz/All%20Functions/C.%20Plotting/sm.pl.stacked_barplot/\nsm.pl.stacked_barplot (adata,\n                       x_axis='ROI_individual',\n                       y_axis='phenotype',\n                       method='absolute')\n</code></pre> <pre><code># Plot the number of cells normalized to 100% \nsm.pl.stacked_barplot (adata,\n                       x_axis='ROI_individual',\n                       y_axis='phenotype',\n                       method='percent')\n</code></pre> <pre><code># specify the elements to be in the plot\nx_axis_elements = ['CD57-low-1', 'CD57-low-2', 'CD57-low-3', 'CD57-high-2', 'CD57-high-1', 'CD57-high-3']\ny_axis_elements = ['ASMA+ cells', 'Myeloid', 'NK cells', 'Neutrophils', 'Other Immune cells', 'Treg', 'Tumor']\n</code></pre> <pre><code># replot\nsm.pl.stacked_barplot (adata,\n                       x_axis='ROI_individual',\n                       y_axis='phenotype',\n                       method='percent',\n                       subset_xaxis=x_axis_elements,\n                       subset_yaxis=y_axis_elements)\n</code></pre> <pre><code># quiet a number of parameters to play around:\nsm.pl.stacked_barplot (adata, \n                x_axis='ROI_individual', y_axis='phenotype', \n                subset_xaxis=x_axis_elements, subset_yaxis=y_axis_elements, \n                order_xaxis=None, order_yaxis=None, \n                method='percent', plot_tool='plotly', \n                matplotlib_cmap=None, \n                matplotlib_bbox_to_anchor=(1, 1.02), \n                matplotlib_legend_loc=2, \n                return_data=False)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/archive/4-CellType_Proportion_Exploration/#calculate-the-fold-change-in-cell-types-between-the-different-rois","title":"Calculate the fold change in cell types between the different ROI's","text":"<pre><code>adata = sm.tl.foldchange (adata, \n                          from_group=['CD57-low-1', 'CD57-low-2', 'CD57-low-3'], \n                          to_group=None, \n                          imageid='ROI_individual', \n                          phenotype='phenotype',\n                          normalize=True, \n                          subset_phenotype=None, \n                          label='foldchange')\n</code></pre> <pre><code>/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/tools/_foldchange.py:102: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/tools/_foldchange.py:103: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/tools/_foldchange.py:104: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/tools/_foldchange.py:109: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/scimap/tools/_foldchange.py:110: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\ncalculating P values\n</code></pre> <pre><code>adata\n</code></pre> <pre><code>AnnData object with n_obs \u00d7 n_vars = 11170 \u00d7 9\n    obs: 'X_centroid', 'Y_centroid', 'Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation', 'imageid', 'phenotype', 'index_info', 'ROI', 'ROI_individual'\n    uns: 'all_markers', 'dendrogram_phenotype', 'foldchange_pval', 'foldchange_fc'\n</code></pre> <pre><code># Heatmap of foldchnage  \nsm.pl.foldchange (adata, label='foldchange', method='heatmap',\n                     p_val=0.05, nonsig_color='grey',\n                     cmap = 'vlag', log=True, center=0, linecolor='black',linewidths=0.7,\n                     vmin=-5, vmax=5, row_cluster=False)\n</code></pre> <pre><code># Parallel_coordinates plot of the foldchanges\nsm.pl.foldchange (adata, label='foldchange', \n                  subset_xaxis = ['ASMA+ cells', 'NK cells', 'Neutrophils', 'Treg', 'Tumor'],\n                log=True, method='parallel_coordinates', invert_axis=True,\n                parallel_coordinates_color=['black','blue','green','red','#000000'],\n                matplotlib_bbox_to_anchor=(1.04,1),\n                matplotlib_legend_loc='upper left',\n                xticks_rotation=90,\n                return_data = False)\n</code></pre> <pre><code># save adata\nadata.write(str(common_path) + 'may2022_tutorial.h5ad')\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/archive/5-Simple_Spatial_Analysis/","title":"Simple Spatial Analysis","text":"<pre><code>\"\"\"\nCreated on Mon May 16 19:00:32 2022\n@author: Ajit Johnson Nirmal\nSCIMAP tutorial May 2022\n\"\"\"\n</code></pre> <pre><code># load packages\nimport scimap as sm\nimport scanpy as sc\nimport pandas as pd\nimport anndata as ad\n</code></pre>"},{"location":"tutorials/archive/5-Simple_Spatial_Analysis/#tutorial-material","title":"Tutorial material","text":"<p>You can download the material for this tutorial from the following link: The jupyter notebook is available here:</p> <pre><code>common_path = \"/Users/aj/Dropbox (Partners HealthCare)/conferences/scimap_tutorial/may_2022_tutorial/\"\n#common_path = \"C:/Users/ajn16/Dropbox (Partners HealthCare)/conferences/scimap_tutorial/may_2022_tutorial/\"\n</code></pre> <pre><code># load data\n#adata = sm.pp.mcmicro_to_scimap (image_path= str(common_path) + 'exemplar_001/quantification/unmicst-exemplar-001_cell.csv')\n#manual_gate = pd.read_csv(str(common_path) + 'manual_gates.csv')\n#adata = sm.pp.rescale (adata, gate=manual_gate)\n#phenotype = pd.read_csv(str(common_path) + 'phenotype_workflow.csv')\n#adata = sm.tl.phenotype_cells (adata, phenotype=phenotype, label=\"phenotype\") \n# add user defined ROI's before proceeding\n</code></pre> <pre><code># load saved anndata object\nadata = ad.read(str(common_path) + 'may2022_tutorial.h5ad')\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/archive/5-Simple_Spatial_Analysis/#calculate-distances-between-cell-types","title":"Calculate distances between cell types","text":"<p><code>sm.tl.spatial_distance</code>: The function allows users to calculate the average shortest between phenotypes or clusters of interest (3D data supported).</p> <pre><code>adata = sm.tl.spatial_distance (adata, \n                               x_coordinate='X_centroid', y_coordinate='Y_centroid', \n                               z_coordinate=None, \n                               phenotype='phenotype', \n                               subset=None, \n                               imageid='imageid', \n                               label='spatial_distance')\n</code></pre> <pre><code>Processing Image: unmicst-exemplar-001_cell\n</code></pre> <pre><code>adata.uns['spatial_distance']\n</code></pre> Other Immune cells Unknown Myeloid Tumor ASMA+ cells Neutrophils Treg NK cells unmicst-exemplar-001_cell_1 0.000000 508.809972 561.874000 547.544519 506.115689 581.323686 570.267087 1248.001853 unmicst-exemplar-001_cell_2 0.000000 25.516388 63.601485 67.024246 27.928445 157.289841 100.258654 816.837582 unmicst-exemplar-001_cell_3 0.000000 15.315383 59.503385 56.590105 34.479892 147.005355 96.374952 817.307871 unmicst-exemplar-001_cell_4 0.000000 28.482334 13.752853 51.500837 46.148651 111.763900 143.243322 746.050742 unmicst-exemplar-001_cell_5 26.357699 0.000000 45.589024 30.234937 58.354288 120.715789 96.739267 824.241184 ... ... ... ... ... ... ... ... ... unmicst-exemplar-001_cell_11166 0.000000 106.320078 70.605640 96.293073 50.637223 91.990689 43.229554 410.740868 unmicst-exemplar-001_cell_11167 0.000000 31.114913 72.531210 118.065360 54.921505 136.323479 30.072174 399.697389 unmicst-exemplar-001_cell_11168 0.000000 50.369768 70.748013 126.968337 36.065610 123.048957 40.094561 409.435592 unmicst-exemplar-001_cell_11169 0.000000 103.275795 64.057762 91.786425 64.741519 93.600860 35.697321 397.194037 unmicst-exemplar-001_cell_11170 10.165511 0.000000 88.288672 113.521913 86.006117 150.562555 23.735243 389.273701 <p>11170 rows \u00d7 8 columns</p> <pre><code># summary heatmap\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [3, 1]\nsm.pl.spatial_distance (adata)\n</code></pre> <p></p> <pre><code># Heatmap without summarizing the individual images\nsm.pl.spatial_distance (adata, heatmap_summarize=False)\n</code></pre> <p></p> <pre><code>sm.pl.spatial_distance (adata, heatmap_summarize=False, imageid='ROI_individual')\n</code></pre> <p></p> <pre><code># Numeric plot of shortest distance of phenotypes \n# from tumor cells\nsm.pl.spatial_distance (adata, method='numeric',distance_from='Tumor')\n</code></pre> <p></p> <pre><code>sm.pl.spatial_distance (adata, method='numeric',distance_from='Tumor', log=True)\n</code></pre> <p></p> <pre><code># plot for each ROI seperately\nsm.pl.spatial_distance (adata, method='numeric',distance_from='Tumor', imageid='ROI')\n</code></pre> <p></p> <pre><code>sm.pl.spatial_distance (adata, method='numeric',distance_from='Tumor', imageid='ROI', log=True)\n</code></pre> <p></p> <pre><code># Distribution plot of shortest distance of phenotypes from Tumor cells\nsm.pl.spatial_distance (adata, method='distribution',distance_from='Tumor',distance_to = 'ASMA+ cells',\n    imageid='ROI_individual', log=True)\n</code></pre> <p></p> <pre><code>\n</code></pre>"},{"location":"tutorials/archive/5-Simple_Spatial_Analysis/#spatial-co-occurance-analysis","title":"Spatial co-occurance analysis","text":"<p><code>sm.tl.spatial_interaction</code>: The function allows users to computes how likely celltypes are found next to each another compared to random background (3D data supported).</p> <pre><code># Using the radius method to identify local neighbours compute P-values\nadata = sm.tl.spatial_interaction (adata, \n                                  method='radius', \n                                  radius=30, \n                                  label='spatial_interaction_radius')\n</code></pre> <pre><code>Processing Image: ['unmicst-exemplar-001_cell']\nCategories (1, object): ['unmicst-exemplar-001_cell']\nIdentifying neighbours within 30 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\n</code></pre> <pre><code># Using the KNN method to identify local neighbours \nadata = sm.tl.spatial_interaction(adata, \n                                  method='knn', \n                                  knn=10, \n                                  label='spatial_interaction_knn')\n</code></pre> <pre><code>Processing Image: ['unmicst-exemplar-001_cell']\nCategories (1, object): ['unmicst-exemplar-001_cell']\nIdentifying the 10 nearest neighbours for every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\n</code></pre> <pre><code># view results\n# spatial_interaction heatmap for a single image\nsm.pl.spatial_interaction(adata, \n                          summarize_plot=True, \n                          binary_view=True,\n                          spatial_interaction='spatial_interaction_radius',\n                          row_cluster=False, linewidths=0.75, linecolor='black')\n</code></pre> <p></p> <pre><code># spatial_interaction heatmap for a single image\nsm.pl.spatial_interaction(adata, \n                          summarize_plot=True, \n                          binary_view=True,\n                          spatial_interaction='spatial_interaction_knn',\n                          row_cluster=False, linewidths=0.75, linecolor='black')\n</code></pre> <p></p> <pre><code># Pass the ROI's as different images\nadata = sm.tl.spatial_interaction(adata, \n                                  method='radius', \n                                  imageid = 'ROI_individual',\n                                  radius=30, \n                                  label='spatial_interaction_radius_roi')\n</code></pre> <pre><code>Processing Image: ['Other']\nCategories (1, object): ['Other']\nIdentifying neighbours within 30 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\nProcessing Image: ['artifacts']\nCategories (1, object): ['artifacts']\nIdentifying neighbours within 30 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\nProcessing Image: ['CD57-low-1']\nCategories (1, object): ['CD57-low-1']\nIdentifying neighbours within 30 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\nProcessing Image: ['CD57-low-3']\nCategories (1, object): ['CD57-low-3']\nIdentifying neighbours within 30 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\nProcessing Image: ['CD57-low-2']\nCategories (1, object): ['CD57-low-2']\nIdentifying neighbours within 30 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\nProcessing Image: ['CD57-high-3']\nCategories (1, object): ['CD57-high-3']\nIdentifying neighbours within 30 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\nProcessing Image: ['CD57-high-1']\nCategories (1, object): ['CD57-high-1']\nIdentifying neighbours within 30 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\nProcessing Image: ['CD57-high-2']\nCategories (1, object): ['CD57-high-2']\nIdentifying neighbours within 30 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\n</code></pre> <pre><code># spatial_interaction heatmap\nsm.pl.spatial_interaction(adata, \n                          summarize_plot=True, \n                          spatial_interaction='spatial_interaction_radius_roi',\n                          row_cluster=True, linewidths=0.75, linecolor='black')\n</code></pre> <p></p> <pre><code># spatial_interaction heatmap\nsm.pl.spatial_interaction(adata, \n                          summarize_plot=False, \n                          spatial_interaction='spatial_interaction_radius_roi',\n                          yticklabels=True,\n                          row_cluster=True, linewidths=0.75, linecolor='black')\n</code></pre> <p></p> <pre><code>\n</code></pre>"},{"location":"tutorials/archive/5-Simple_Spatial_Analysis/#quantifying-the-proximity-score","title":"Quantifying the proximity score","text":"<p><code>sm.tl.spatial_pscore</code>: A scoring system to evaluate user defined proximity between cell types.  </p> <p>The function generates two scores and saved at adata.uns: - Proximity Density: Total number of interactions identified divided by the total number of cells of the cell-types that were used for interaction analysis. - Proximity Volume: Total number of interactions identified divided by the total number of all cells in the data. The interaction sites are also recorded and saved in adata.obs</p> <pre><code># Calculate the score for proximity between `Tumor CD30+` cells and `M2 Macrophages`\nadata =  sm.tl.spatial_pscore (adata,proximity= ['Tumor', 'NK cells'],\n                               score_by = 'ROI_individual',\n                               phenotype='phenotype',\n                               method='radius',\n                               radius=20,\n                               subset=None, \n                               label='spatial_pscore')\n</code></pre> <pre><code>Identifying neighbours within 20 pixels of every cell\nFinding neighbourhoods with Tumor\nFinding neighbourhoods with NK cells\nPlease check:\nadata.obs['spatial_pscore'] &amp;\nadata.uns['spatial_pscore'] for results\n</code></pre> <pre><code># Plot only `Proximity Volume` scores\nplt.figure(figsize=(10, 5))\nsm.pl.spatial_pscore (adata, color='Black', plot_score='Proximity Volume')\n</code></pre> <pre><code>/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning:\n\nPass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n</code></pre> <p></p> <pre><code># Plot only `Proximity Density` scores\nplt.figure(figsize=(10, 5))\nsm.pl.spatial_pscore (adata, color='Black', plot_score='Proximity Density')\n</code></pre> <pre><code>/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning:\n\nPass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n</code></pre> <p></p> <pre><code># voronoi plot\nplt.rcParams['figure.figsize'] = [15, 10]\nsm.pl.voronoi(adata, color_by='spatial_pscore', \n                 voronoi_edge_color = 'black',\n                 voronoi_line_width = 0.3, \n                 voronoi_alpha = 0.8, \n                 size_max=5000,\n                 overlay_points=None, \n                 plot_legend=True, \n                 legend_size=6)\n</code></pre> <p></p> <pre><code># save adata\nadata.write(str(common_path) + 'may2022_tutorial.h5ad')\n</code></pre> <pre><code>/opt/anaconda3/envs/scimap/lib/python3.9/site-packages/anndata/_core/anndata.py:1228: FutureWarning:\n\nThe `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Reordering categories will always return a new Categorical object.\n\n... storing 'spatial_pscore' as categorical\n</code></pre> <p>This concludes this tutorial</p>"},{"location":"tutorials/archive/6_animate_with_scimap/","title":"Animate with scimap","text":"<pre><code># 31 May 2022\n# Animate UMAP with SCIMAP\n# Ajit Johnson Nirmal\n</code></pre>"},{"location":"tutorials/archive/6_animate_with_scimap/#preparing-data","title":"Preparing Data","text":"<p>The objective is to create an animation showing transition between UMAP plot and XY coordinate plot in spatial data.</p> <p>Let us use the same data that we used in the previous tutorial.</p> <pre><code># Let us start off with importing scimap\nimport scimap as sm\n</code></pre> <pre><code># let us import the same data that we using the previous tutorial\n# Check out the previous tutorial for details\ncommon_path = \"/Users/aj/Dropbox (Partners HealthCare)/conferences/scimap_tutorial/may_2022_tutorial/\"\nadata = sm.pp.mcmicro_to_scimap (feature_table_path= str(common_path) + 'exemplar_001/quantification/unmicst-exemplar-001_cell.csv')\n</code></pre> <pre><code>Loading unmicst-exemplar-001_cell.csv\n</code></pre> <p>All you need to be aware of is that you would need the XY coordinates in <code>adata.obs</code>. Check out the first two columns below. </p> <pre><code>adata.obs.head(3)\n</code></pre> X_centroid Y_centroid Area MajorAxisLength MinorAxisLength Eccentricity unmicst-exemplar-001_cell_1 1768.330435 257.226087 115 12.375868 11.823117 0.295521 unmicst-exemplar-001_cell_2 1107.173913 665.869565 92 11.874070 9.982065 0.541562 unmicst-exemplar-001_cell_3 1116.290323 671.338710 62 9.995049 8.673949 0.496871 <p>We already have one of the coordinate systems in place (i.e. the XY system). Let us generate the other coordinate system. We are going to perform <code>UMAP</code> but you can use any other method such as <code>PCA</code> or <code>TSNE</code> etc...</p> <pre><code># Run UMAP in scimap\nadata = sm.tl.umap (adata)\n</code></pre> <pre><code>OMP: Info #270: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n</code></pre> <pre><code>\n</code></pre> <p>If you are interested to know where the umap results are stored, it is in <code>adata.obsm</code>.  You might also need to know this if you plan to pass in your custom coordinate systems. You could save your custom coordinates as a 2D array in <code>adata.obsm</code> and call it in the <code>sm.hl.animate()</code> function</p> <pre><code># take a sneek peek at the UMAP results\nadata.obsm['umap']\n</code></pre> <pre><code>array([[ 5.8368936,  5.994031 ],\n       [ 7.6336074,  8.640663 ],\n       [ 7.0792394,  8.212058 ],\n       ...,\n       [ 9.53943  , 11.315233 ],\n       [ 8.265402 , 12.259403 ],\n       [ 5.8973293,  6.0002956]], dtype=float32)\n</code></pre> <p>Now that we are set with both the coordinate systems can create the animation. However, it may be still a bit dull as we do not have intersting way to color the plot.  A common way to color a plot is by its cell-types. As I had showed previously, you could use scimap's cell phenotyping method to identify cell types. For simplicity let us cluster the data and color by those clusters.</p> <pre><code># Perform k means clustering with k=5 and save the results in a column called kmeans\nadata = adata = sm.tl.cluster (adata, k= 5, method = 'kmeans', label='kmeans')\n</code></pre> <pre><code>Kmeans clustering\n</code></pre> <pre><code># check results\nadata.obs['kmeans'].value_counts()\n</code></pre> <pre><code>1    5050\n4    4345\n0     996\n3     703\n2      76\nName: kmeans, dtype: int64\n</code></pre> <p>As you can see above we have identified 5 clusters.</p>"},{"location":"tutorials/archive/6_animate_with_scimap/#time-for-animation","title":"Time for Animation","text":"<p>Here is the documentaion for all the parameters that are available within the <code>animate</code> function. Something to keep in mind is that not all IDE's are able to render the animation and so I highly recommend saving the animation to disk before viewing it. As saving takes quiet a long time, I generally optimize the look of the animation by subsampling the data. Sometimes <code>jupyter notebook</code> just renders a still image and so that might also help with optimization. </p> <pre><code>sm.hl.animate (adata, color='kmeans')\n</code></pre> <p></p> <p>Let us now save the animation to disk. In order to save the animation you would need something called <code>imagemagick</code> installed on your computer. Please follow this link to install it. </p> <p>To save the animation to your disk pass, the path to the location, along with the file name like so: <code>save_animation = \"/path/to/directory/my_figure\"</code></p> <pre><code>sm.hl.animate (adata, color='kmeans',\n               save_animation = '/Users/aj/Downloads/test')\n</code></pre> <pre><code>Saving file- This can take several minutes to hours for large files\n</code></pre> <p></p> <p>You might notice that the <code>gif</code> images are quiet large. I will add supoort to saving as <code>mp4</code> soon.  I generally use some online tool to convert it to <code>mp4</code> for reducing the file size. </p> <p>There are a number of <code>parameters</code> to play around with to customize the look of the animation. Check out the documentation for more details. <pre><code>palette=None, \nsubset=None, subsample=None,\nuse_layer=None, use_raw=False, log=False, \nn_frames=50, interval=50, reverse=True, final_frame=5, \ns=None, alpha=1, cmap='vlag', tight_layout=True, \nplot_legend=False, title=None, fontsize=20, pltStyle=None,\nfigsize=(5, 5)\n</code></pre></p> <p>Please note you can only plot one image at a time as in most cases the XY are unique to each image. If you are working with a dataset with multiple images, please use the <code>subset</code> parameter to subset the one image that you want to plot. As I mentioned earlier use the <code>subsample</code> parameter to optimize the feel of the plot. </p> <p>You could also <code>color</code> the plot by expression of a particular marker by using and these parmaters control different aspects of it <code>use_layer=None, use_raw=False, log=False</code> </p> <pre><code>sm.hl.animate (adata, color='CD45')\n</code></pre> <p></p> <p>Use <code>n_frames=50, interval=50, reverse=True, final_frame=5</code> to control the smoothness and duration of the animation. You can also change the theme/ background of the plot using the <code>pltStyle=None</code> paramater. </p> <pre><code>sm.hl.animate (adata, color='kmeans', pltStyle='dark_background', s=1)\n</code></pre> <p></p> <p>Note that I changed the dot size with <code>s=1</code> in the above plot. If you think that is still large, increase  the size of the entire figure using <code>figsize = (25,25)</code> which will retrospectively make the points smaller. </p>"},{"location":"tutorials/archive/6_animate_with_scimap/#happy-animating","title":"Happy Animating.","text":"<p>I would love to see what you create. Tag me on twitter.</p>"},{"location":"tutorials/md/add_rois_scimap/","title":"\ud83d\ude4c Add Region of Interest (ROIs) for Comparitive Analysis","text":"<p>Frequently, adding Regions of Interest (ROIs) to an image is crucial for conducting comparative analysis, such as identifying distinct histological sites, tumor regions, or boundaries. To incorporate ROIs into scimap, there are two approaches:</p> <ol> <li>Directly drawing on the image using napari.</li> <li>For images stored on OMERO, ROIs can be added, exported, and then imported into scimap.</li> </ol> <pre><code># import packages\nimport scimap as sm\nimport anndata as ad\n</code></pre> <pre><code>Running SCIMAP  1.3.14\n</code></pre> <pre><code># Load the data that we saved in the last tutorial (cell phenotyping)\nadata = ad.read_h5ad('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre>"},{"location":"tutorials/md/add_rois_scimap/#1-add-rois-via-napari","title":"1. Add ROIs via Napari","text":"<p>When you open napari, a new layer named \"ROI\" is automatically added by default. To create Regions of Interest, select the \"Add Polygons\" tool and draw your desired ROIs, which can include multiple polygons. You also have the option to rename this layer to something more specific, such as \"Tumor Regions.\" For different classes of ROIs, like stromal regions, simply create a new layer and repeat the process.</p> <p>It's important to note that ROIs should not overlap, since each cell can only be assigned to one unique ROI.</p> <p>To save the ROIs, simply close the napari window.</p> <pre><code>%gui qt\nimage_path = '/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/registration/exemplar-001.ome.tif'\n</code></pre> <pre><code>adata = sm.pl.addROI_image(image_path, adata)\n</code></pre> <pre><code>        Opening Napari;\n        Add shape layers (on left) to draw ROI's. \n        Rename the shape layer to give a name to your ROI\n        Multiple shape layers are supported\n        ROI's should not overlap\n        Close Napari to save ROI's.\n\nIdentifying cells within selected ROI's\nROIs saved under adata.obs['ROI']\n</code></pre> <pre><code>\n</code></pre> <p>I've created three layers, \"ROI1\", \"ROI2\" and \"ROI3\" with each layer containing several designated areas.</p> <pre><code># print the number of cells within the assigned ROIs\nadata.obs['ROI'].value_counts()\n</code></pre> <pre><code>ROI\nOther    9132\nROI3     1513\nROI2      497\nROI1       59\nName: count, dtype: int64\n</code></pre> <pre><code># check the added ROIs\nsm.pl.spatial_scatterPlot (adata, colorBy = ['ROI'],figsize=(3,3), s=0.7, fontsize=5, catCmap='Set1')\n</code></pre> <p></p> <pre><code># We can now do any downstream analysis for example let's look at the distribution of cell types within these ROIs\nsm.pl.stacked_barplot (adata, x_axis='ROI', y_axis='phenotype')\n</code></pre> <p></p> <pre><code># or look at the correaltion of cell types between ROIs\nsm.pl.groupCorrelation(adata, groupBy='phenotype', condition='ROI', figsize=(6,4))\n</code></pre> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/plotting/groupCorrelation.py:127: FutureWarning:\n\nThe default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n</code></pre> <p></p> <pre><code>\n</code></pre>"},{"location":"tutorials/md/add_rois_scimap/#2-add-rois-via-omero","title":"2. Add ROIs via Omero","text":"<p><code>sm.hl.add_roi_omero</code> function seamlessly integrates Regions of Interest ( ROIs) extracted from Omero into AnnData object.</p> <p>The function allows users to add annotations that have been extracted from Omero using the following script</p> <p>The script will download a CSV file. The same conditions apply as before. No ROI should overlap. </p> <pre><code>roi_df = pd.read_csv('path/to/roi.csv')\n\n# Add ROIs to a single image dataset\nadata = sm.hl.addROI_omero(adata, roi=roi_df, label='Omero_ROI')\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/md/add_rois_scimap/#save-results","title":"Save Results","text":"<pre><code># Save the results\nadata.write('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/md/animate_scimap/","title":"\ud83d\udc69\u200d\ud83c\udfa8 Animate with SCIMAP!","text":"<p>The goal is to produce an animation that illustrates the transition from a UMAP plot to an XY coordinate plot within spatial data.</p> <pre><code># import packages\nimport scimap as sm\nimport anndata as ad\n</code></pre> <pre><code>Running SCIMAP  1.3.8\n</code></pre> <pre><code># Load the data that we saved in the last tutorial (with ROIs added)\nadata = ad.read_h5ad('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre> <p>To transition between physical XY coordinates and UMAP, we first require the UMAP coordinates.</p>"},{"location":"tutorials/md/animate_scimap/#set-up","title":"Set Up","text":"<pre><code>adata = sm.tl.umap (adata)\n</code></pre> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/umap/umap_.py:1943: UserWarning:\n\nn_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n</code></pre> <p>With both coordinate systems ready, we can proceed to create the animation. However, without a compelling coloring method, the plot might still appear lackluster. A popular approach to color a plot involves using cell types. As previously demonstrated, you can employ scimap's cell phenotyping method for identifying cell types. For the sake of simplicity, let's cluster the data and color it based on those clusters.</p> <pre><code>adata = adata = sm.tl.cluster (adata, k= 5, method = 'kmeans', label='kmeans')\n</code></pre> <pre><code>Kmeans clustering\n\n\n/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning:\n\nThe default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n</code></pre>"},{"location":"tutorials/md/animate_scimap/#animate","title":"Animate","text":"<p>Consult the documentation to explore all available parameters within the animate function. It's important to remember that not all IDEs can render animations directly, so it's advisable to save the animation to disk for viewing. Since saving can take a considerable amount of time, optimizing the animation's appearance through data subsampling is a common practice. Additionally, keep in mind that sometimes Jupyter Notebooks may only display a still image, which can also contribute to optimization efforts.</p> <pre><code>sm.hl.animate (adata, color='kmeans')\n</code></pre> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/helpers/animate.py:241: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/helpers/animate.py:420: UserWarning:\n\nNo data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n</code></pre> <p></p> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/matplotlib/animation.py:892: UserWarning:\n\nAnimation was deleted without rendering anything. This is most likely not intended. To prevent deletion, assign the Animation to a variable, e.g. `anim`, that exists until you output the Animation using `plt.show()` or `anim.save()`.\n</code></pre> <p>Now, let's proceed to save the animation to disk. To do this, you'll need to have ImageMagick installed on your computer. Please visit the provided link to install it.</p> <p>To save the animation on your disk, specify the path to the desired directory and the file name in the following manner: <code>save_animation = \"/path/to/directory/my_figure\"</code>.</p> <pre><code>sm.hl.animate (adata, color='kmeans', save_animation = '/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData')\n</code></pre> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/helpers/animate.py:241: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/helpers/animate.py:420: UserWarning:\n\nNo data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n\nMovieWriter imagemagick unavailable; using Pillow instead.\n\n\nSaving file- This can take several minutes to hours for large files\n</code></pre> <p></p> <p>You may find that the GIF images generated are quite large. Support for saving as MP4 will be added shortly, which typically helps in reducing file size. In the meantime, I often resort to using an online tool to convert the GIFs to MP4 format.</p> <p>Additionally, there are several parameters you can adjust to customize the animation's appearance. For more information on these options, please refer to the documentation.</p> <pre><code>palette=None, \nsubset=None, \nsubsample=None,\nuse_layer=None, \nuse_raw=False, \nlog=False, \nn_frames=50, \ninterval=50, \nreverse=True, \nfinal_frame=5, \ns=None, \nalpha=1, \ncmap='vlag', \ntight_layout=True, \nplot_legend=False, \ntitle=None, \nfontsize=20, \npltStyle=None,\nfigsize=(5, 5)\n</code></pre> <p>It's important to remember that you can plot only one image at a time since the XY coordinates are typically unique to each image. When dealing with a dataset that contains multiple images, utilize the <code>subset</code> parameter to select the specific image you wish to plot. As previously advised, you can use the <code>subsample</code> parameter to refine the appearance of the plot.</p> <p>Additionally, you have the option to color the plot based on the expression of a specific marker. The parameters <code>use_layer=None</code>, <code>use_raw=False</code>, and <code>log=False</code> allow you to control various aspects of this feature.</p> <pre><code>sm.hl.animate (adata, color='CD45')\n</code></pre> <p></p> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/matplotlib/animation.py:892: UserWarning:\n\nAnimation was deleted without rendering anything. This is most likely not intended. To prevent deletion, assign the Animation to a variable, e.g. `anim`, that exists until you output the Animation using `plt.show()` or `anim.save()`.\n</code></pre> <p>To adjust the smoothness and length of the animation, set <code>n_frames=50</code>, <code>interval=50</code>, <code>reverse=True</code>, and <code>final_frame=5</code>. For customizing the plot's theme or background, use the <code>pltStyle=None</code> parameter.</p> <pre><code>sm.hl.animate (adata, color='kmeans', pltStyle='dark_background', s=1)\n</code></pre> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/helpers/animate.py:241: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/helpers/animate.py:420: UserWarning:\n\nNo data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n</code></pre> <p></p> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/matplotlib/animation.py:892: UserWarning:\n\nAnimation was deleted without rendering anything. This is most likely not intended. To prevent deletion, assign the Animation to a variable, e.g. `anim`, that exists until you output the Animation using `plt.show()` or `anim.save()`.\n</code></pre> <p>In the plot mentioned above, I adjusted the dot size to <code>s=1</code>. Should you still find the dots too large, consider enlarging the whole figure by setting <code>figsize = (25,25)</code>, which will effectively reduce the relative size of the points.</p> <p>Happy Animating.</p> <p>I'm excited to see what you come up with. Don't forget to tag us on Twitter!</p> <pre><code>\n</code></pre>"},{"location":"tutorials/md/anndata_scimap/","title":"\ud83e\udd77 Getting started with SCIMAP","text":"<pre><code># import scimap\nimport scimap as sm\n</code></pre> <pre><code>Running SCIMAP  1.3.12\n</code></pre> <p>The sample data provided is generated by the mcmicro pipeline. Let's begin by exploring how to seamlessly import mcmicro pipeline output into Scimap with a straightforward single-line command.</p> <p>In this section of the tutorial, we'll be working with the single-cell data you've obtained, located within the directory \"scimapExampleData/quantification\". This dataset is rich with information, encompassing not just the expressions of various markers in individual cells but also valuable metadata such as XY coordinates and cell sizes. </p> <pre><code># Provide the path to the single-cell feature table. Note that you can specify multiple paths as a list.\nfeature_table_path = [\"/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/quantification/exemplar-001--unmicst_cell.csv\"]\n\n# create the annData object\nadata = sm.pp.mcmicro_to_scimap(feature_table_path)\n</code></pre> <pre><code>Loading exemplar-001--unmicst_cell.csv\n</code></pre>"},{"location":"tutorials/md/anndata_scimap/#exploring-contents-of-the-anndata-object","title":"Exploring contents of the annData object","text":"<pre><code>adata\n\n# The dataset contains 11201 cells and 9 markers\n# The obs sections contains the meta data related to each cell\n</code></pre> <pre><code>AnnData object with n_obs \u00d7 n_vars = 11201 \u00d7 9\n    obs: 'X_centroid', 'Y_centroid', 'Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation', 'CellID', 'imageid'\n    uns: 'all_markers'\n    layers: 'log'\n</code></pre> <pre><code># print the contents of the expression matrix. \n# By default on import, scimap applies a log transformation, you could set `log=False` if it is already log transformed\nadata.X\n</code></pre> <pre><code>array([[7.0737187 , 5.09012558, 6.56401223, ..., 6.56296306, 5.32982432,\n        6.75017136],\n       [7.02618545, 5.1830041 , 6.67364145, ..., 6.93618427, 5.96229317,\n        6.80626408],\n       [7.13129875, 5.06030083, 6.67480083, ..., 7.19693192, 5.66577023,\n        6.8434742 ],\n       ...,\n       [7.07756235, 5.31643791, 6.67671156, ..., 6.89449634, 5.64170442,\n        6.80208784],\n       [6.90256944, 5.31600484, 6.31401645, ..., 6.7339149 , 5.45318208,\n        6.77120455],\n       [7.06054074, 5.45066285, 6.32567977, ..., 6.34348493, 5.14151735,\n        6.73978032]])\n</code></pre> <pre><code># print metadata\nadata.obs\n</code></pre> X_centroid Y_centroid Area MajorAxisLength MinorAxisLength Eccentricity Solidity Extent Orientation CellID imageid exemplar-001--unmicst_cell_1 1767.692308 257.290598 117 12.402944 12.006487 0.250814 0.959016 0.812500 -1.146733 1 exemplar-001--unmicst_cell exemplar-001--unmicst_cell_2 1107.173913 665.869565 92 11.874070 9.982065 0.541562 0.948454 0.696970 -0.435290 2 exemplar-001--unmicst_cell exemplar-001--unmicst_cell_3 1116.413793 671.068966 58 10.113305 7.629922 0.656364 0.878788 0.585859 1.221658 3 exemplar-001--unmicst_cell exemplar-001--unmicst_cell_4 982.728625 677.029740 269 25.433196 15.183300 0.802251 0.835404 0.531621 -0.705293 4 exemplar-001--unmicst_cell exemplar-001--unmicst_cell_5 1141.071078 680.125000 408 26.604670 19.759781 0.669604 0.937931 0.739130 -0.711002 5 exemplar-001--unmicst_cell ... ... ... ... ... ... ... ... ... ... ... ... exemplar-001--unmicst_cell_11197 1270.593750 3131.731250 160 19.414487 11.039993 0.822582 0.893855 0.701754 -1.364872 11197 exemplar-001--unmicst_cell exemplar-001--unmicst_cell_11198 1177.349057 3130.839623 106 14.080819 10.062622 0.699499 0.876033 0.706667 1.478579 11198 exemplar-001--unmicst_cell exemplar-001--unmicst_cell_11199 1255.904762 3131.285714 105 15.623503 9.143181 0.810875 0.882353 0.596591 -1.065479 11199 exemplar-001--unmicst_cell exemplar-001--unmicst_cell_11200 1354.448276 3131.810345 58 9.779089 7.836216 0.598231 0.878788 0.725000 -1.072712 11200 exemplar-001--unmicst_cell exemplar-001--unmicst_cell_11201 1125.662500 3133.100000 80 14.311249 7.225347 0.863194 0.941176 0.714286 1.370610 11201 exemplar-001--unmicst_cell <p>11201 rows \u00d7 11 columns</p> <pre><code># lastly lets print the markers\nadata.var\n</code></pre> ELANE CD57 CD45 CD11B SMA CD16 ECAD FOXP3 NCAM <p>Upon inspection, you will note the following characteristics about the data: it has undergone log transformation, is devoid of DNA channels, and lacks background channels. By default, the data has been processed to address key considerations: it has been log-transformed, DNA channels have been removed, and background channels have been excluded. However, these preprocessing steps can be customized or overridden as needed.</p>"},{"location":"tutorials/md/anndata_scimap/#what-if-your-data-was-not-generated-using-the-mcmicro-pipeline","title":"\ud83e\uddd0 What if your data was not generated using the MCMICRO pipeline?","text":"<p>If you're working with data not produced by mcmicro, it's crucial to consult the documentation for each function used in this series of tutorials. Each function operates under specific assumptions about its parameters. For instance, all spatial functions assume that XY coordinates are located in the 'X_centroid' and 'Y_centroid' columns. If your dataset organizes this information differently, you'll need to specify your column names when running the function.</p> <pre><code># import packages\nimport anndata as ad\nimport pandas as pd\n</code></pre> <p>After importing the necessary packages, you can create an AnnData object as shown below.</p> <pre><code># Load data\ndata = pd.read_csv ('path/to/counts_table.csv') # Counts matrix\nmeta = pd.read_csv ('path/to/meta_data.csv') # Meta data like x and y coordinates \n\n# combine the data and metadata file to generate the AnnData object\nadata = ad.AnnData (data)\nadata.obs = meta\n</code></pre> <p>When manually importing data without using the built-in function that automates the process, it is crucial to follow four essential steps to ensure compatibility and effective data management for further analysis:</p> <ol> <li> <p>Ensure Unique Image Identification: Incorporate a column named <code>imageid</code> within the metadata to assign a unique identifier to each image, especially when handling datasets comprising multiple images. This facilitates the organization and retrieval of specific image data within a larger dataset.</p> </li> <li> <p>Preserve Raw Data: Store the unprocessed raw data in <code>adata.raw</code>. This practice retains the original state of the data for reference or baseline comparisons before any preprocessing steps are applied.</p> </li> <li> <p>Log Transformation Layer: Generate a layer named <code>log</code> to hold log-transformed data. Log transformation is a critical step for normalizing data and mitigating the impact of large-scale differences across measurements, enhancing the analysis's robustness and interpretability.</p> </li> <li> <p>Marker Annotation: Maintain a record of all markers present in the images, ensuring their order matches the layers within the image data. This annotation is instrumental when loading images to precisely identify which layer corresponds to each marker, thus streamlining the analysis process by clarifying the relationship between image layers and their respective biological markers.</p> </li> </ol> <p>By adhering to these guidelines, researchers can ensure their manually imported datasets are well-organized and primed for comprehensive analysis, leveraging the full capabilities of their analytical platforms.</p> <pre><code># preserve raw data\nadata.raw = adata\n\n# log transform data\nadata = sm.pp.log1p(adata)\n\n# Add marker annotation\nadata.uns['all_markers'] = ['list', 'of', 'markers']\n</code></pre>"},{"location":"tutorials/md/anndata_scimap/#save-the-anndata-object","title":"Save the annData object","text":"<p>Once the AnnData object is created, it becomes the central data structure for all subsequent analyses. This is highly beneficial because it encapsulates all results within the object, eliminating the need to manage multiple related files. You can conveniently share this single file with collaborators, allowing them to continue the analysis seamlessly or resume from where you left off. Furthermore, numerous single-cell analysis tools, such as Scanpy, are built upon this framework. This integration allows for the straightforward application of functions from various packages without the necessity of data reformatting to suit each tool's specific requirements.</p> <pre><code># Save the results\nadata.write('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre> <pre><code>\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/md/cell_interaction_scimap/","title":"\ud83e\udd0f Cell-Cell Interaction / Proximity / Co-Occurance Analysis","text":"<p>The <code>sm.tl.spatial_interaction</code> function calculates the likelihood of cell types being adjacent to each other, compared to a permuted background, and supports 3D data. This analysis is based on cell centroids, with the option to determine neighbors either by a) a radius from the cell centroid or b) a fixed number of nearest neighbors. The measurement units depend on how the X and Y coordinates are computed. I recommend setting a neighborhood radius between 50-100 microns. By default, MCMCIRO stores XY coordinates in pixels, necessitating a conversion from pixels to microns, which varies based on magnification, binning, and other settings during image acquisition.</p> <pre><code># import packages\nimport scimap as sm\nimport anndata as ad\n</code></pre> <pre><code>Running SCIMAP  1.3.14\n</code></pre> <pre><code># Load the data that we saved in the last tutorial (with ROIs added)\nadata = ad.read_h5ad('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre>"},{"location":"tutorials/md/cell_interaction_scimap/#run-spatial-interaction-tool","title":"Run spatial interaction tool","text":"<pre><code>adata = sm.tl.spatial_interaction (adata, \n                                  method='radius', \n                                  radius=70, \n                                  label='spatial_interaction_radius')\n\n# if you would like to use set nearest neighbours use method = 'knn' and knn=10\n</code></pre> <pre><code>Processing Image: ['exemplar-001--unmicst_cell']\nCategories (1, object): ['exemplar-001--unmicst_cell']\nIdentifying neighbours within 70 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\n</code></pre> <p>Let's take a look at the results</p> <pre><code>sm.pl.spatial_interaction(adata, \n                          spatial_interaction='spatial_interaction_radius',\n                          linewidths=0.75, linecolor='black', figsize=(5,4))\n</code></pre> <p></p> <p>In the depicted plot, red and blue signify the likelihood of two cell types being adjacent to each other, while grey denotes interactions that lack significance.</p> <p>It's important to understand that when analyzing multiple images, the results represent an average across all the images involved. Since the demo contains only one image, to simulate multiple images, let's once again utilize the ROIs, treating them as distinct images for analysis purposes.</p> <pre><code># rerun the analysis with passing ROI column \nadata = sm.tl.spatial_interaction(adata, \n                                  method='radius', \n                                  imageid = 'ROI',\n                                  radius=70, \n                                  label='spatial_interaction_radius_roi')\n</code></pre> <pre><code>Processing Image: ['Other']\nCategories (1, object): ['Other']\nIdentifying neighbours within 70 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\nProcessing Image: ['ROI3']\nCategories (1, object): ['ROI3']\nIdentifying neighbours within 70 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\nProcessing Image: ['ROI1']\nCategories (1, object): ['ROI1']\nIdentifying neighbours within 70 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\nProcessing Image: ['ROI2']\nCategories (1, object): ['ROI2']\nIdentifying neighbours within 70 pixels of every cell\nMapping phenotype to neighbors\nPerforming 1000 permutations\nConsolidating the permutation results\n</code></pre> <pre><code># view the results\nsm.pl.spatial_interaction(adata, \n                          spatial_interaction='spatial_interaction_radius_roi',\n                          linewidths=0.75, linecolor='black', figsize=(5,4))\n</code></pre> <p></p> <p>This reflects the average across the images (in this case, ROIs), but let's now proceed to visualize the data for each image individually by adding <code>summarize_plot=False</code></p> <pre><code>sm.pl.spatial_interaction(adata, \n                          spatial_interaction='spatial_interaction_radius_roi',\n                          yticklabels=True, figsize=(5,10), row_cluster=True,\n                          summarize_plot=False,\n                          linewidths=0.75, linecolor='black')\n</code></pre> <p></p> <p>As seen above, each image (ROIs) is represented on the x-axis, with all pairs of interactions featured on the y-axis. The data is clustered, enabling the identification of the most significant interacting pairs across the images.</p> <p>You can also set <code>subset_phenotype</code> and <code>subset_neighbour_phenotype</code> to specifically display only cell types of interest, which is particularly useful for publications.</p> <p>Lastly, let me introduce a parameter named <code>binary_view</code>. When set to <code>True</code>, this parameter binarizes the heatmap, omitting the z-scores for simpler interpretation.</p> <pre><code>sm.pl.spatial_interaction(adata, \n                          spatial_interaction='spatial_interaction_radius',  binary_view=True,\n                          linewidths=0.75, linecolor='black', figsize=(5,4))\n</code></pre> <p></p> <p>Typically, I combine this with distance plots to understand cell distribution across the tissue. Utilizing both distance and interaction plots together effectively highlights interacting cell partners in manuscripts.</p> <pre><code># lastly we can also visualize the interactions as a network plot:\nsm.pl.spatialInteractionNetwork(adata, spatial_interaction='spatial_interaction_radius', figsize=(6,4))\n</code></pre> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scipy/stats/_stats_py.py:9694: RuntimeWarning:\n\ndivide by zero encountered in log\n</code></pre> <p></p>"},{"location":"tutorials/md/cell_interaction_scimap/#save-results","title":"Save Results","text":"<pre><code># Save the results\nadata.write('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/md/cell_proportion_scimap/","title":"\ud83e\udd29 Cell-Type Proportion Exploration","text":"<pre><code># import packages\nimport scimap as sm\nimport anndata as ad\n</code></pre> <pre><code>Running SCIMAP  1.3.14\n</code></pre> <pre><code># Load the data that we saved in the last tutorial (with ROIs added)\nadata = ad.read_h5ad('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre>"},{"location":"tutorials/md/cell_proportion_scimap/#investigate-cell-type-composition-within-the-rois","title":"Investigate cell-type composition within the ROI's","text":"<pre><code># plots the absolute count of cells within each ROI\nsm.pl.stacked_barplot (adata,\n                       x_axis='ROI',\n                       y_axis='phenotype',\n                       method='absolute')\n</code></pre> <pre><code># Plot the number of cells normalized to 100% \nsm.pl.stacked_barplot (adata,\n                       x_axis='ROI',\n                       y_axis='phenotype',\n                       method='percent')\n</code></pre> <p>The <code>stacked_barplot</code> function offers numerous additional parameters for customization. For further details, consult the documentation. For instance, it allows for plotting specific cell types, defining custom orders for both the x and y axes, passing custom color schemes, and more.</p>"},{"location":"tutorials/md/cell_proportion_scimap/#compute-the-fold-change-in-cell-types-across-various-rois","title":"Compute the fold change in cell types across various ROIs.","text":"<pre><code>adata = sm.tl.foldchange (adata, \n                          from_group=['ROI1'], \n                          to_group=None, \n                          imageid='ROI', \n                          phenotype='phenotype',\n                          normalize=True, \n                          subset_phenotype=None, \n                          label='foldchange')\n</code></pre> <pre><code>calculating foldchange\ncalculating P values\n\n\n/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/tools/foldchange.py:110: FutureWarning:\n\nSetting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['ROI1', 'ROI1', 'ROI1', 'ROI1', 'ROI1', ..., 'ROI1', 'ROI1', 'ROI1', 'ROI1', 'ROI1']\nLength: 59\nCategories (1, object): ['ROI1']' has dtype incompatible with category, please explicitly cast to a compatible dtype first.\n\n/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/tools/foldchange.py:111: FutureWarning:\n\nSetting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['Immune', 'ECAD+', 'Immune', 'Immune', 'Immune', ..., 'Unknown', 'Unknown', 'ECAD+', 'ECAD+', 'ECAD+']\nLength: 59\nCategories (3, object): ['ECAD+', 'Immune', 'Unknown']' has dtype incompatible with category, please explicitly cast to a compatible dtype first.\n\n/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/tools/foldchange.py:116: FutureWarning:\n\nSetting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['Other', 'Other', 'Other', 'Other', 'Other', ..., 'Other', 'Other', 'Other', 'Other', 'Other']\nLength: 11142\nCategories (3, object): ['Other', 'ROI2', 'ROI3']' has dtype incompatible with category, please explicitly cast to a compatible dtype first.\n</code></pre> <pre><code># Now let's plot the results\n\nsm.pl.foldchange (adata, label='foldchange', method='heatmap', p_val=0.05, nonsig_color='grey', figsize=(5,5),\n                  log=True, center=0, linecolor='black',linewidths=1)\n</code></pre> <pre><code># lets plot the same results differently (this would be more useful when you have more groups to compare)\n\n# Parallel_coordinates plot of the foldchanges\nsm.pl.foldchange (adata, label='foldchange', \n                log=True, method='parallel_coordinates', \n                invert_axis=True,\n                xticks_rotation=90,\n                return_data = False)\n</code></pre>"},{"location":"tutorials/md/cell_proportion_scimap/#exploring-the-phenotypes-overlaid-on-a-umap","title":"Exploring the phenotypes overlaid on a UMAP","text":"<pre><code># view the phenotype on a UMAP\nadata = sm.tl.umap(adata)\n</code></pre> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/umap/umap_.py:1943: UserWarning:\n\nn_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n</code></pre> <pre><code>sm.pl.umap(adata, color=['ECAD', 'CD45', 'phenotype'], s=0.5, figsize=(20, 4))\n</code></pre> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/plotting/umap.py:290: UserWarning:\n\nNo data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n</code></pre>"},{"location":"tutorials/md/cell_proportion_scimap/#exploring-the-expression-of-markers-with-phenotypes","title":"Exploring the expression of markers with phenotypes","text":"<pre><code># Heatmap (here values over 0.5 are considered positive as we have scaled the data)\nsm.pl.heatmap(adata, groupBy='phenotype', standardScale=None, figsize=(6,3), showPrevalence=True, vmin=0, vmax=1)\n</code></pre> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/plotting/heatmap.py:312: UserWarning:\n\nThis figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n</code></pre>"},{"location":"tutorials/md/cell_proportion_scimap/#exploring-the-correlation-of-markers","title":"Exploring the correlation of markers","text":"<pre><code>sm.pl.markerCorrelation(adata, figsize=(6,4))\n</code></pre>"},{"location":"tutorials/md/cell_proportion_scimap/#exploring-the-correlation-of-abundance-of-cell-types-between-conditions","title":"Exploring the correlation of abundance of cell types between conditions","text":"<pre><code>sm.pl.groupCorrelation(adata, groupBy='ROI', condition='phenotype', figsize=(6,4))\n</code></pre> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/plotting/groupCorrelation.py:127: FutureWarning:\n\nThe default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n</code></pre>"},{"location":"tutorials/md/cell_proportion_scimap/#save-results","title":"Save Results","text":"<pre><code># Save the results\nadata.write('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/md/clustering_scimap/","title":"\ud83e\udd39\ud83c\udffc\u200d\u2642\ufe0f Cell phenotyping by unsupervised clustering of the single cell data","text":"<pre><code># import packages\nimport scimap as sm\nimport anndata as ad\n</code></pre> <pre><code>Running SCIMAP  1.3.12\n</code></pre> <pre><code># Load the data that we saved in the last tutorial - (Prepare data for SCIMAP)\nadata = ad.read_h5ad('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre> <p><code>sm.tl.cluster</code> function can be used for clustering cells within the dataset. It supports three popular clustering algorithms:</p> <ul> <li>kmeans</li> <li>phenograph</li> <li>leiden</li> </ul> <p>Users are encouraged to select the clustering algorithm that best matches their data's nature and their analytical goals.</p> <pre><code>adata = sm.tl.cluster(adata, method='leiden', resolution=0.3, use_raw=False, log=False)\n</code></pre> <pre><code>Leiden clustering\n\n\n/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scanpy/preprocessing/_pca.py:229: ImplicitModificationWarning:\n\nSetting element `.obsm['X_pca']` of view, initializing view as actual.\n</code></pre> <pre><code># view the results\nadata.obs['leiden'].value_counts()\n</code></pre> <pre><code>leiden\n0    3895\n1    2661\n2    1563\n3    1223\n4     820\n5     496\n6     462\n7      81\nName: count, dtype: int64\n</code></pre> <pre><code>\n</code></pre> <p>Now, let us construct a heatmap to examine the expression levels of specific markers across each identified cluster.</p> <pre><code>sm.pl.heatmap(adata, groupBy='leiden', standardScale='column', figsize=(5,4), showPrevalence=True)\n</code></pre> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/plotting/heatmap.py:312: UserWarning:\n\nThis figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n</code></pre> <p></p> <pre><code>\n</code></pre> <p>Based on the expression profile of markers, we shall assign a cell type to each cluster. Utilize the <code>rename</code> function for this purpose.</p> <pre><code>rename_dict = {'Tumor': ['5','1'],\n               'Myeloid': ['2'],\n               'Treg': ['6'],\n               'Vessels': ['4'],\n               'Artifacts': ['7'],\n                'Immune': ['3','0']}\n\nadata = sm.hl.rename(adata, rename=rename_dict, from_column='leiden', to_column='leiden_phenotype')\n</code></pre> <pre><code>Renaming 5 to Tumor\nRenaming 1 to Tumor\nRenaming 2 to Myeloid\nRenaming 6 to Treg\nRenaming 4 to Vessels\nRenaming 7 to Artifacts\nRenaming 3 to Immune\nRenaming 0 to Immune\n</code></pre> <pre><code># now rebuild the heatmap to verify the expression pattern of markers within each cell type\nsm.pl.heatmap(adata, groupBy='leiden_phenotype', standardScale='column', figsize=(5,4), showPrevalence=True)\n</code></pre> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/plotting/heatmap.py:312: UserWarning:\n\nThis figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n</code></pre> <p></p> <pre><code>\n</code></pre> <p>I often overlay the defined cell types on a spatial scatterplot too, just to see if they match up with the tissue's histology.</p> <pre><code>sm.pl.spatial_scatterPlot (adata, colorBy = ['leiden_phenotype'],figsize=(3,3), s=0.7, fontsize=5, catCmap='Set1')\n</code></pre> <p></p> <pre><code>%gui qt\n</code></pre> <p>While useful, to ensure accurate cell type assignment, you'd want to overlay the cell types on the actual image. By examining marker combinations, confirm the assignments are correct. If not, adjust the clustering parameters and refine the cell types.</p> <pre><code># pass in the path to the image\nimage_path = '/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/registration/exemplar-001.ome.tif'\n\n# view in napari\nsm.pl.image_viewer(image_path=image_path, \n                   adata=adata, \n                   overlay='leiden_phenotype', \n                   point_size=10,\n                   point_color='white')\n\n# Note that if your AnnotatedData object (adata) includes multiple images, \n# you can use the `subset` parameter to specify the image name found in the `imageid` column, \n# enabling the loading of just that particular image.\n</code></pre>"},{"location":"tutorials/md/clustering_scimap/#save-results","title":"Save Results","text":"<pre><code># Save the results\nadata.write('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/md/demo_data_scimap/","title":"\ud83d\udce5 SCIMAP Demo Data","text":"<p>A short guide to downloading our demo data for trying out the scimap toolbox.</p> <p>You can download the data in two methods:</p> <ol> <li>Utilize the built-in download function of scimap.</li> <li>Visit the website through your browser and manually download the data.</li> </ol>"},{"location":"tutorials/md/demo_data_scimap/#1-built-in-function","title":"1. Built in function","text":"<pre><code>import scimap as sm\n</code></pre> <pre><code>Running SCIMAP  1.3.16\n</code></pre> <pre><code># Provide a download directory\ndownload_directory = '/Users/aj/Downloads'\nsm.hl.downloadDemoData (download_directory)\n</code></pre> <pre><code>Downloading scimapExampleData.zip...\n\n\nscimapExampleData.zip: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 287M/287M [04:35&lt;00:00, 1.09MiB/s]\n\nDownloaded scimapExampleData.zip to /Users/aj/Downloads/scimapExampleData.zip\n</code></pre> <p>A zipped data folder will appear in the specified directory. Simply unzip it, and you'll be all set to start.</p>"},{"location":"tutorials/md/demo_data_scimap/#2-download-from-zonodo","title":"2. Download from Zonodo","text":"<ul> <li>Go to Zonodo</li> <li>Click on the download button</li> <li>unzip the downloaded file</li> </ul> <p>DOI: 10.5281/zenodo.10845624</p> <p>If you have any questions or encounter any issues while following the tutorial, please don't hesitate to contact us for assistance.</p>"},{"location":"tutorials/md/export_scimap/","title":"\u2b07\ufe0f Export data from SCIMAP into csv","text":"<p>After completing some analysis and when you're ready to export the data, you can utilize the specified function for this purpose. However, it's important to note that if you plan to return and continue your analysis later, you should rely on the <code>.h5ad</code> file you've saved. While exporting to a CSV file can be handy, only a subset of the data\u2014specifically, what's contained in <code>adata.obs</code> and <code>adata.X</code>\u2014is exported. Be aware that all other compartments of the data are not preserved during the CSV export process.</p> <pre><code># import packages\nimport scimap as sm\nimport anndata as ad\n</code></pre> <pre><code>Running SCIMAP  1.3.14\n</code></pre> <pre><code># Load the data that we saved in the last tutorial (with ROIs added)\nadata = ad.read_h5ad('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre> <pre><code># by default the raw data is exported\noutput_dir= '/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData'\nsm.hl.scimap_to_csv(adata, output_dir=output_dir, file_name='scimapProcessed.csv')\n</code></pre> <p>Refer to the documentation to learn how to export additional layers beyond just the raw data.</p> <pre><code>\n</code></pre>"},{"location":"tutorials/md/install_scimap/","title":"\ud83d\udcc1 Setting up SCIMAP","text":"<p>Before we set up SCIMAP, we highly recommend using an environment manager like Conda. Using an environment manager like Conda allows you to create and manage isolated environments with specific package versions and dependencies.</p> <p>Download and Install the right conda based on the opertating system that you are using</p>"},{"location":"tutorials/md/install_scimap/#lets-create-a-new-conda-environment-and-install-scimap","title":"Let's create a new conda environment and install SCIMAP","text":"<p>Use the terminal (mac/linux) and anaconda promt (windows) to run the following command</p> <pre><code>conda create --name scimap -y python=3.10\n</code></pre> <p>Install SCIMAP within the conda environment.</p> <pre><code>conda activate scimap\npip install scimap\n</code></pre>"},{"location":"tutorials/md/install_scimap/#set-up-jupyter-notebook-spyder-or-any-interactive-ide","title":"Set up Jupyter Notebook / Spyder or any interactive IDE","text":"<p>Install jupyter notebook within the conda environment</p> <pre><code>pip install notebook ipywidgets\n</code></pre> <p>After installation, open Jupyter Notebook by typing the following command in the terminal, ensuring that the cspot environment is activated and you are within the environment before executing the jupyter notebook command.</p> <pre><code>jupyter notebook\n</code></pre> <p>We will talk about how to run SCIMAP in the next tutorial.</p>"},{"location":"tutorials/md/proximity_scimap/","title":"\u2696\ufe0f Tool for Computing Proximity Scores between Samples","text":"<pre><code># import packages\nimport scimap as sm\nimport anndata as ad\n</code></pre> <pre><code>Running SCIMAP  1.3.14\n</code></pre> <pre><code># Load the data that we saved in the last tutorial (with ROIs added)\nadata = ad.read_h5ad('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre> <p>Quantifying the proximity score with <code>sm.tl.spatial_pscore</code> offers a systematic way to evaluate the closeness between specific cell types as defined by the user. </p> <p>This analysis generates two key metrics: the Proximity Density and the Proximity Volume, both of which are saved in <code>adata.uns</code>. </p> <p>Proximity Density reflects the ratio of identified interactions to the total number of cells of the interacting types, providing insight into how frequently these cell types interact relative to their population size. </p> <p>Proximity Volume, on the other hand, compares the number of interactions to the total cell count in the dataset, offering a broader view of the interaction's significance across the entire sample. </p> <p>Additionally, the locations of these interaction sites are recorded and saved in <code>adata.obs</code>, allowing for detailed spatial analysis. Running this analysis can elucidate the biological significance of the spatial arrangement of cell types, which is crucial for understanding tissue structure, function, and disease pathology in a more nuanced and quantitative manner.</p> <pre><code># Calculate the score for proximity between `Tumor` cells and `Blood Vessels`\nadata =  sm.tl.spatial_pscore (adata,proximity= ['ECAD+', 'SMA+'],\n                               score_by = 'ROI',\n                               phenotype='phenotype',\n                               method='radius',\n                               radius=50)\n</code></pre> <pre><code>Identifying neighbours within 50 pixels of every cell\nPlease check:\nadata.obs['spatial_pscore'] &amp;\nadata.uns['spatial_pscore'] for results\n</code></pre> <pre><code>sm.pl.spatial_pscore (adata, color='black', plot_score='Proximity Volume', figsize=(4,2)) # \n</code></pre> <p></p> <pre><code>sm.pl.spatial_pscore (adata, color='Black', plot_score='Proximity Density', figsize=(4,2))\n</code></pre> <p></p> <p>As previously noted, the locations of these interactions are recorded, enabling us to spatially plot and examine their distribution within the tissue.</p> <pre><code>sm.pl.voronoi(adata, color_by='spatial_pscore', \n                 voronoi_edge_color = 'black',\n                 size_max=3000,\n                 voronoi_line_width = 0.3, \n                 voronoi_alpha = 0.8, \n                 overlay_points=None, \n                 plot_legend=True, \n                 legend_size=6)\n</code></pre> <p></p>"},{"location":"tutorials/md/proximity_scimap/#save-results","title":"Save Results","text":"<pre><code># Save the results\nadata.write('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/md/scimap_helper_functions/","title":"\ud83d\udc51 Additional Helper Function to make Your Life Easier","text":"<pre><code># import packages\nimport scimap as sm\nimport anndata as ad\n</code></pre> <pre><code>Running SCIMAP  1.3.14\n</code></pre> <pre><code># Load the data that we saved in the last tutorial (with ROIs added)\nadata = ad.read_h5ad('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre>"},{"location":"tutorials/md/scimap_helper_functions/#classify","title":"classify","text":"<p>The <code>sm.hl.classify</code> function allows users to annotate cells based on the presence or absence of certain markers, providing the option to apply classifications across the entire dataset or within specific subsets, such as groups of cells that have already been phenotyped or clustered. This functionality is especially useful for quickly determining the percentage of cells expressing a particular marker within a subset of interest. A prerequisite for using this function is that gating has been performed and the rescale function has been applied, as it relies on threshold-based classification.</p> <pre><code>adata.var.index\n</code></pre> <pre><code>Index(['ELANE', 'CD57', 'CD45', 'CD11B', 'SMA', 'CD16', 'ECAD', 'FOXP3',\n       'NCAM'],\n      dtype='object')\n</code></pre> <pre><code># I am going to find out how many cells are CD45 and FOXP3 positive and ECAD negative likely indicating Tregs\nadata = sm.hl.classify(adata, pos=['CD45', 'FOXP3'], neg=['ECAD'], collapse_failed=False, label='T_cell_classification')\n</code></pre> <pre><code># let's look at the results\nadata.obs['T_cell_classification'].value_counts()\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/md/scimap_helper_functions/#dropfeatures","title":"dropFeatures","text":"<p>The <code>sm.hl.dropFeatures</code> function simplifies the refinement of an adata object by allowing users to selectively exclude markers, cells, metadata columns, and particular cell groups.</p> <pre><code>adata\n</code></pre> <pre><code>AnnData object with n_obs \u00d7 n_vars = 11201 \u00d7 9\n    obs: 'X_centroid', 'Y_centroid', 'Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation', 'CellID', 'imageid', 'leiden', 'leiden_phenotype', 'ROI', 'phenotype', 'spatial_pscore', 'index_info', 'neigh_kmeans', 'RCNs', 'spatial_lda_kmeans', 'spatial_expression_kmeans', 'spatial_aggregate_radius', 'tumor_similarity_ROI1'\n    uns: 'all_markers', 'foldchange_fc', 'foldchange_pval', 'gates', 'spatial_count', 'spatial_distance', 'spatial_expression', 'spatial_interaction_radius', 'spatial_interaction_radius_roi', 'spatial_lda', 'spatial_lda_probability', 'spatial_pscore', 'tumor_similarity'\n    obsm: 'umap'\n    layers: 'log'\n</code></pre> <p>The dataset now contains 11201 cella and 9 markers</p> <pre><code># Lets drop 2 markers\nadata = sm.hl.dropFeatures(adata, drop_markers=['CD45', 'FOXP3'])\n</code></pre> <pre><code>adata\n</code></pre> <pre><code>AnnData object with n_obs \u00d7 n_vars = 11201 \u00d7 7\n    obs: 'X_centroid', 'Y_centroid', 'Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation', 'CellID', 'imageid', 'leiden', 'leiden_phenotype', 'ROI', 'phenotype', 'spatial_pscore', 'index_info', 'neigh_kmeans', 'RCNs', 'spatial_lda_kmeans', 'spatial_expression_kmeans', 'spatial_aggregate_radius', 'tumor_similarity_ROI1'\n    uns: 'all_markers', 'foldchange_fc', 'foldchange_pval', 'gates', 'spatial_count', 'spatial_distance', 'spatial_expression', 'spatial_interaction_radius', 'spatial_interaction_radius_roi', 'spatial_lda', 'spatial_lda_probability', 'spatial_pscore', 'tumor_similarity'\n    obsm: 'umap'\n    layers: 'log'\n</code></pre> <p>As you can see now the dataset contains only 7 markers</p> <pre><code># lets also drop some cells\nadata = sm.hl.dropFeatures(adata, drop_groups='ROI3', groups_column='ROI')\n</code></pre> <pre><code>adata\n</code></pre> <pre><code>AnnData object with n_obs \u00d7 n_vars = 9629 \u00d7 7\n    obs: 'X_centroid', 'Y_centroid', 'Area', 'MajorAxisLength', 'MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation', 'CellID', 'imageid', 'leiden', 'leiden_phenotype', 'ROI', 'phenotype', 'spatial_pscore', 'index_info', 'neigh_kmeans', 'RCNs', 'spatial_lda_kmeans', 'spatial_expression_kmeans', 'spatial_aggregate_radius', 'tumor_similarity_ROI1'\n    uns: 'all_markers', 'foldchange_fc', 'foldchange_pval', 'gates', 'spatial_count', 'spatial_distance', 'spatial_expression', 'spatial_interaction_radius', 'spatial_interaction_radius_roi', 'spatial_lda', 'spatial_lda_probability', 'spatial_pscore', 'tumor_similarity'\n    obsm: 'umap'\n    layers: 'log'\n</code></pre> <p>As you can see now the dataset contains only 9629 cells now</p> <pre><code>\n</code></pre>"},{"location":"tutorials/md/scimap_phenotyping/","title":"\ud83d\udc7d Cell phenotyping using a Hierarchical Prior Knowledge Table","text":"<pre><code># import packages\nimport scimap as sm\nimport anndata as ad\nimport pandas as pd\n</code></pre> <pre><code>Running SCIMAP  2.2.9\n</code></pre> <pre><code># Load the data that we saved in the last tutorial - (Prepare data for SCIMAP)\nadata = ad.read_h5ad('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre> <p>This method requires more work but is significantly more sensitive and scalable compared to clustering-based approaches.</p>"},{"location":"tutorials/md/scimap_phenotyping/#to-run-the-method-youll-need-two-main-components","title":"To run the method, you'll need two main components:","text":"<p>To successfully execute the method, you will need:</p> <ol> <li>A <code>.csv</code> file containing manual gates. Should manual gates be absent, the algorithm will attempt to adjust the data by fitting two Gaussian distributions. Nonetheless, employing manual gating is recommended due to its heightened sensitivity.</li> <li>A <code>.csv</code> file outlining a gating workflow strategy.</li> </ol> <p>The execution of the algorithm is structured into three primary steps:</p> <ol> <li>Gate Identification: Utilize <code>sm.pl.napariGater</code> to identify the gates.</li> <li>Data Rescaling: Apply <code>sm.pp.rescale</code> to adjust the data based on the identified gates.</li> <li>Phenotyping: Process the rescaled data using <code>sm.tl.phenotype</code> to run the phenotyping algorithm.</li> </ol>"},{"location":"tutorials/md/scimap_phenotyping/#step-1-define-manual-gates","title":"Step 1: Define manual gates","text":"<pre><code>%gui qt\n</code></pre> <p>This method will launch a napari window displaying several layers, each representing a different gate. You can toggle these layers on and off with the goal of identifying the gate that most accurately captures the positive cells. It's crucial to zoom and pan through the image to ensure the selected gate encompasses all positive cells throughout the image. Bear in mind that achieving 100% accuracy might not be feasible, so a certain margin of error may need to be accepted. This process is iterative, meaning adjustments may be necessary even after initial phenotyping and analysis. Manual gating must be conducted independently for each marker and each image.</p> <pre><code>image_path = '/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/registration/exemplar-001.ome.tif'\n</code></pre> <pre><code>sm.pl.napariGater (image_path, adata) # new method\n</code></pre> <pre><code>/var/folders/k5/3pb7tmfn0551jy0cf67ljdf00000gq/T/ipykernel_8388/1794404260.py:1: UserWarning:\n\nNOTE: napariGater() is currently in beta testing. If you encounter any issues, please report them at: https://github.com/labsyspharm/scimap/issues\n\n\n\nInitializing...\nLoading image data...\nCalculating contrast settings...\nInitialization completed in 0.01 seconds\nOpening napari viewer...\nNapari viewer initialized in 0.91 seconds\nGate confirmed for CD57 at 7.00\nGate confirmed for ELANE at 7.80\nGate confirmed for CD45 at 6.40\nGate confirmed for CD11B at 7.60\nGate confirmed for SMA at 7.50\nGate confirmed for CD16 at 6.50\nGate confirmed for ECAD at 7.35\nGate confirmed for FOXP3 at 7.36\nGate confirmed for NCAM at 7.00\n</code></pre> <pre><code># check the gates\nadata.uns['gates']\n</code></pre> exemplar-001--unmicst_cell markers CD11B 7.60 CD16 6.50 CD45 6.40 CD57 7.00 ECAD 7.35 ELANE 7.80 FOXP3 7.36 NCAM 7.00 SMA 7.50 <p>Remember to save the <code>adata</code> object to ensure that the gates are preserved. \ud83d\uddb4 You can perform partial gating and return later to complete the rest. The function keeps track of the markers and images you\u2019ve already gated and will display this information in the interface when you return. \ud83d\udd04\ud83c\udfaf</p>"},{"location":"tutorials/md/scimap_phenotyping/#importing-gates-via-a-csv-file","title":"Importing Gates via a CSV File \ud83d\udcc4\u2728","text":"<p>If you\u2019re not using <code>napariGater()</code>, you can also import gates using a CSV file. Here are two important points to keep in mind:</p> <p>1\ufe0f\u20e3 The marker column must be named exactly as <code>\"markers\"</code> \ud83c\udff7\ufe0f. 2\ufe0f\u20e3 The remaining columns should contain the gates for each image in the dataset. \ud83d\uddbc\ufe0f Ensure the column names precisely match the <code>'imageid'</code> column in the <code>adata</code> object. \ud83e\uddec You can retrieve it by typing: <pre><code>adata.obs['imageid']\n</code></pre></p>"},{"location":"tutorials/md/scimap_phenotyping/#multiple-images-and-uniform-gates","title":"Multiple Images and Uniform Gates \ud83d\udee0\ufe0f","text":"<p>If you have multiple images and want to apply the same gate to all of them, you have two options:</p> <p>1\ufe0f\u20e3 Copy-paste the same gate values across all columns in your CSV file. \ud83d\udd8b\ufe0f 2\ufe0f\u20e3 Alternatively, use just one column named \"gates\" (with no additional columns). In this case, the same gate will be applied to all images in your dataset, provided there is more than one image. \u2705  </p>"},{"location":"tutorials/md/scimap_phenotyping/#a-final-note","title":"A Final Note \ud83d\udcdd","text":"<p>When you run the <code>rescale</code> function without specifying anything for the <code>gate</code> parameter, it will try to auto-identify gates using a GMM (Gaussian Mixture Model) function. \u26a0\ufe0f However, this method is generally not very accurate, and we discourage relying on it. \ud83d\udeab  </p> <p>If gates are missing for some images or markers, the GMM will be automatically applied. \ud83d\udd04 Be cautious when interpreting results for those images or markers! \ud83e\uddd0  </p> <p>With these tips, you\u2019ll have more control over your gating process! \ud83d\ude80</p> <pre><code># Do the above step for each marker and then create a `.csv` file like below:\npd.read_csv('/Users/aj/Partners HealthCare Dropbox/Ajit Nirmal/nirmal lab/resources/exemplarData/scimapExampleData/manual_gates.csv')\n</code></pre> markers exemplar-001--unmicst_cell 0 ELANE 7.80 1 CD57 8.90 2 CD45 6.40 3 CD11B 7.60 4 SMA NaN 5 CD16 6.50 6 ECAD 7.35 7 FOXP3 NaN 8 NCAM 7.00 <p>You'll observe that the first column lists the markers present in the dataset, while the second column specifies the gate, named after the specific image's ID found in <code>adata.obs['imageid']</code>. This  is especially useful when dealing with datasets containing multiple images, as it allows for a distinct column for each image. I have also intentionally left out 2 markers (SMA and FOXP3) where GMM will be applied automatically. You can control the GMM using the <code>gmm_components</code> parameter.</p> <p>Although visual gating has proven to be the most sensitive method for us, you can also apply single and bi-marker gating approaches, similar to FACS, to assist in determining a threshold.</p> <pre><code># single \nsm.pl.distPlot(adata, layer='log', markers=['CD45','ECAD','FOXP3'], ncols=3, fontsize=6, figsize=(5,2))\n</code></pre> <p></p> <p>We also use bimarker gating to identify a gate</p> <pre><code>sm.pl.densityPlot2D(adata, markerA='SMA', markerB='CD45', layer='log')\n</code></pre> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/mpl_scatter_density/generic_density_artist.py:77: RuntimeWarning:\n\nAll-NaN slice encountered\n\n/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/mpl_scatter_density/generic_density_artist.py:82: RuntimeWarning:\n\nAll-NaN slice encountered\n</code></pre> <p></p>"},{"location":"tutorials/md/scimap_phenotyping/#step-2-rescale-the-data","title":"Step 2: Rescale the data","text":"<p>You can provide gating information by either inputting a <code>manual_gates.csv</code> file into the <code>gate</code> parameter or, if you used <code>napariGater</code>, directly using <code>adata.uns['gates']</code>. </p> <p>For markers not included in the <code>manual_gates.csv</code> file, the function automatically identifies gates using a Gaussian Mixture Model (GMM) algorithm. This provides thresholds for markers where manual gates are unavailable. \ud83c\udfaf  </p> <pre><code># Load the manual gates from CSV and rescale the data based on the gates\nmanual_gate = pd.read_csv('/Users/aj/Partners HealthCare Dropbox/Ajit Nirmal/nirmal lab/resources/exemplarData/scimapExampleData/manual_gates.csv')\nadata = sm.pp.rescale (adata, gate=manual_gate)\n</code></pre> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/preprocessing/rescale.py:145: FutureWarning:\n\nDowncasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n\n\n\nRunning GMM for image: exemplar-001--unmicst_cell\nApplying GMM to markers: SMA, FOXP3\n\nScaling Image: exemplar-001--unmicst_cell\nScaling ELANE (gate: 7.800)\nScaling CD57 (gate: 8.900)\nScaling CD45 (gate: 6.400)\nScaling CD11B (gate: 7.600)\nScaling SMA (gate: 6.597)\nScaling CD16 (gate: 6.500)\nScaling ECAD (gate: 7.350)\nScaling FOXP3 (gate: 6.307)\nScaling NCAM (gate: 7.000)\n</code></pre> <p>As you can see GMM was automatically applied to SMA and FOXP3</p>"},{"location":"tutorials/md/scimap_phenotyping/#step-3-run-the-phenotyping-algorithm","title":"Step 3: Run the phenotyping algorithm","text":"<pre><code># load the phenotyping workflow\nphenotype = pd.read_csv('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/phenotype_workflow.csv')\n# view the table:\nphenotype.style.format(na_rep='')\n</code></pre> Unnamed: 0 Unnamed: 1 ELANE CD57 CD45 CD11B SMA CD16 ECAD FOXP3 NCAM 0 all ECAD+ pos 1 all Immune pos 2 all SMA+ pos 3 Immune NK cells allpos neg allpos 4 Immune Other myeloid cells pos 5 Immune Treg pos 6 Other myeloid cells Dendritic cells allneg allneg <p>As it can be seen from the table above,  </p> <ol> <li>The <code>first column</code> has to contain the cell that are to be classified.  </li> <li>The <code>second column</code> indicates the phenotype a particular cell will be assigned if it satifies the conditions in the row.  </li> <li><code>Column three</code> and onward represent protein markers. If the protein marker is known to be expressed for that cell type, then it is denoted by either <code>pos</code>, <code>allpos</code>. If the protein marker is known to not express for a cell type it can be denoted by <code>neg</code>, <code>allneg</code>. If the protein marker is irrelevant or uncertain to express for a cell type, then it is left empty. <code>anypos</code> and <code>anyneg</code> are options for using a set of markers and if any of the marker is positive or negative, the cell type is denoted accordingly.</li> </ol> <p>To give users maximum flexibility in identifying desired cell types, we have implemented various classification arguments as described above for strategical classification. They include</p> <ul> <li>allpos</li> <li>allneg</li> <li>anypos</li> <li>anyneg</li> <li>pos</li> <li>neg</li> </ul> <p><code>pos</code> : \"Pos\" looks for cells positive for a given marker. If multiple markers are annotated as <code>pos</code>, all must be positive to denote the cell type. For example, a Regulatory T cell can be defined as <code>CD3+CD4+FOXP3+</code> by passing <code>pos</code> to each marker. If one or more markers don't meet the criteria (e.g. CD4-), the program will classify it as <code>Likely-Regulatory-T cell</code>, pending user confirmation. This is useful in cases of technical artifacts or when cell types (such as cancer cells) are defined by marker loss (e.g. T-cell Lymphomas).</p> <p><code>neg</code> : Same as <code>pos</code> but looks for negativity of the defined markers. </p> <p><code>allpos</code> : \"Allpos\" requires all defined markers to be positive. Unlike <code>pos</code>, it doesn't classify cells as <code>Likely-cellType</code>, but strictly annotates cells positive for all defined markers.</p> <p><code>allneg</code> : Same as <code>allpos</code> but looks for negativity of the defined markers. </p> <p><code>anypos</code> : \"Anypos\" requires only one of the defined markers to be positive. For example, to define macrophages, a cell could be designated as such if any of <code>CD68</code>, <code>CD163</code>, or <code>CD206</code> is positive.</p> <p><code>anyneg</code> : Same as <code>anyneg</code> but looks for negativity of the defined markers. </p> <pre><code>adata = sm.tl.phenotype_cells (adata, phenotype=phenotype, label=\"phenotype\") \n</code></pre> <pre><code>Phenotyping ECAD+\nPhenotyping Immune\nPhenotyping SMA+\n-- Subsetting Immune\nPhenotyping NK cells\nPhenotyping Other myeloid cells\nPhenotyping Treg\n-- Subsetting Other myeloid cells\nPhenotyping Dendritic cells\nConsolidating the phenotypes across all groups\n\n\n/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/tools/phenotype_cells.py:174: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/tools/phenotype_cells.py:290: FutureWarning:\n\nDataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n\n/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/tools/phenotype_cells.py:290: FutureWarning:\n\nDowncasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n</code></pre> <pre><code># Summary of the phenotyping\nadata.obs['phenotype'].value_counts()\n</code></pre> <pre><code>phenotype\nImmune                 3977\nECAD+                  2873\nSMA+                   1947\nUnknown                1496\nTreg                    657\nOther myeloid cells     170\nNK cells                 64\nDendritic cells          17\nName: count, dtype: int64\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/md/scimap_phenotyping/#visualisation-of-the-results","title":"Visualisation of the Results","text":"<pre><code># Heatmap (here values over 0.5 are considered positive as we have scaled the data)\nsm.pl.heatmap(adata, groupBy='phenotype', standardScale=None, figsize=(5,3), showPrevalence=True, vmin=0, vmax=1)\n</code></pre> <pre><code># view the phenotype on a UMAP\nadata = sm.tl.umap(adata)\n</code></pre> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/umap/umap_.py:1943: UserWarning:\n\nn_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n</code></pre> <pre><code>sm.pl.umap(adata, color=['phenotype'], s=1)\n</code></pre> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/plotting/umap.py:304: UserWarning:\n\nNo data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n</code></pre> <pre><code># spatial scatter plot to look at the distribution of cells\nsm.pl.spatial_scatterPlot (adata, colorBy = ['phenotype'],figsize=(2.75,2), s=0.3, fontsize=5, catCmap='Set1')\n</code></pre> <pre><code># View the results by overlaying it on the raw image\nimage_path = '/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/registration/exemplar-001.ome.tif'\n\n# view in napari\nsm.pl.image_viewer(image_path=image_path, \n                   adata=adata, \n                   overlay='phenotype', \n                   point_size=10,\n                   point_color='white')\n\n# Note that if your AnnotatedData object (adata) includes multiple images, \n# you can use the `subset` parameter to specify the image name found in the `imageid` column, \n# enabling the loading of just that particular image.\n</code></pre>"},{"location":"tutorials/md/scimap_phenotyping/#save-results","title":"Save Results","text":"<pre><code># Save the results\nadata.write('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/md/scimap_video/","title":"\ud83c\udfa5 Video Tutorials","text":""},{"location":"tutorials/md/scimap_video/#2021","title":"2021","text":"<pre><code>from IPython.display import HTML\nHTML('&lt;iframe width=\"500\" height=\"300\" src=\"https://www.youtube.com/embed/knh5elRksUk\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen&gt;&lt;/iframe&gt;')\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/md/spatial_analysis_scimap/","title":"\ud83d\udccd Simple Spatial Analysis","text":"<pre><code># import packages\nimport scimap as sm\nimport anndata as ad\n</code></pre> <pre><code>Running SCIMAP  1.3.14\n</code></pre> <pre><code># Load the data that we saved in the last tutorial (with ROIs added)\nadata = ad.read_h5ad('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre>"},{"location":"tutorials/md/spatial_analysis_scimap/#compute-the-distances-among-cell-types","title":"Compute the distances among cell types.","text":"<pre><code>adata = sm.tl.spatial_distance (adata, phenotype='phenotype')\n</code></pre> <pre><code>Processing Image: exemplar-001--unmicst_cell\n</code></pre> <p>We'll utilize built-in plotting functions for visualization; however, for those interested in conducting additional analysis or custom plotting of these distances, the results can be found in <code>adata.uns['spatial_distance']</code>.</p> <pre><code># This is one of the most complicated plotting functions in the package\n# as I packed a lot of options into one (see the documentation)\n# I will try and split this into multiple functions in the future\n# To start- let's get an overview with a heatmap\n\nsm.pl.spatial_distance (adata, figsize=(5,4))\n</code></pre> <p></p> <p>For datasets containing multiple images, the default behavior averages the distances across all images. To analyze and plot the distances for each image individually, you should set <code>heatmap_summarize</code> to <code>False</code>. Although in this example with only one image the plot will appear similar to the previous one, you'll observe a difference in the y-axis.</p> <pre><code>sm.pl.spatial_distance (adata, heatmap_summarize=False, figsize=(9,4))\n</code></pre> <p></p> <p>By default, summarization is performed using the <code>imageid</code> column, but you can also plot based on different conditions (such as control vs. treated) present in the dataset. Since we've included Regions of Interest (ROIs) in this dataset, let's attempt to plot the data based on these ROIs.</p> <pre><code>sm.pl.spatial_distance (adata, heatmap_summarize=False, imageid='ROI', figsize=(7,5))\n</code></pre> <p></p> <p>These heatmaps provide a comprehensive overview of the proximity between cell types and how this proximity varies by ROIs, conditions, or across different images. After gaining an understanding of the broader landscape and possibly formulating some hypotheses, it's time to delve into a more detailed analysis.</p> <p>Let's say there is an interest in identifying the cells closest to tumor cells; we will do the following analysis to address this interest.</p> <pre><code># Numeric plot of the shortest distance of phenotypes from tumor cells\n\nsm.pl.spatial_distance (adata, method='numeric',distance_from='ECAD+', height=3, aspect=11/8)\n</code></pre> <p></p> <p>From the above plot, it's clear that NK cells and dendritic cells are distant from the tumor cells, while other cell types are so closely positioned that it's difficult to distinguish them. So, let's log the x-axis to make the pattern more distinct.</p> <pre><code>sm.pl.spatial_distance (adata, method='numeric',distance_from='ECAD+', log=True, height=3, aspect=11/8)\n</code></pre> <p></p> <p>Excellent, now let's say you're interested in comparing these observations between different conditions in your dataset (such as control vs. treatment). Since our dataset doesn't include multiple images, we'll use the ROIs as a substitute once again, as the underlying concept remains the same.</p> <pre><code>sm.pl.spatial_distance (adata, method='numeric',distance_from='ECAD+', log=True, imageid='ROI', height=3, aspect=9/8)\n</code></pre> <p></p> <p>Now, let's say you've narrowed down to a few cell types of interest. We can also subset and display only these selected cells.</p> <pre><code>distance_to = ['SMA+', 'Treg', 'NK cells', 'Dendritic cells']\nsm.pl.spatial_distance (adata, method='numeric', \n                        distance_from='ECAD+', distance_to=distance_to, \n                        log=True, imageid='ROI', \n                        height=3, aspect=9/8)\n</code></pre> <p></p> <p>We can also visualize this using distribution plots instead of box plots, which is particularly useful if you want to demonstrate that the distance between two cell types vary across different conditions. However, in this case, the difference might not be apparent since we are working with demo data.</p> <pre><code>sm.pl.spatial_distance (adata, method='distribution',distance_from='ECAD+',distance_to = 'SMA+', imageid='ROI', log=True, height=3, aspect=9/8)\n</code></pre> <p></p>"},{"location":"tutorials/md/spatial_analysis_scimap/#save-results","title":"Save Results","text":"<pre><code># Save the results\nadata.write('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/md/spatial_biology_scimap/","title":"\ud83d\uddc2\ufe0f Mastering Spatial Analysis of Multiplex Imaging Data with SCIMAP","text":"<p>This series is designed to equip researchers, data scientists, and enthusiasts with the knowledge and tools necessary to unlock the full potential of spatial analysis techniques. Whether you're new to the field or looking to deepen your understanding, these tutorials will guide you through the intricacies of analyzing complex imaging data, enabling you to uncover the spatial relationships and patterns that lie within.</p> <p>\ud835\udd4f Let us know what else you would like to see here!</p>"},{"location":"tutorials/md/spatial_biology_scimap/#set-up","title":"Set up","text":"<p>\ud83e\udd16 Install Scimap \ud83d\udce5 Download demo data \ud83d\udcc1 Prepare demo data for analysis </p>"},{"location":"tutorials/md/spatial_biology_scimap/#cell-phenotyping","title":"Cell Phenotyping","text":"<p>\ud83e\udd39\ud83c\udffc\u200d\u2642\ufe0f Phenotype cells by unsupervised clustering \ud83d\udc7d Phenotype cells using a hierarchical probabilistic model \ud83d\ude4c Add Regions of Interest (ROIs) for exploration \ud83e\udd29 Explore the composition of defined cell types between samples and ROIs </p>"},{"location":"tutorials/md/spatial_biology_scimap/#spatial-analysis","title":"Spatial Analysis","text":"<p>\ud83d\udccd Calculate and visualize distances between cell types \ud83e\udd0f Cell-cell interaction/ co-occurrence analysis \u2696\ufe0f Compare proximity scores between samples \ud83d\udd2d Search for spatial patterns </p>"},{"location":"tutorials/md/spatial_biology_scimap/#cellular-neighbourhoods","title":"Cellular Neighbourhoods","text":"<p>\ud83c\udf33 Compute neighborhoods using cell-type or cluster information (includes LDA method) \ud83d\ude80 Compute neighborhoods using expression data </p>"},{"location":"tutorials/md/spatial_biology_scimap/#export-and-helper-functions","title":"Export and Helper Functions","text":"<p>\u2b07\ufe0f Export analysis results to <code>.csv</code> \ud83d\udc69\u200d\ud83c\udfa8 Animate with scimap \ud83d\udc51 Merge objects, Classify cells etc.. </p>"},{"location":"tutorials/md/spatial_biology_scimap/#videos","title":"Videos","text":"<p>\ud83c\udfa5 Video tutorials </p>"},{"location":"tutorials/md/spatial_lag_scimap/","title":"\ud83d\ude80 Identify Spatial Neighbourhoods on Expression Data","text":"<p>As mentioned earlier, <code>spatial_count</code> and <code>spatial_lda</code> are tailored for categorical data, specifically cell phenotypes. But what if cell types haven't been defined and there's a need to discern cellular neighborhoods directly from expression data? This approach carries both pros and cons. On the upside, there's no prerequisite to define cell types. However, interpreting neighborhoods can become challenging without defined cell types, and the method may be susceptible to batch effects. A significant advantage of working with categorical data is that, ideally, batch effects would have been addressed during the phenotyping stage, simplifying subsequent analyses.</p> <pre><code># import packages\nimport scimap as sm\nimport anndata as ad\n</code></pre> <pre><code>Running SCIMAP  1.3.14\n</code></pre> <pre><code># Load the data that we saved in the last tutorial (with ROIs added)\nadata = ad.read_h5ad('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre> <pre><code># make sure you drop markers that are background or antibodies that did not work as all these can affect your results\nadata = sm.tl.spatial_expression(adata, method='radius', radius=80, label='spatial_expression')\n</code></pre> <pre><code>Identifying neighbours within 80 pixels of every cell\n</code></pre> <pre><code># note that the df_name parameter needs to the same as the label used in the previous step.\nadata = sm.tl.spatial_cluster(adata, df_name='spatial_expression', method='kmeans', k=6, label='spatial_expression_kmeans')\n</code></pre> <pre><code>Kmeans clustering\n</code></pre> <pre><code># Let's visualize the results.\nsm.pl.voronoi(adata, color_by='spatial_expression_kmeans', \n                 voronoi_edge_color = 'black',\n                 voronoi_line_width = 0.3, \n                 voronoi_alpha = 0.8, \n                 size_max=3000,\n                 overlay_points=None, \n                 plot_legend=True, \n                 legend_size=6)\n</code></pre> <p></p> <p>Now, please return to the tutorials for <code>spatial_count</code> and <code>spatial_lda</code> to continue. The steps for understanding neighborhoods follow the same principles outlined there.</p>"},{"location":"tutorials/md/spatial_lag_scimap/#save-results","title":"Save Results","text":"<pre><code># Save the results\nadata.write('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/md/spatial_lda_scimap/","title":"\ud83c\udf33 Identify Spatial Neighbourhoods on Categorical Data (cell phenotypes)","text":"<p>In this  tutorial, we delve into the specifics of spatial analysis using categorical data, such as cell types or cluster assignments. We will guide you through two primary methods: <code>spatial_count</code> and <code>spatial_lda</code>, each offering a nuanced perspective on analyzing cellular arrangements within tissues. You'll learn not only to delineate and interpret neighborhoods but also to visualize them effectively. The tutorial culminates in exploring neighborhood-to-neighborhood correlations and interactions, equipping you with a comprehensive toolkit for spatial analysis in biological research.</p> <pre><code># import packages\nimport scimap as sm\nimport anndata as ad\n</code></pre> <pre><code>Running SCIMAP  1.3.14\n</code></pre> <pre><code># Load the data that we saved in the last tutorial (with ROIs added)\nadata = ad.read_h5ad('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre> <p>The <code>spatial_count</code> approach is straightforward. For each cell, a local neighborhood is identified and normalized, resulting in a matrix that is subsequently utilized for clustering. This process defines the spatial neighborhoods.</p>"},{"location":"tutorials/md/spatial_lda_scimap/#a-spatial_count-approach","title":"A. spatial_count approach","text":"<pre><code>adata = sm.tl.spatial_count(adata, phenotype='phenotype', method='radius', radius=80, label='spatial_count')\n</code></pre> <pre><code>Identifying neighbours within 80 pixels of every cell\n</code></pre> <p>After using the tool, the next step is to cluster the results. We'll do this with the <code>spatial_cluster</code> function. Make sure to check out the documentation to see all the different ways you can cluster. For now, we'll keep it simple and go with the k-means method.</p> <pre><code># note that the df_name parameter needs to the same as the label used in the previous step.\nadata = sm.tl.spatial_cluster(adata, df_name='spatial_count', method='kmeans', k=6, label='neigh_kmeans')\n</code></pre> <pre><code>Kmeans clustering\n</code></pre> <pre><code># Let's visualize the results.\nsm.pl.voronoi(adata, color_by='neigh_kmeans', \n                 voronoi_edge_color = 'black',\n                 voronoi_line_width = 0.3, \n                 voronoi_alpha = 0.8, \n                 size_max=3000,\n                 overlay_points=None, \n                 plot_legend=True, \n                 legend_size=6)\n</code></pre> <p></p> <p>In this example, I've chosen k=5 for clustering, but typically, I over-cluster the data and then group them into meta clusters. This approach helps ensure that no rare clusters are missed. To understand these neighborhoods, I examine the cell type composition within each one. When analyzing solid tumors, you'll often find a tumor neighborhood dominated by tumor cells, usually over 90%, and a tumor-stromal interface neighborhood that features a mix of tumor and stromal cells.</p> <pre><code># Let's plot the composition of these neighbourhoods\nsm.pl.stacked_barplot (adata, x_axis='neigh_kmeans', y_axis='phenotype')\n</code></pre> <p></p> <p>While analyzing the clusters, the cell type distribution allows us to name each neighborhood. We won't do that here since we're working with demo data, but it's worth noting that naming is more straightforward with just 6 clusters. The challenge arises when dealing with 30 or 40 clusters. To address this, I employ several strategies for grouping them into meta clusters:</p> <ol> <li>I use Plotly to create stacked bar plots, which offer added interactivity. This feature lets me toggle specific cell types on and off to examine their distribution across neighborhoods.</li> <li>I also utilize Plotly for spatial scatter plots, adding another layer of interactivity. This helps in understanding distribution based on known histology. For example, if a cluster is localized to the skin's upper layer, it likely represents a structural unit like the epidermis. Note that while scimap doesn't natively support spatial scatter plots in Plotly, I'll share a script that enables this functionality.</li> <li>Additionally, I analyze the correlation of cell type abundance across neighborhoods, aiding in grouping similar clusters together.</li> </ol> <p>Below, you'll find demonstrations of these three approaches:</p>"},{"location":"tutorials/md/spatial_lda_scimap/#1-stacked-bar-plot-with-plotly","title":"1. stacked bar plot with plotly","text":"<pre><code># you will notice that the execution of this line will open a new tab in your web browser with the plot\nsm.pl.stacked_barplot (adata, x_axis='neigh_kmeans', y_axis='phenotype', plot_tool='plotly')\n</code></pre>"},{"location":"tutorials/md/spatial_lda_scimap/#2-spatial-scatter-plot-with-plotly","title":"2. spatial scatter plot with plotly","text":"<pre><code># Vizualising using plotly\nimport pandas as pd\nimport plotly.express as px\nimport plotly.io as pio\n\ndef plotly (adata,phenotype,image_id=None,x='X_centroid',y='Y_centroid',size=2, **kwargs):\n    if image_id is not None:\n        adata = adata[adata.obs['imageid'] == image_id]    \n    data = pd.DataFrame({'x':adata.obs[x], 'y':adata.obs[y],'col': adata.obs[phenotype]})\n    data = data.sort_values(by=['col'])\n    fig = px.scatter(data, x=\"x\", y=\"y\", color=\"col\", **kwargs)\n    fig.update_traces(marker=dict(size=size),selector=dict(mode='markers'),hoverlabel = dict(namelength = -1))\n    fig.update_yaxes(autorange=\"reversed\", tickformat='g')\n    fig.update_xaxes(tickformat='g')\n    fig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)','paper_bgcolor': 'rgba(0, 0, 0, 0)'})\n    fig.show()\n</code></pre> <pre><code># you will notice that the execution of this line will open a new tab in your web browser with the plot\nplotly (adata,phenotype='neigh_kmeans', size=8)\n</code></pre>"},{"location":"tutorials/md/spatial_lda_scimap/#3-correlation-plot-to-check-which-clusters-are-similar","title":"3. Correlation plot to check which clusters are similar","text":"<pre><code>sm.pl.groupCorrelation(adata, groupBy='phenotype', condition='neigh_kmeans', figsize=(6,4))\n</code></pre> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/plotting/groupCorrelation.py:127: FutureWarning:\n\nThe default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n</code></pre> <p>After deciding which clusters to group together, use the rename function to add a new column that represents the consolidated neighborhoods.</p> <pre><code># Consolidate clusters to neighborhoods\n\nrename_dict = {'RCN1': ['1'],\n               'RCN2': ['0', '4'],\n                'RCN3': ['2'],\n                'RCN4': ['3']}\n\nadata = sm.hl.rename(adata, rename=rename_dict, from_column='neigh_kmeans', to_column='RCNs')\n</code></pre> <pre><code>Renaming 1 to RCN1\nRenaming 0 to RCN2\nRenaming 4 to RCN2\nRenaming 2 to RCN3\nRenaming 3 to RCN4\n</code></pre> <pre><code># Visualize the RCNs composition between patient groups (in this case ROIs as example)\n\nsm.pl.pie(adata, phenotype='RCNs', group_by='ROI', ncols=3)\n</code></pre> <pre><code>/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/plotting/pie.py:149: FutureWarning:\n\nThe default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n\n/Users/aj/miniconda3/envs/scimap/lib/python3.10/site-packages/scimap/plotting/pie.py:154: FutureWarning:\n\nThe default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n</code></pre> <p></p> <p>After defining the neighborhoods, all analyses previously applied to cell types can also be conducted on these neighborhoods. This includes calculating distances between neighborhoods, examining interaction patterns between and within neighborhoods, observing how these interactions vary across different neighborhoods, and analyzing fold changes in neighborhood abundance between ROIs or patient groups, among others. For guidance on executing these analyses, refer to other tutorials. The key point is that once the neighborhoods are established, a wide range of analytical possibilities becomes accessible.</p> <pre><code>\n</code></pre>"},{"location":"tutorials/md/spatial_lda_scimap/#b-spatial_lda-approach","title":"B. spatial_lda approach","text":"<p>The <code>sm.tl.spatial_lda</code> function constructs a neighborhood matrix utilizing categorical variables, such as cell types, designated by the user. It applies Latent Dirichlet Allocation (LDA) to explore the latent architecture of cellular distributions. This methodology produces weights that clarify the spatial configuration of cells, thus facilitating the identification of Recurrent Cellular Neighborhoods (RCNs). Generally, LDA is utilized for text data, aiming to cluster documents based on the frequency of word usage. It's important to note that, in contrast to text data, which may contain millions of unique words, our scenario typically involves a much smaller vocabulary\u2014often between 5 to 20 cell types. This limited \"vocabulary\" can prevent the LDA model from converging. Therefore, rather than directly utilizing the output of the LDA model, we extract latent variables post-training and cluster these to define cellular neighborhoods. This approach adapts the LDA model, commonly used for text, to effectively analyze cellular spatial distributions.</p> <pre><code># run the LDA tool\nadata = sm.tl.spatial_lda(adata, method='radius', radius=80, label='spatial_lda')\n</code></pre> <pre><code>Processing: ['exemplar-001--unmicst_cell']\nIdentifying neighbours within 80 pixels of every cell\nPre-Processing Spatial LDA\nTraining Spatial LDA\nCalculating the Coherence Score\n\nCoherence Score:  0.35570971537759294\nGathering the latent weights\n</code></pre> <pre><code># note that the df_name parameter needs to be the same as the label used in the previous step.\nadata = sm.tl.spatial_cluster(adata, df_name='spatial_lda', method='kmeans', k=6, label='spatial_lda_kmeans')\n</code></pre> <pre><code>Kmeans clustering\n</code></pre> <pre><code># Let's visualize the results.\nsm.pl.voronoi(adata, color_by='spatial_lda_kmeans', \n                 voronoi_edge_color = 'black',\n                 voronoi_line_width = 0.3, \n                 voronoi_alpha = 0.8, \n                 size_max=3000,\n                 overlay_points=None, \n                 plot_legend=True, \n                 legend_size=6)\n</code></pre> <p></p> <p>As observed, some neighborhoods resemble those identified earlier by the <code>count</code> method. No single method suits all datasets, so it's advisable to experiment with both methods and determine which yields the best results, particularly in light of known positive controls within the data, such as distinct tissue structures. </p> <p>Once neighborhoods have been defined, the downstream processes remain consistent with what was previously described\u2014endeavor to discern the significance of each neighborhood, compare them across different image/ patient groups, and formulate your hypothesis accordingly.</p>"},{"location":"tutorials/md/spatial_lda_scimap/#save-results","title":"Save Results","text":"<pre><code># Save the results\nadata.write('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre> <pre><code>\n</code></pre>"},{"location":"tutorials/md/spatial_search_scimap/","title":"\ud83d\udd2d Tools to Search for Spatial Patterns","text":"<p>Often, we seek to identify specific tissue areas that harbor a particular type of interaction or combinations of cells. Understanding the underlying histology allows us to start formulating hypotheses about these patterns.</p> <pre><code># import packages\nimport scimap as sm\nimport anndata as ad\n</code></pre> <pre><code>Running SCIMAP  1.3.14\n</code></pre> <pre><code># Load the data that we saved in the last tutorial (with ROIs added)\nadata = ad.read_h5ad('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre>"},{"location":"tutorials/md/spatial_search_scimap/#identify-regions-of-aggregation-single-cell-type","title":"Identify regions of Aggregation (single cell type)","text":"<p>The <code>sm.tl.spatial_aggregate</code> function is instrumental in identifying spatial clusters of cells that share similar phenotypes throughout the tissue. For instance, it can be utilized to locate a tumor mass by adjusting the 'purity' parameter. This adjustment grants the ability to define the minimum required similarity percentage among cells within a certain radius to classify them as part of an aggregation region. Such precision in identifying areas of cellular aggregation enhances the analysis's accuracy. For example, once the tumor domain is pinpointed, its prevalence can be compared between treatment and control groups or across designated histological sites, facilitating a deeper understanding of the tumor's spatial dynamics and potential treatment impacts.</p> <pre><code>adata = sm.tl.spatial_aggregate(adata, method='radius', radius=50, purity=80, label='spatial_aggregate_radius')\n</code></pre> <pre><code>Identifying neighbours within 50 pixels of every cell\n</code></pre> <p>Let's visualize the results. </p> <pre><code>sm.pl.voronoi(adata, color_by='spatial_aggregate_radius', \n                 voronoi_edge_color = 'black',\n                 voronoi_line_width = 0.3, \n                 voronoi_alpha = 0.8, \n                 size_max=3000,\n                 overlay_points=None, \n                 plot_legend=True, \n                 legend_size=6)\n</code></pre> <p></p> <p>As observed, although most regions do not show significant enrichment of the specified cell types, there are certain areas that meet the established criteria.</p>"},{"location":"tutorials/md/spatial_search_scimap/#identify-regions-of-aggregation-multiple-cell-type","title":"Identify regions of Aggregation (multiple cell type)","text":"<p>What if your interest lies in pinpointing areas where two or more cell types are in close proximity, potentially indicating functional significance? In that case, we can utilize the <code>spatial_pscore</code> function. Although its primary aim is to provide a quantitative measure of proximity, it also highlights the specific tissue regions where these mixed cell types are located.</p> <pre><code># Calculate the score for proximity between `Tumor` cells and `Blood Vessels`\nadata =  sm.tl.spatial_pscore (adata,proximity= ['ECAD+', 'SMA+'],\n                               phenotype='phenotype',\n                               method='radius',\n                               radius=50)\n</code></pre> <pre><code>Identifying neighbours within 50 pixels of every cell\nPlease check:\nadata.obs['spatial_pscore'] &amp;\nadata.uns['spatial_pscore'] for results\n</code></pre> <pre><code>sm.pl.voronoi(adata, color_by='spatial_pscore', \n                 voronoi_edge_color = 'black',\n                 voronoi_line_width = 0.3, \n                 voronoi_alpha = 0.8, \n                 size_max=3000,\n                 overlay_points=None, \n                 plot_legend=True, \n                 legend_size=6)\n</code></pre> <p></p> <p>In the plot above, the regions highlighted in red indicate areas where tumor cells and blood vessels are found in close proximity.</p>"},{"location":"tutorials/md/spatial_search_scimap/#search-for-regions-of-aggregation-based-on-similarity","title":"Search for regions of Aggregation based on Similarity","text":"<p>What if you've spotted an area of interest in a raw image and wish to explore whether there are other regions within that image, or across the dataset, sharing the same molecular composition? For this task, the <code>spatial_similarity_search</code> function is your go-to tool. A preliminary step for using this function is identifying a Region of Interest (ROI), preferably a small one for better specificity, using the <code>addROI_image</code> function. This identified ROI then serves as the input for the spatial similarity search. It's important to note that if multiple ROIs are used, an average of these regions will be taken as the basis for the search. Therefore, it's generally recommended to be precise in defining your ROI to ensure the specificity of your search results.</p> <p>For the purpose of this tutorial I am just going to use one of the ROIs that we defined previously. </p> <pre><code>adata = sm.tl.spatial_similarity_search(adata, ROI_column='ROI', similarity_threshold=0.4,\n                                          ROI_subset=['ROI1'], method='radius', radius=40,\n                                          label='tumor_similarity')\n</code></pre> <pre><code>Identifying neighbours within 40 pixels of every cell\n</code></pre> <pre><code># Let's look at the regions identified by the method\nsm.pl.voronoi(adata, color_by='spatial_pscore', \n                 voronoi_edge_color = 'black',\n                 voronoi_line_width = 0.3, \n                 voronoi_alpha = 0.8, \n                 size_max=3000,\n                 overlay_points=None, \n                 plot_legend=True, \n                 legend_size=6)\n</code></pre> <p></p>"},{"location":"tutorials/md/spatial_search_scimap/#save-results","title":"Save Results","text":"<pre><code># Save the results\nadata.write('/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/resources/exemplarData/scimapExampleData/scimapExampleData.h5ad')\n</code></pre> <pre><code>\n</code></pre>"}]}